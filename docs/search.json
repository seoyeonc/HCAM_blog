[
  {
    "objectID": "3_figure.html",
    "href": "3_figure.html",
    "title": "Figure",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 31, 2023\n\n\n[CAM]other methods chest xray\n\n\nSEOYEON CHOI\n\n\n\n\nSep 23, 2023\n\n\n[CAM]HCAM_ebayes\n\n\nSEOYEON CHOI\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Main_Blog",
      "**Result**",
      "**Figure**"
    ]
  },
  {
    "objectID": "1_studies.html",
    "href": "1_studies.html",
    "title": "Studies",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 27, 2023\n\n\n[HCAM]Study\n\n\nSEOYEON CHOI\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Main_Blog",
      "**Studies**"
    ]
  },
  {
    "objectID": "posts/2_research/2023-11-29-HCAM_Tutorial.html",
    "href": "posts/2_research/2023-11-29-HCAM_Tutorial.html",
    "title": "[CAM]HCAM Tutorial",
    "section": "",
    "text": "import HCAM\nfrom torchvision.models import *\nfrom fastai.vision.all import *"
  },
  {
    "objectID": "posts/2_research/2023-11-29-HCAM_Tutorial.html#mode-1",
    "href": "posts/2_research/2023-11-29-HCAM_Tutorial.html#mode-1",
    "title": "[CAM]HCAM Tutorial",
    "section": "Mode 1",
    "text": "Mode 1\n\none = HCAM.HCAM(lrnr = lrnr2)\n\n\none.learner_thresh(Thresh=1600,input_img=x_cat)\n\n/home/csy/Dropbox/blog/posts/CAM/HCAM/learners.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[0].detach().reshape(-1))**2)))\n/home/csy/Dropbox/blog/posts/CAM/HCAM/learners.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  self.ybar_threshed = np.where(power_threshed&gt;Thresh,torch.tensor(camimg[0].detach().reshape(-1)),0)\n\n\n\none.learner_step(Rate=-0.05)\n\n\none.prob(input_img=x_cat)\n\n\none.mode_decomp(input_img=x_cat)\n\n\n# one(input_img=x_cat)\n\n\nHCAM.plot(dls,input_img=x_cat,\n         input_img1=one(input_img=x_cat)['x'],input_img1_res=one(input_img=x_cat)['x_res'],\n         one=0.3, one_res=0.2)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-11-29-HCAM_Tutorial.html#mode-2",
    "href": "posts/2_research/2023-11-29-HCAM_Tutorial.html#mode-2",
    "title": "[CAM]HCAM Tutorial",
    "section": "Mode 2",
    "text": "Mode 2\n\none.learner_thresh(Thresh=1600,input_img=one(input_img=x_cat)['x_res'])\n\n\none.learner_step(Rate=-0.05)\n\n\none.prob(input_img=one(input_img=x_cat)['x_res'])\n\n\none.mode_decomp(input_img=one(input_img=x_cat)['x_res'])\n\n\n# one(input_img=one(input_img=x_cat)['x_res'])\n\n\nHCAM.plot(dls,input_img=x_cat,\n         input_img1=one(input_img=x_cat)['x'],input_img1_res=one(input_img=x_cat)['x_res'],\n         input_img2=one(input_img=one(input_img=x_cat)['x'])['x'],input_img2_res=one(input_img=one(input_img=x_cat)['x_res'])['x_res'],\n         one=0.35, one_res=0.2, two=0.5, two_res=0.2)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html",
    "title": "[CAM]Other Methods",
    "section": "",
    "text": "https://pythonrepo.com/repo/jacobgil-pytorch-grad-cam\nhttps://github.com/jacobgil/pytorch-grad-cam"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_gradcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_gradcam",
    "title": "[CAM]Other Methods",
    "section": "Cat_GradCAM",
    "text": "Cat_GradCAM\n\nCat_GradCAM_Original\n\ngradcam_original = GradCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_gradcam_original = gradcam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_gradcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_GradCAM_Randombox\n\ngradcam_randombox = GradCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_gradcam_randombox = gradcam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_gradcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_gradcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_gradcam",
    "title": "[CAM]Other Methods",
    "section": "Dog_GradCAM",
    "text": "Dog_GradCAM\n\nDog_GradCAM_Original\n\ncam_dog_gradcam_original = gradcam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_gradcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_GradCAM_Randombox\n\ncam_dog_gradcam_randombox = gradcam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_gradcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_hirescam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_hirescam",
    "title": "[CAM]Other Methods",
    "section": "Cat_HiResCAM",
    "text": "Cat_HiResCAM\n\nCat_HiResCAM_Original\n\nhirescam_original = HiResCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_hirescam_original = hirescam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_hirescam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_HiResCAM_Randombox\n\nhirescam_randombox = HiResCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_hirescam_randombox = hirescam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_hirescam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_hirescam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_hirescam",
    "title": "[CAM]Other Methods",
    "section": "Dog_HiResCAM",
    "text": "Dog_HiResCAM\n\nDog_HiResCAM_Original\n\ncam_dog_hirescam_original = hirescam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_hirescam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_HiResCAM_Random\n\ncam_dog_hirescam_randombox = hirescam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_hirescam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_scorecam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_scorecam",
    "title": "[CAM]Other Methods",
    "section": "Cat_ScoreCAM",
    "text": "Cat_ScoreCAM\n\nCat_ScoreCAM_Original\n\nscorecam_original = ScoreCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_scorecam_original = scorecam_original(input_tensor=x_cat,targets=None)\n\n100%|██████████| 32/32 [00:25&lt;00:00,  1.26it/s]\n100%|██████████| 32/32 [00:24&lt;00:00,  1.29it/s]\n100%|██████████| 32/32 [00:24&lt;00:00,  1.29it/s]\n\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_scorecam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_ScoreCAM_Randombox\n\nscorecam_randombox = ScoreCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_scorecam_randombox = scorecam_randombox(input_tensor=x_cat_r,targets=None)\n\n100%|██████████| 32/32 [00:24&lt;00:00,  1.30it/s]\n100%|██████████| 32/32 [00:24&lt;00:00,  1.31it/s]\n100%|██████████| 32/32 [00:24&lt;00:00,  1.30it/s]\n\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_scorecam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_scorecam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_scorecam",
    "title": "[CAM]Other Methods",
    "section": "Dog_ScoreCAM",
    "text": "Dog_ScoreCAM\n\nDog_ScoreCAM_Original\n\ncam_dog_scorecam_original = scorecam_original(input_tensor=x_dog,targets=None)\n\n100%|██████████| 32/32 [00:24&lt;00:00,  1.29it/s]\n100%|██████████| 32/32 [00:24&lt;00:00,  1.30it/s]\n100%|██████████| 32/32 [00:24&lt;00:00,  1.29it/s]\n\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_scorecam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_ScoreCAM_Randombox\n\ncam_dog_scorecam_randombox = scorecam_randombox(input_tensor=x_dog_r,targets=None)\n\n100%|██████████| 32/32 [00:24&lt;00:00,  1.30it/s]\n100%|██████████| 32/32 [00:24&lt;00:00,  1.29it/s]\n100%|██████████| 32/32 [00:24&lt;00:00,  1.30it/s]\n\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_scorecam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_gradcamplusplus",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_gradcamplusplus",
    "title": "[CAM]Other Methods",
    "section": "Cat_GradCAMPlusPlus",
    "text": "Cat_GradCAMPlusPlus\n\nCat_GradCAMPlusPlus_Original\n\ngradcamplusplus_original = GradCAMPlusPlus(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_gradcamplusplus_original = gradcamplusplus_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_gradcamplusplus_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_GradCAMPlusPlus_Randombox\n\ngradcamplusplus_randombox = GradCAMPlusPlus(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_gradcamplusplus_randombox = gradcamplusplus_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_gradcamplusplus_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_gradcamplusplus",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_gradcamplusplus",
    "title": "[CAM]Other Methods",
    "section": "Dog_GradCAMPlusPlus",
    "text": "Dog_GradCAMPlusPlus\n\nDog_GradCAMPlusPlus_Original\n\ncam_dog_gradcamplusplus_original = gradcamplusplus_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_gradcamplusplus_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_GradCAMPlusPlus_Randombox\n\ncam_dog_gradcamplusplus_randombox = gradcamplusplus_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_gradcamplusplus_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_ablationcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_ablationcam",
    "title": "[CAM]Other Methods",
    "section": "Cat_AblationCAM",
    "text": "Cat_AblationCAM\n\nCat_AblationCAM_Original\n\nablationcam_original = AblationCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_ablationcam_original = ablationcam_original(input_tensor=x_cat,targets=None)\n\n100%|██████████| 16/16 [00:26&lt;00:00,  1.67s/it]\n100%|██████████| 16/16 [00:26&lt;00:00,  1.65s/it]\n100%|██████████| 16/16 [00:27&lt;00:00,  1.70s/it]\n\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_ablationcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_AblationCAM_Randombox\n\nablationcam_randombox = AblationCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_ablationcam_randombox = ablationcam_randombox(input_tensor=x_cat_r,targets=None)\n\n100%|██████████| 16/16 [00:25&lt;00:00,  1.62s/it]\n100%|██████████| 16/16 [00:25&lt;00:00,  1.60s/it]\n100%|██████████| 16/16 [00:25&lt;00:00,  1.59s/it]\n\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_ablationcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_ablationcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_ablationcam",
    "title": "[CAM]Other Methods",
    "section": "Dog_AblationCAM",
    "text": "Dog_AblationCAM\n\nDog_AblationCAM_Original\n\ncam_dog_ablationcam_original = ablationcam_original(input_tensor=x_dog,targets=None)\n\n100%|██████████| 16/16 [00:25&lt;00:00,  1.61s/it]\n100%|██████████| 16/16 [00:25&lt;00:00,  1.58s/it]\n100%|██████████| 16/16 [00:25&lt;00:00,  1.61s/it]\n\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_ablationcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_AblationCAM_Randombox\n\ncam_dog_ablationcam_randombox = ablationcam_randombox(input_tensor=x_dog_r,targets=None)\n\n100%|██████████| 16/16 [00:25&lt;00:00,  1.59s/it]\n100%|██████████| 16/16 [00:25&lt;00:00,  1.62s/it]\n100%|██████████| 16/16 [00:25&lt;00:00,  1.61s/it]\n\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_ablationcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_xgradcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_xgradcam",
    "title": "[CAM]Other Methods",
    "section": "Cat_XGradCAM",
    "text": "Cat_XGradCAM\n\nCat_XGradCAM_Original\n\nxgradcam_original = XGradCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_xgradcam_original = xgradcam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_xgradcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_XGradCAM_Randombox\n\nxgradcam_randombox = XGradCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_xgradcam_randombox = xgradcam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_xgradcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_xgradcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_xgradcam",
    "title": "[CAM]Other Methods",
    "section": "Dog_XGradCAM",
    "text": "Dog_XGradCAM\n\nDog_XGradCAM_Original\n\ncam_dog_xgradcam_original = xgradcam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_xgradcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_XGradCAM_Randombox\n\ncam_dog_xgradcam_randombox = xgradcam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_xgradcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_eigencam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_eigencam",
    "title": "[CAM]Other Methods",
    "section": "Cat_EigenCAM",
    "text": "Cat_EigenCAM\n\nCat_EigenCAM_Original\n\neigencam_original = EigenCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_eigencam_original = eigencam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_eigencam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_EigenCAM_Randombox\n\neigencam_randombox = EigenCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_eigencam_randombox = eigencam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_eigencam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_eigencam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_eigencam",
    "title": "[CAM]Other Methods",
    "section": "Dog_EigenCAM",
    "text": "Dog_EigenCAM\n\nDog_EigenCAM_Original\n\ncam_dog_eigencam_original = eigencam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_eigencam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_EigenCAM_Randombox\n\ncam_dog_eigencam_randombox = eigencam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_eigencam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_fullgrad",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_fullgrad",
    "title": "[CAM]Other Methods",
    "section": "Cat_FullGrad",
    "text": "Cat_FullGrad\n\nCat_FullGrad_Original\n\nfullgrad_original = FullGrad(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\nWarning: target_layers is ignored in FullGrad. All bias layers will be used instead\n\n\n\ncam_cat_fullgrad_original = fullgrad_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_fullgrad_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_FullGrad_Randombox\n\nfullgrad_randombox = FullGrad(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\nWarning: target_layers is ignored in FullGrad. All bias layers will be used instead\n\n\n\ncam_cat_fullgrad_randombox = fullgrad_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_fullgrad_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_fullgrad",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_fullgrad",
    "title": "[CAM]Other Methods",
    "section": "Dog_FullGrad",
    "text": "Dog_FullGrad\n\nDog_FullGrad_Original\n\ncam_dog_fullgrad_original = fullgrad_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_fullgrad_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_FullGrad_Randombox\n\ncam_dog_fullgrad_randombox = fullgrad_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_fullgrad_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_eigengradcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_eigengradcam",
    "title": "[CAM]Other Methods",
    "section": "Cat_EigenGradCAM",
    "text": "Cat_EigenGradCAM\n\nCat_EigenGradCAM_Original\n\neigengradcam_original = EigenGradCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_eigengradcam_original = eigengradcam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_eigengradcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_EigenGradCAM_Randombox\n\neigengradcam_randombox = EigenGradCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_eigengradcam_randombox = eigengradcam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_eigengradcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_eigengradcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_eigengradcam",
    "title": "[CAM]Other Methods",
    "section": "Dog_EigenGradCAM",
    "text": "Dog_EigenGradCAM\n\nDog_EigenGradCAM_Original\n\ncam_dog_eigengradcam_original = eigengradcam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_eigengradcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_EigenGradCAM_Randombox\n\ncam_dog_eigengradcam_randombox = eigengradcam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_eigengradcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_layercam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_layercam",
    "title": "[CAM]Other Methods",
    "section": "Cat_LayerCAM",
    "text": "Cat_LayerCAM\n\nCat_LayerCAM_Original\n\nlayercam_original = LayerCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_layercam_original = layercam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_layercam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_LayerCAM_Randombox\n\nlayercam_randombox = LayerCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_layercam_randombox = layercam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_layercam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_layercam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_layercam",
    "title": "[CAM]Other Methods",
    "section": "Dog_LayerCAM",
    "text": "Dog_LayerCAM"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_layercam_original",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_layercam_original",
    "title": "[CAM]Other Methods",
    "section": "Dog_LayerCAM_Original",
    "text": "Dog_LayerCAM_Original\n\ncam_dog_layercam_original = layercam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_layercam_original.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_layercam_randombox",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_layercam_randombox",
    "title": "[CAM]Other Methods",
    "section": "Dog_LayerCAM_Randombox",
    "text": "Dog_LayerCAM_Randombox\n\ncam_dog_layercam_randombox = layercam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_layercam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#figure_original",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#figure_original",
    "title": "[CAM]Other Methods",
    "section": "Figure_Original",
    "text": "Figure_Original\n\nfig, ((ax1,ax2,ax3,ax4),\n      (ax5,ax6,ax7,ax8),\n      (ax9,ax10,ax11,ax12),\n      (ax13,ax14,ax15,ax16),\n     (ax17,ax18,ax19,ax20)) = plt.subplots(5,4) \nplt.title('Original')\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax1)\nax1.imshow(cam_cat_gradcam_original.squeeze(), alpha=0.7)\nax1.set_title(\"GradCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_dog_gradcam_original.squeeze(), alpha=0.7)\nax2.set_title(\"GradCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax3)\nax3.imshow(cam_cat_hirescam_original.squeeze(), alpha=0.7)\nax3.set_title(\"HiResCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax4)\nax4.imshow(cam_dog_hirescam_original.squeeze(), alpha=0.7)\nax4.set_title(\"HiResCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax5)\nax5.imshow(cam_cat_scorecam_original.squeeze(), alpha=0.7)\nax5.set_title(\"ScoreCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax6)\nax6.imshow(cam_dog_scorecam_original.squeeze(), alpha=0.7)\nax6.set_title(\"ScoreCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax7)\nax7.imshow(cam_cat_gradcamplusplus_original.squeeze(), alpha=0.7)\nax7.set_title(\"GradCAMPlusPlus CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax8)\nax8.imshow(cam_dog_gradcamplusplus_original.squeeze(), alpha=0.7)\nax8.set_title(\"GradCAMPlusPlus DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax9)\nax9.imshow(cam_cat_ablationcam_original.squeeze(), alpha=0.7)\nax9.set_title(\"AblationCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax10)\nax10.imshow(cam_dog_ablationcam_original.squeeze(), alpha=0.7)\nax10.set_title(\"AblationCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax11)\nax11.imshow(cam_cat_xgradcam_original.squeeze(), alpha=0.7)\nax11.set_title(\"XGradCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax12)\nax12.imshow(cam_dog_xgradcam_original.squeeze(), alpha=0.7)\nax12.set_title(\"XGradCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax13)\nax13.imshow(cam_cat_eigencam_original.squeeze(), alpha=0.7)\nax13.set_title(\"EigenCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax14)\nax14.imshow(cam_dog_eigencam_original.squeeze(), alpha=0.7)\nax14.set_title(\"EigenCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax15)\nax15.imshow(cam_cat_fullgrad_original.squeeze(), alpha=0.7)\nax15.set_title(\"FullGrad CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax16)\nax16.imshow(cam_dog_fullgrad_original.squeeze(), alpha=0.7)\nax16.set_title(\"FullGrad DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax17)\nax17.imshow(cam_cat_eigengradcam_original.squeeze(), alpha=0.7)\nax17.set_title(\"EigenGradCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax18)\nax18.imshow(cam_dog_eigengradcam_original.squeeze(), alpha=0.7)\nax18.set_title(\"EigenGradCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax19)\nax19.imshow(cam_cat_layercam_original.squeeze(), alpha=0.7)\nax19.set_title(\"LayerCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax20)\nax20.imshow(cam_dog_layercam_original.squeeze(), alpha=0.7)\nax20.set_title(\"LayerCAM DOG PART\")\n#\nfig.set_figwidth(20)            \nfig.set_figheight(20)\nfig.tight_layout()\n\n# plt.savefig('original_other_plot.pdf', format='pdf')\nwith open('fig_original_plt.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\n\n\n\n\n\n\n\nwith open('fig_original_plt.pkl', 'rb') as file:\n    fig_original_plt = pickle.load(file)\nfig_original_plt.show()\n\n\n\n\n\n\n\n\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Matplotlib subplot을 Plotly로 변환\nfig = make_subplots(rows=5, cols=4, subplot_titles=('GradCAM CAT PART', 'GradCAM DOG PART', \n                                                   'HiResCAM CAT PART', 'HiResCAM DOG PART',\n                                                   'ScoreCAM CAT PART', 'ScoreCAM DOG PART',\n                                                   'GradCAMPlusPlus CAT PART', 'GradCAMPlusPlus DOG PART',\n                                                   'AblationCAM CAT PART', 'AblationCAM DOG PART',\n                                                   'XGradCAM CAT PART', 'XGradCAM DOG PART',\n                                                   'EigenCAM CAT PART', 'EigenCAM DOG PART',\n                                                   'FullGrad CAT PART', 'FullGrad DOG PART',\n                                                   'EigenGradCAM CAT PART', 'EigenGradCAM DOG PART',\n                                                   'LayerCAM CAT PART', 'LayerCAM DOG PART'))\n\n# 각 subplot에 이미지 및 heatmap 추가\nfor i, (image, heatmap, title) in enumerate([(cam_cat_gradcam_original.squeeze(), 'GradCAM CAT PART'),\n                                              (cam_dog_gradcam_original.squeeze(), 'GradCAM DOG PART'),\n                                              (cam_cat_hirescam_original.squeeze(), 'HiResCAM CAT PART'),\n                                              (cam_dog_hirescam_original.squeeze(), 'HiResCAM DOG PART'),\n                                              (cam_cat_scorecam_original.squeeze(), 'ScoreCAM CAT PART'),\n                                              (cam_dog_scorecam_original.squeeze(), 'ScoreCAM DOG PART'),\n                                              (cam_cat_gradcamplusplus_original.squeeze(), 'GradCAMPlusPlus CAT PART'),\n                                              (cam_dog_gradcamplusplus_original.squeeze(), 'GradCAMPlusPlus DOG PART'),\n                                              (cam_cat_ablationcam_original.squeeze(), 'AblationCAM CAT PART'),\n                                              (cam_dog_ablationcam_original.squeeze(), 'AblationCAM DOG PART'),\n                                              (cam_cat_xgradcam_original.squeeze(), 'XGradCAM CAT PART'),\n                                              (cam_dog_xgradcam_original.squeeze(), 'XGradCAM DOG PART'),\n                                              (cam_cat_eigencam_original.squeeze(), 'EigenCAM CAT PART'),\n                                              (cam_dog_eigencam_original.squeeze(), 'EigenCAM DOG PART'),\n                                              (cam_cat_fullgrad_original.squeeze(), 'FullGrad CAT PART'),\n                                              (cam_dog_fullgrad_original.squeeze(), 'FullGrad DOG PART'),\n                                              (cam_cat_eigengradcam_original.squeeze(), 'EigenGradCAM CAT PART'),\n                                              (cam_dog_eigengradcam_original.squeeze(), 'EigenGradCAM DOG PART'),\n                                              (cam_cat_layercam_original.squeeze(), 'LayerCAM CAT PART'),\n                                              (cam_dog_layercam_original.squeeze(), 'LayerCAM DOG PART')]):\n    row = i // 4 + 1\n    col = i % 4 + 1\n\n    fig.add_trace(go.Image(z=image, colorscale='Viridis'), row=row, col=col)\n    fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True, row=row, col=col)\n    fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True, row=row, col=col)\n    fig.update_layout(title_text=title, title_font_size=16, showlegend=False)\n\n# 그림 크기 조정 및 출력\nfig.update_layout(width=1000, height=1200, title_text='Original', title_font_size=20)\nfig.show()\n\nwith open('fig_original_plotly.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\nwith open('fig_original_plotly.pkl', 'rb') as file:\n    fig_original_plotly = pickle.load(file)\nfig_original_plotly.show()\n\nFileNotFoundError: [Errno 2] No such file or directory: 'fig_original_plotly.pkl'"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#figure_randombox",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#figure_randombox",
    "title": "[CAM]Other Methods",
    "section": "Figure_Randombox",
    "text": "Figure_Randombox\n\nfig, ((ax1,ax2,ax3,ax4),\n      (ax5,ax6,ax7,ax8),\n      (ax9,ax10,ax11,ax12),\n      (ax13,ax14,ax15,ax16),\n     (ax17,ax18,ax19,ax20)) = plt.subplots(5,4) \nplt.title('Randombox')\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax1)\nax1.imshow(cam_cat_gradcam_randombox.squeeze(), alpha=0.7)\nax1.set_title(\"GradCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_dog_gradcam_randombox.squeeze(), alpha=0.7)\nax2.set_title(\"GradCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax3)\nax3.imshow(cam_cat_hirescam_randombox.squeeze(), alpha=0.7)\nax3.set_title(\"HiResCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax4)\nax4.imshow(cam_dog_hirescam_randombox.squeeze(), alpha=0.7)\nax4.set_title(\"HiResCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax5)\nax5.imshow(cam_cat_scorecam_randombox.squeeze(), alpha=0.7)\nax5.set_title(\"ScoreCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax6)\nax6.imshow(cam_dog_scorecam_randombox.squeeze(), alpha=0.7)\nax6.set_title(\"ScoreCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax7)\nax7.imshow(cam_cat_gradcamplusplus_randombox.squeeze(), alpha=0.7)\nax7.set_title(\"GradCAMPlusPlus CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax8)\nax8.imshow(cam_dog_gradcamplusplus_randombox.squeeze(), alpha=0.7)\nax8.set_title(\"GradCAMPlusPlus DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax9)\nax9.imshow(cam_cat_ablationcam_randombox.squeeze(), alpha=0.7)\nax9.set_title(\"AblationCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax10)\nax10.imshow(cam_dog_ablationcam_randombox.squeeze(), alpha=0.7)\nax10.set_title(\"AblationCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax11)\nax11.imshow(cam_cat_xgradcam_randombox.squeeze(), alpha=0.7)\nax11.set_title(\"XGradCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax12)\nax12.imshow(cam_dog_xgradcam_randombox.squeeze(), alpha=0.7)\nax12.set_title(\"XGradCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax13)\nax13.imshow(cam_cat_eigencam_randombox.squeeze(), alpha=0.7)\nax13.set_title(\"EigenCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax14)\nax14.imshow(cam_dog_eigencam_randombox.squeeze(), alpha=0.7)\nax14.set_title(\"EigenCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax15)\nax15.imshow(cam_cat_fullgrad_randombox.squeeze(), alpha=0.7)\nax15.set_title(\"FullGrad CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax16)\nax16.imshow(cam_dog_fullgrad_randombox.squeeze(), alpha=0.7)\nax16.set_title(\"FullGrad DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax17)\nax17.imshow(cam_cat_eigengradcam_randombox.squeeze(), alpha=0.7)\nax17.set_title(\"EigenGradCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax18)\nax18.imshow(cam_dog_eigengradcam_randombox.squeeze(), alpha=0.7)\nax18.set_title(\"EigenGradCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax19)\nax19.imshow(cam_cat_layercam_randombox.squeeze(), alpha=0.7)\nax19.set_title(\"LayerCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax20)\nax20.imshow(cam_dog_layercam_randombox.squeeze(), alpha=0.7)\nax20.set_title(\"LayerCAM DOG PART\")\n#\nfig.set_figwidth(20)            \nfig.set_figheight(20)\nfig.tight_layout()\n\n# plt.savefig('randombox_other_plot.pdf', format='pdf')\n\nwith open('fig_randombox_plt.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\n\n\n\n\n\n\n\nwith open('fig_randombox_plt.pkl', 'rb') as file:\n    fig_randombox_plt = pickle.load(file)\nfig_randombox_plt.show()"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html",
    "title": "[CAM]chest xray",
    "section": "",
    "text": "import torch \nfrom fastai.vision.all import * \nimport cv2 as cv\nimport fastbook\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nimport os"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#st-cam-결과-분리",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#st-cam-결과-분리",
    "title": "[CAM]chest xray",
    "section": "1st cam 결과 분리",
    "text": "1st cam 결과 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx12.squeeze().show(ax=ax1)  #MODE1\nx1.squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"X1\")\nax2.set_title(\"X1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1=x1.reshape(1,3,224,224)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\nver2 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x1).squeeze())\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax1)\nax1.imshow(ver2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART\")\n#\nx1.squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\na1=net(x1).tolist()[0][0]\nb1=net(x1).tolist()[0][1]\nnp.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1))\n\n(6.664552246309979e-19, 1.0)\n\n\n\\(\\theta\\) 생각, hyperparameter로서..\n\ntest1=ver2[0]-torch.min(ver2[0])\n\n\nA3=torch.exp(-0.04*test1)  \n\n\nA4=1-A3\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 WEIGHT WITH THETA=0.04\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 RES WEIGHT WITH THETA=0.04\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n#mode2_res\nX3=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv.resize(X3,(224,224),interpolation=cv.INTER_LINEAR))\nx3=x.squeeze().to('cpu')*Y1*Y3-torch.min(x.squeeze().to('cpu')*Y1*Y3)\n\n\n#mode1*x\nX4=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY4=torch.Tensor(cv.resize(X4,(224,224),interpolation=cv.INTER_LINEAR))\nx4=x.squeeze().to('cpu')*Y1*Y4"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-분리-결과",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-분리-결과",
    "title": "[CAM]chest xray",
    "section": "2nd 분리 결과",
    "text": "2nd 분리 결과\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx12.squeeze().show(ax=ax1)  \nx1.squeeze().show(ax=ax2)  \nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx4.squeeze().show(ax=ax1)  \nx3.squeeze().show(ax=ax2)  \nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx3=x3.reshape(1,3,224,224)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\nver22 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x3).squeeze())"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam",
    "title": "[CAM]chest xray",
    "section": "CAM",
    "text": "CAM\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx3.squeeze().show(ax=ax1)\nax1.imshow(ver22[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART\")\n#\nx3.squeeze().show(ax=ax2)\nax2.imshow(ver22[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2, ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ver22[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\n#\n\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\na2=net(x3).tolist()[0][0]\nb2=net(x3).tolist()[0][1]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(3.322455317236289e-16, 0.9999999999999998)"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#차",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#차",
    "title": "[CAM]chest xray",
    "section": "2차",
    "text": "2차\n\nver2 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x1).squeeze())"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam-1",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam-1",
    "title": "[CAM]chest xray",
    "section": "CAM",
    "text": "CAM\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax1)\nax1.imshow(ver2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART\")\n#\nx1.squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\na1=net(x1).tolist()[0][0]\nb1=net(x1).tolist()[0][1]\nnp.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1))\n\n(3.013152213595138e-16, 0.9999999999999997)\n\n\n\ntest=ver2[0]-torch.min(ver2[0])\n\n\ntest1=ver2[1]-torch.min(ver2[1])\n\n\nA3=torch.exp(-0.08*test)  \n\n\nA4=1-A3\n\n\nA33 = torch.exp(-0.08*test1)\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"X2 WEIGHT WITH THETA=0.08\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A33.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"X2 RES WEIGHT WITH THETA=0.08\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n#mode2_res\nX3=np.array(A33.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv.resize(X3,(224,224),interpolation=cv.INTER_LINEAR))\nx3=(x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1))*0.2*Y3\n\n#x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1)*0.03\n\n\n#mode1그림을 위한 mode2_res*x\nX_3=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY_3=torch.Tensor(cv.resize(X_3,(224,224),interpolation=cv.INTER_LINEAR))\nx_3=(x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1))*Y3\n\n\n#mode2*x\nX4=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY4=torch.Tensor(cv.resize(X_3,(224,224),interpolation=cv.INTER_LINEAR))\nx4=(x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1))*Y4*0.2"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-cam-결과-분리",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-cam-결과-분리",
    "title": "[CAM]chest xray",
    "section": "2nd cam 결과 분리",
    "text": "2nd cam 결과 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx12.squeeze().show(ax=ax1)  \nx1.squeeze().show(ax=ax2)  \nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx4.squeeze().show(ax=ax1)  \nx3.squeeze().show(ax=ax2)  \nax1.set_title(\"X2\")\nax2.set_title(\"X2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx3=x3.reshape(1,3,224,224)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\nver22 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x3).squeeze())"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam-2",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam-2",
    "title": "[CAM]chest xray",
    "section": "CAM",
    "text": "CAM\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx3.squeeze().show(ax=ax1)\nax1.imshow(ver22[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART\")\n#\nx3.squeeze().show(ax=ax2)\nax2.imshow(ver22[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2, ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ver22[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\n#\n\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\na2=net(x3).tolist()[0][0]\nb2=net(x3).tolist()[0][1]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(1.1537635027871649e-15, 0.9999999999999989)"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#st-cam-결과-분리-1",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#st-cam-결과-분리-1",
    "title": "[CAM]chest xray",
    "section": "1st cam 결과 분리",
    "text": "1st cam 결과 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx12.squeeze().show(ax=ax1)  #MODE1\nx1.squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"X1\")\nax2.set_title(\"X1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1=x1.reshape(1,3,224,224)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-cam-분리",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-cam-분리",
    "title": "[CAM]chest xray",
    "section": "2nd cam 분리",
    "text": "2nd cam 분리\n\nver2 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x1).squeeze())"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam-3",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam-3",
    "title": "[CAM]chest xray",
    "section": "cam",
    "text": "cam\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax1)\nax1.imshow(ver2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART\")\n#\nx1.squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\na1=net(x1).tolist()[0][0]\nb1=net(x1).tolist()[0][1]\nnp.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1))\n\n(1.4950733419675e-20, 1.0)\n\n\n\ntest=ver2[0]-torch.min(ver2[0])\n\n\ntest1=ver2[1]-torch.min(ver2[1])\n\n\nA3=torch.exp(-0.1*test)  \n\n\nA4=1-A3\n\n\nA33 = torch.exp(-0.1*test1)\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"X2 WEIGHT WITH THETA=0.1\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A33.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"X2 RES WEIGHT WITH THETA=0.1\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n#mode2_res\nX3=np.array(A33.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv.resize(X3,(224,224),interpolation=cv.INTER_LINEAR))\nx3=(x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1))*0.3*Y3\n\n#x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1)*0.03\n\n\n#mode1그림을 위한 mode2_res*x\nX_3=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY_3=torch.Tensor(cv.resize(X_3,(224,224),interpolation=cv.INTER_LINEAR))\nx_3=(x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1))*Y3\n\n\n#mode2*x\nX4=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY4=torch.Tensor(cv.resize(X_3,(224,224),interpolation=cv.INTER_LINEAR))\nx4=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1)*Y4*0.05"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-cam-결과-분리-1",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-cam-결과-분리-1",
    "title": "[CAM]chest xray",
    "section": "2nd cam 결과 분리",
    "text": "2nd cam 결과 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx12.squeeze().show(ax=ax1)  \nx1.squeeze().show(ax=ax2)  \nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx4.squeeze().show(ax=ax1)  \nx3.squeeze().show(ax=ax2)  \nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx3=x3.reshape(1,3,224,224)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\nver22 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x3).squeeze())\n\ncam\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx3.squeeze().show(ax=ax1)\nax1.imshow(ver22[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART\")\n#\nx3.squeeze().show(ax=ax2)\nax2.imshow(ver22[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2, ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ver22[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\n#\n\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\na2=net(x3).tolist()[0][0]\nb2=net(x3).tolist()[0][1]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(4.3886825515670436e-18, 1.0)"
  },
  {
    "objectID": "posts/2_research/2023-12-26-HCAM_edit_cat.html#mode-1",
    "href": "posts/2_research/2023-12-26-HCAM_edit_cat.html#mode-1",
    "title": "[CAM]수정본 HCAM_cat",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.35).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x1).squeeze())\n\n\npower_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\nybar_threshed3 = np.where(power_threshed3&gt;10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\nybar_threshed3 = torch.tensor(ybar_threshed3.reshape(16,16))\n\npower_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\nybar_threshed4 = np.where(power_threshed4&gt;10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\nybar_threshed4 = torch.tensor(ybar_threshed4.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\n&lt;ipython-input-32-292f842a7fbc&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed3 = np.where(power_threshed3&gt;10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\n&lt;ipython-input-32-292f842a7fbc&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\n&lt;ipython-input-32-292f842a7fbc&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed4 = np.where(power_threshed4&gt;10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\n\n\n\na1,b1 = net(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.9992811248320637, 0.0007188751679363709)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 2nd CAM 분리\n\n# test1=camimg1[0]-torch.min(camimg1[0])\nA3 = torch.exp(-0.05*(ybar_threshed3))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1)*Y2-torch.min((x1)*Y2)\n\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1)*Y22-torch.min((x1)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n(x2*0.2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x2).squeeze())\n\n\npower_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\nybar_threshed5 = np.where(power_threshed5&gt;4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\nybar_threshed5 = torch.tensor(ybar_threshed5.reshape(16,16))\n\npower_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\nybar_threshed6 = np.where(power_threshed6&gt;4,torch.tensor(camimg2[1].detach().reshape(-1)),0)\nybar_threshed6 = torch.tensor(ybar_threshed6.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\n&lt;ipython-input-44-4701a2d33601&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed5 = np.where(power_threshed5&gt;4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\n&lt;ipython-input-44-4701a2d33601&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\n&lt;ipython-input-44-4701a2d33601&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed6 = np.where(power_threshed6&gt;4,torch.tensor(camimg2[1].detach().reshape(-1)),0)\n\n\n\na2,b2 = net(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.9965164483511132, 0.003483551648886877)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-12-26-HCAM_edit_cat.html#mode-3-만들기",
    "href": "posts/2_research/2023-12-26-HCAM_edit_cat.html#mode-3-만들기",
    "title": "[CAM]수정본 HCAM_cat",
    "section": "mode 3 만들기",
    "text": "mode 3 만들기\n\n# test2=camimg2[0]-torch.min(camimg2[0])\n\n\nA5 = torch.exp(-0.05*(ybar_threshed5))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n\nwith open('hcam_cat_plt1.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\nwith open('hcam_cat_plt2.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n    \n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n(x2*0.2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\nwith open('hcam_cat_plt3.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n    \n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*0.8).squeeze().show(ax=ax1)  #MODE3\n(x3*0.2).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_cat_plt4.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt1.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt2.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt3.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt4.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_cat_plt_mode1.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt_mode1.pkl', 'rb') as file:\n    hcam_cat_plt_mode1 = pickle.load(file)\nplt.show(hcam_cat_plt_mode1)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*0.5).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_cat_plt_mode2.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt_mode2.pkl', 'rb') as file:\n    hcam_cat_plt_mode2 = pickle.load(file)\nplt.show(hcam_cat_plt_mode2)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*0.5 + x32*0.5).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_cat_plt_mode3.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt_mode3.pkl', 'rb') as file:\n    hcam_cat_plt_mode3 = pickle.load(file)\nplt.show(hcam_cat_plt_mode3)"
  },
  {
    "objectID": "posts/2_research/2023-09-14-CAM_Image_download.html",
    "href": "posts/2_research/2023-09-14-CAM_Image_download.html",
    "title": "[CAM]Image Download",
    "section": "",
    "text": "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html\nhttps://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html\n\nimport\n\nimport torch \nfrom fastai.vision.all import *\nimport cv2\nimport numpy as np\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageFile\nfrom PIL import Image\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom torchvision.utils import save_image\nimport os\n\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\n\ndef label_func(f):\n    if f[0].isupper():\n        return 'cat' \n    else: \n        return 'dog' \n\n\n\nOriginal Image로 학습하는 과정\n\npath=untar_data(URLs.PETS)/'images'\n\n\n# path.ls()\n\n\nfiles=get_image_files(path)\n\n\ndls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) \n\n\nlrnr=cnn_learner(dls,resnet34,metrics=error_rate)\nlrnr.fine_tune(1)\n\n\nnet1=lrnr.model[0]\nnet2=lrnr.model[1] \n\n\nnet2 = torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), \n    torch.nn.Flatten(),\n    torch.nn.Linear(512,out_features=2,bias=False))\n\n\nnet=torch.nn.Sequential(net1,net2)\n\n\nlrnr2=Learner(dls,net,metrics=accuracy) \n\n\nlrnr2.fine_tune(10) \n\n\ninterp = ClassificationInterpretation.from_learner(lrnr2)\ninterp.plot_confusion_matrix()\n\n\ninterp.print_classification_report()\n\n\n\n랜덤박스가 들어간 개 고양이 그림 다운로드\n\npath=untar_data(URLs.PETS)/'images'\n\n\nif str(list(path.ls())[103]).split('/')[-1].split('.')[-1]==\"jpg\" :\n    print(\"jpg\")\n#name=str(list(path.ls())[i]).split('/')[-1]\n\n\npath.ls()\n\n\nfor i in range(7393) :\n    img = PILImage.create(get_image_files(path)[i])\n    img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n    name = str(list(path.ls())[i]).split('/')[-1]\n    fname = name.split('.')[-1]\n    if fname!=\"jpg\" : \n        print(name)\n    else : pass\n\n.mat 파일 같은 이상한 거 삭제\n\n# os.remove(r\"/home/csy/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.mat\")\n\n\n# os.remove(r\"/home/csy/.fastai/data/oxford-iiit-pet/images/Abyssinian_102.mat\")\n\n\n# os.remove(r\"/home/csy/.fastai/data/oxford-iiit-pet/images/Abyssinian_101.mat\")\n\n\n# os.mkdir(\"random_pet_one\")\n\n\n# for i in range(len(path.ls())) :\n#     img = PILImage.create(get_image_files(path)[i])\n#     img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n#     (w, h) = (img.shape[0], img.shape[1])\n#     a = random.uniform(0, w*0.7)\n#     b = random.uniform(0, h*0.9)\n#     shape = [(a, b), (a+85, b+85)]\n#     font = ImageFont.truetype(\"DejaVuSans.ttf\", round(h*0.075))\n#     name = str(list(path.ls())[i]).split('/')[-1]\n#     fname = name.split('.')[-1]\n#     if name[0].isupper() == True :\n#         img1 = ImageDraw.Draw(img)  \n#         img1.rectangle(shape, fill =\"white\", outline =\"black\")\n#         ImageDraw.Draw(img).text((a+5, b+15), 'Cat', (0,0,0), font=font)\n#         img.save(\"random_pet_one/\"+name)\n#     else: \n#         img1 = ImageDraw.Draw(img)  \n#         img1.rectangle(shape, fill =\"black\", outline =\"black\")\n#         ImageDraw.Draw(img).text((a+5, b+15), 'Dog', (255,255,255), font=font)\n#         img.save(\"random_pet_one/\"+name)"
  },
  {
    "objectID": "posts/2_research/2023-09-19-HCAM_original.html",
    "href": "posts/2_research/2023-09-19-HCAM_original.html",
    "title": "[CAM]HCAM original",
    "section": "",
    "text": "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html\nhttps://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html\nCNN으로 이미지 분류를 할 때 마지막 단의 출력값이 클수록 softmax를 거친 뒤 1에 가까워 진다면, 입력 이미지의 label에 해당하는 채널의 마지막 conv layer의 출력이 크게 하는 클래스에 크게 반응했다는 것이 됌..!"
  },
  {
    "objectID": "posts/2_research/2023-09-19-HCAM_original.html#ebayes-x",
    "href": "posts/2_research/2023-09-19-HCAM_original.html#ebayes-x",
    "title": "[CAM]HCAM original",
    "section": "ebayes X",
    "text": "ebayes X\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        camimg = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x).squeeze())\n        a,b = net(x).tolist()[0]\n        catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n        if catprob&gt;dogprob: \n            test=camimg[0]-torch.min(camimg[0])\n            A1=torch.exp(-0.1*test)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n        else: \n            test=camimg[1]-torch.min(camimg[1])\n            A1=torch.exp(-0.1*test)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-09-19-HCAM_original.html#mode-1",
    "href": "posts/2_research/2023-09-19-HCAM_original.html#mode-1",
    "title": "[CAM]HCAM original",
    "section": "mode 1",
    "text": "mode 1\n\ntest=camimg[0]-torch.min(camimg[0])\nA1=torch.exp(-0.01*(test))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.3).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x1).squeeze())\n\n\na1,b1 = net(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.9986349047084874, 0.0013650952915126677)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.3).squeeze().show(ax=ax1)\nax1.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.3).squeeze().show(ax=ax2)\nax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 2nd CAM 분리\n\ntest1=camimg1[0]-torch.min(camimg1[0])\nA3 = torch.exp(-0.015*(test1))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1)*Y2-torch.min((x1)*Y2)\n\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1)*Y22-torch.min((x1)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n(x2*0.3).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x2).squeeze())\n\n\na2,b2 = net(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.19813533943993217, 0.8018646605600679)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-09-19-HCAM_original.html#mode-3-만들기",
    "href": "posts/2_research/2023-09-19-HCAM_original.html#mode-3-만들기",
    "title": "[CAM]HCAM original",
    "section": "mode 3 만들기",
    "text": "mode 3 만들기\n\ntest2=camimg2[0]-torch.min(camimg2[0])\n\n\nA5 = torch.exp(-0.05*(test2))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n(x2*0.3).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*0.3).squeeze().show(ax=ax1)  #MODE3\n(x3*0.2).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*0.3).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*0.3 + x32*0.2).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-09-19-HCAM_original.html#mode-1-1",
    "href": "posts/2_research/2023-09-19-HCAM_original.html#mode-1-1",
    "title": "[CAM]HCAM original",
    "section": "mode 1",
    "text": "mode 1\n\ntest=camimg[1]-torch.min(camimg[1])\nA1=torch.exp(-0.015*(test))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x1).squeeze())\n\n\na1,b1 = net(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.003175590188180829, 0.9968244098118192)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.3).squeeze().show(ax=ax1)\nax1.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.3).squeeze().show(ax=ax2)\nax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 2nd CAM 분리\n\ntest1=camimg1[1]-torch.min(camimg1[1])\nA3 = torch.exp(-0.05*(test1))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n# res \nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1*0.2)*Y2-torch.min((x1*0.2)*Y2)\n#\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1*0.2)*Y22-torch.min((x1*0.2)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*3).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x2).squeeze())\n\n\na2,b2 = net(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.6993123345460756, 0.3006876654539244)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-09-19-HCAM_original.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "href": "posts/2_research/2023-09-19-HCAM_original.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "title": "[CAM]HCAM original",
    "section": "mode 3 만들기 더이상 분리되지 않는 듯",
    "text": "mode 3 만들기 더이상 분리되지 않는 듯\n\ntest2=camimg2[1]-torch.min(camimg2[1])\n\n\nA5 = torch.exp(-0.05*(test2))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*2).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*8).squeeze().show(ax=ax1)  #MODE3\n(x3).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*1).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*1 + x32*1).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\npath_r=Path('random_pet_one')   #랜덤박스넣은사진\n\n\nfiles_r=get_image_files(path_r)\n\n\ndls_r=ImageDataLoaders.from_name_func(path_r,files_r,label_func,item_tfms=Resize(512))"
  },
  {
    "objectID": "posts/2_research/2023-09-15-CAM-Original_rst.html",
    "href": "posts/2_research/2023-09-15-CAM-Original_rst.html",
    "title": "[CAM]Original CAM",
    "section": "",
    "text": "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html\nhttps://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html"
  },
  {
    "objectID": "posts/2_research/2023-09-15-CAM-Original_rst.html#cat",
    "href": "posts/2_research/2023-09-15-CAM-Original_rst.html#cat",
    "title": "[CAM]Original CAM",
    "section": "CAT",
    "text": "CAT\n\nx, = first(dls.test_dl([PILImage.create(get_image_files(path)[2])]))\n\n\ncamimg = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x).squeeze())\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow((camimg[0]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"CAT PART\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow((camimg[1]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -&gt; 보라색\n\n\na,b = net(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(0.9999981602003378, 1.8397996622021463e-06)"
  },
  {
    "objectID": "posts/2_research/2023-09-15-CAM-Original_rst.html#dog",
    "href": "posts/2_research/2023-09-15-CAM-Original_rst.html#dog",
    "title": "[CAM]Original CAM",
    "section": "DOG",
    "text": "DOG\n\nx, = first(dls.test_dl([PILImage.create(get_image_files(path)[12])]))\n\n\ncamimg = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x).squeeze())\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow((camimg[0]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"CAT PART\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow((camimg[1]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -&gt; 보라색\n\n\na,b = net(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(0.00010162988443540359, 0.9998983701155646)"
  },
  {
    "objectID": "posts/2_research/2023-09-15-CAM-Original_rst.html#cat-1",
    "href": "posts/2_research/2023-09-15-CAM-Original_rst.html#cat-1",
    "title": "[CAM]Original CAM",
    "section": "CAT",
    "text": "CAT\n\nx, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[2])]))\n\n\ncamimg = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x).squeeze())\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow((camimg[0]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"CAT PART\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow((camimg[1]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -&gt; 보라색\n\n\na,b = net(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(0.999967767699998, 3.22323000020705e-05)"
  },
  {
    "objectID": "posts/2_research/2023-09-15-CAM-Original_rst.html#dog-1",
    "href": "posts/2_research/2023-09-15-CAM-Original_rst.html#dog-1",
    "title": "[CAM]Original CAM",
    "section": "DOG",
    "text": "DOG\n\nx, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[12])]))\n\n\ncamimg = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x).squeeze())\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow((camimg[0]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"CAT PART\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow((camimg[1]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -&gt; 보라색\n\n\na,b = net(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(0.0002528585790783918, 0.9997471414209217)"
  },
  {
    "objectID": "posts/3_result/3_figure/2023-09-23-HCAM_hy.html#mode-1",
    "href": "posts/3_result/3_figure/2023-09-23-HCAM_hy.html#mode-1",
    "title": "[CAM]HCAM_ebayes",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.35).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x1).squeeze())\n\n\npower_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\nybar_threshed3 = np.where(power_threshed3&gt;10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\nybar_threshed3 = torch.tensor(ybar_threshed3.reshape(16,16))\n\npower_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\nybar_threshed4 = np.where(power_threshed4&gt;10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\nybar_threshed4 = torch.tensor(ybar_threshed4.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\n&lt;ipython-input-333-292f842a7fbc&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed3 = np.where(power_threshed3&gt;10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\n&lt;ipython-input-333-292f842a7fbc&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\n&lt;ipython-input-333-292f842a7fbc&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed4 = np.where(power_threshed4&gt;10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\n\n\n\na1,b1 = net(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.9993523558198389, 0.0006476441801611291)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 2nd CAM 분리\n\n# test1=camimg1[0]-torch.min(camimg1[0])\nA3 = torch.exp(-0.05*(ybar_threshed3))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1)*Y2-torch.min((x1)*Y2)\n\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1)*Y22-torch.min((x1)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n(x2*0.2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x2).squeeze())\n\n\npower_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\nybar_threshed5 = np.where(power_threshed5&gt;4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\nybar_threshed5 = torch.tensor(ybar_threshed5.reshape(16,16))\n\npower_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\nybar_threshed6 = np.where(power_threshed6&gt;4,torch.tensor(camimg2[1].detach().reshape(-1)),0)\nybar_threshed6 = torch.tensor(ybar_threshed6.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\n&lt;ipython-input-364-4701a2d33601&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed5 = np.where(power_threshed5&gt;4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\n&lt;ipython-input-364-4701a2d33601&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\n&lt;ipython-input-364-4701a2d33601&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed6 = np.where(power_threshed6&gt;4,torch.tensor(camimg2[1].detach().reshape(-1)),0)\n\n\n\na2,b2 = net(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.9923479929133789, 0.007652007086621125)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/3_result/3_figure/2023-09-23-HCAM_hy.html#mode-3-만들기",
    "href": "posts/3_result/3_figure/2023-09-23-HCAM_hy.html#mode-3-만들기",
    "title": "[CAM]HCAM_ebayes",
    "section": "mode 3 만들기",
    "text": "mode 3 만들기\n\n# test2=camimg2[0]-torch.min(camimg2[0])\n\n\nA5 = torch.exp(-0.05*(ybar_threshed5))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n(x2*0.2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*0.8).squeeze().show(ax=ax1)  #MODE3\n(x3*0.2).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*0.5).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*0.5 + x32*0.5).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/3_result/3_figure/2023-09-23-HCAM_hy.html#mode-1-1",
    "href": "posts/3_result/3_figure/2023-09-23-HCAM_hy.html#mode-1-1",
    "title": "[CAM]HCAM_ebayes",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed2))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.3).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x1).squeeze())\n\n\npower_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\nybar_threshed3 = np.where(power_threshed3&gt;10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\nybar_threshed3 = torch.tensor(ybar_threshed3.reshape(16,16))\n\npower_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\nybar_threshed4 = np.where(power_threshed4&gt;10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\nybar_threshed4 = torch.tensor(ybar_threshed4.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\n&lt;ipython-input-292-292f842a7fbc&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed3 = np.where(power_threshed3&gt;10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\n&lt;ipython-input-292-292f842a7fbc&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\n&lt;ipython-input-292-292f842a7fbc&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed4 = np.where(power_threshed4&gt;10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\n\n\n\na1,b1 = net(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.005690363539499261, 0.9943096364605006)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed2,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 2nd CAM 분리\n\n# test1=camimg1[1]-torch.min(camimg1[1])\nA3 = torch.exp(-0.05*(ybar_threshed4))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n# res \nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1*0.2)*Y2-torch.min((x1*0.2)*Y2)\n#\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1*0.2)*Y22-torch.min((x1*0.2)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*3).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x2).squeeze())\n\n\npower_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\nybar_threshed5 = np.where(power_threshed5&gt;4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\nybar_threshed5 = torch.tensor(ybar_threshed5.reshape(16,16))\n\npower_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\nybar_threshed6 = np.where(power_threshed6&gt;4,torch.tensor(camimg1[1].detach().reshape(-1)),0)\nybar_threshed6 = torch.tensor(ybar_threshed6.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\n&lt;ipython-input-307-25e0375ebe18&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed5 = np.where(power_threshed5&gt;4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\n&lt;ipython-input-307-25e0375ebe18&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\n&lt;ipython-input-307-25e0375ebe18&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed6 = np.where(power_threshed6&gt;4,torch.tensor(camimg1[1].detach().reshape(-1)),0)\n\n\n\na2,b2 = net(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.7995345644391025, 0.2004654355608974)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed2,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/3_result/3_figure/2023-09-23-HCAM_hy.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "href": "posts/3_result/3_figure/2023-09-23-HCAM_hy.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "title": "[CAM]HCAM_ebayes",
    "section": "mode 3 만들기 더이상 분리되지 않는 듯",
    "text": "mode 3 만들기 더이상 분리되지 않는 듯\n\n# test2=camimg2[1]-torch.min(camimg2[1])\n\n\nA5 = torch.exp(-0.05*(ybar_threshed6))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*4).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*8).squeeze().show(ax=ax1)  #MODE3\n(x3).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4 + x32*2).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/1_studies/2023-10-27-HCAM_study.html",
    "href": "posts/1_studies/2023-10-27-HCAM_study.html",
    "title": "[HCAM]Study",
    "section": "",
    "text": "CNN의 일반적인 구조 : Input layer - Conv Layers - FC layers\n\n\n\n완전 연결 계층; 한 뉴런이 다음 단계 뉴런과 모두 연결되어 있는 상태(= Dense Layer)\n\n예를 들어 flatten 해서 Relu 취하고 Softmax 취하면 이 세 과정이 다 fc layer에 포함된다.\n흑백 이미지 같은 경우에는 흑백으로 표현되어 1차 배열로 flatten 하는데 문제가 없지만 RGB를 모두 표현하는 색 있는 이미지 같은 경우에는 flatten하여 fc layers를 진횅시킨다면 정보 손실 등의 우려가 생긴다."
  },
  {
    "objectID": "posts/1_studies/2023-10-27-HCAM_study.html#fc-layer-fully-connected-layer",
    "href": "posts/1_studies/2023-10-27-HCAM_study.html#fc-layer-fully-connected-layer",
    "title": "[HCAM]Study",
    "section": "",
    "text": "완전 연결 계층; 한 뉴런이 다음 단계 뉴런과 모두 연결되어 있는 상태(= Dense Layer)\n\n예를 들어 flatten 해서 Relu 취하고 Softmax 취하면 이 세 과정이 다 fc layer에 포함된다.\n흑백 이미지 같은 경우에는 흑백으로 표현되어 1차 배열로 flatten 하는데 문제가 없지만 RGB를 모두 표현하는 색 있는 이미지 같은 경우에는 flatten하여 fc layers를 진횅시킨다면 정보 손실 등의 우려가 생긴다."
  },
  {
    "objectID": "posts/1_studies/2023-10-27-HCAM_study.html#footnotes",
    "href": "posts/1_studies/2023-10-27-HCAM_study.html#footnotes",
    "title": "[HCAM]Study",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nGlobal Max Pooling 도 있는데 이것은 GAP와 달리 최댓값, 즉 가장 특징을 잘 표현할 것 같은 값을 반환해준다. ↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HCAM blog",
    "section": "",
    "text": "This blog provides information on HCAM.\n\nSome links related HCAM\n\nCAMExisted Thesis related CAM\n\n\n\nClass Activation Map: https://openaccess.thecvf.com/content_cvpr_2016/papers/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf\n\n\n\n\nGradCAM\nHiResCAM\nGradCAMPlusPlus\nAblationCAM\nXGradCAM\nEigenCAM\nFullGrad\nEigenGradCAM\nLayerCAM\n\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 5, 2024\n\n\nCAMDataset1\n\n\nSEOYEON CHOI\n\n\n\n\nDec 26, 2023\n\n\nCAM수정본 HCAM_cat\n\n\nSEOYEON CHOI\n\n\n\n\nDec 26, 2023\n\n\nCAM수정본 HCAM_dog\n\n\nSEOYEON CHOI\n\n\n\n\nDec 26, 2023\n\n\ntest\n\n\nSEOYEON CHOI\n\n\n\n\nNov 29, 2023\n\n\nCAMHCAM Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nNov 9, 2023\n\n\nCAMScore CAM(Original, Randombox)\n\n\nSEOYEON CHOI\n\n\n\n\nOct 31, 2023\n\n\nCAMother methods chest xray\n\n\nSEOYEON CHOI\n\n\n\n\nOct 27, 2023\n\n\n[HCAM]Study\n\n\nSEOYEON CHOI\n\n\n\n\nOct 18, 2023\n\n\nCAMOther Methods\n\n\nSEOYEON CHOI\n\n\n\n\nSep 23, 2023\n\n\nCAMHCAM_ebayes\n\n\nSEOYEON CHOI\n\n\n\n\nSep 21, 2023\n\n\nCAMchest xray\n\n\nSEOYEON CHOI\n\n\n\n\nSep 19, 2023\n\n\nCAMHCAM original\n\n\nSEOYEON CHOI\n\n\n\n\nSep 16, 2023\n\n\nCAMGrad CAM(Original, Randombox)\n\n\nSEOYEON CHOI\n\n\n\n\nSep 15, 2023\n\n\nCAMOriginal CAM\n\n\nSEOYEON CHOI\n\n\n\n\nSep 14, 2023\n\n\nCAMImage Download\n\n\nSEOYEON CHOI\n\n\n\n\nAug 28, 2023\n\n\nCAMHCAM random\n\n\nSEOYEON CHOI\n\n\n\n\nAug 28, 2023\n\n\nCAMOriginal CAM\n\n\nSEOYEON CHOI\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/3_result/3_figure/2023-10-31-HCAM_Other_Methods_chest_xray.html",
    "href": "posts/3_result/3_figure/2023-10-31-HCAM_Other_Methods_chest_xray.html",
    "title": "[CAM]other methods chest xray",
    "section": "",
    "text": "scorecam nan 값 산출 문제찾는 중..\n\nImport\n\nimport torch \nfrom fastai.vision.all import * \nimport cv2 as cv\nimport fastbook\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nimport os\n\nfrom pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad, EigenGradCAM, LayerCAM\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nimport torchvision\nfrom torchvision.models import resnet18\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torchvision.models import resnet50\n\n\n\nData\nrefer : https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n\n# path=Path('./home/Dropbox/chest_xray/chest_xray') \npath = Path(os.path.expanduser(os.path.join('~', 'Dropbox/chest_xray/chest_xray')))\n\n\npath.ls()\n\n(#3) [Path('/home/csy/Dropbox/chest_xray/chest_xray/train'),Path('/home/csy/Dropbox/chest_xray/chest_xray/test'),Path('/home/csy/Dropbox/chest_xray/chest_xray/val')]\n\n\n\nfiles=get_image_files(path)\n\n\ndls = ImageDataLoaders.from_folder(path, train='train', valid_pct=0.2, item_tfms=Resize(224))      \n\n\ndls.vocab\n\n['NORMAL', 'PNEUMONIA']\n\n\n\ndls.show_batch(max_n=16)\n\n\n\n\n\n\n\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\ngradcam = GradCAM(model=model, target_layers=target_layer)\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\nhirescam = HiResCAM(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\nscorecam = ScoreCAM(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\ngradcamplusplus = GradCAMPlusPlus(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\nablationcam = AblationCAM(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\nxgradcam = XGradCAM(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\neigencam = EigenCAM(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\nfullgrad = FullGrad(model=model, target_layers=target_layer)\n\nWarning: target_layers is ignored in FullGrad. All bias layers will be used instead\n\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\neigengradcam = EigenGradCAM(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\nlayercam = LayerCAM(model=model, target_layers=target_layer)\n\n\n\n1번째 시도\n\nimg = PILImage.create(get_image_files(path)[304])\n\n\nx, = first(dls.test_dl([img]))  #이미지 텐서화\nx = x.to('cpu')\n\n\ncam_gradcam = gradcam(input_tensor=x,targets=None)\n\n\ncam_hirescam = hirescam(input_tensor=x,targets=None)\n\n\ncam_scorecam = scorecam(input_tensor=x,targets=None)\n\n100%|██████████| 32/32 [00:03&lt;00:00,  9.20it/s]\n\n\n\ncam_gradcamplusplus = gradcamplusplus(input_tensor=x,targets=None)\n\n\ncam_ablationcam = ablationcam(input_tensor=x,targets=None)\n\n100%|██████████| 16/16 [00:03&lt;00:00,  4.14it/s]\n\n\n\ncam_xgradcam = xgradcam(input_tensor=x,targets=None)\n\n\ncam_eigencam = eigencam(input_tensor=x,targets=None)\n\n\ncam_fullgrad = fullgrad(input_tensor=x,targets=None)\n\n\ncam_eigengradcam = eigengradcam(input_tensor=x,targets=None)\n\n\ncam_layercam = layercam(input_tensor=x,targets=None)\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_hirescam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART HiResCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_hirescam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART HiResCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_scorecam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART ScoreCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_scorecam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART ScoreCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAMPlusPlus\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAMPlusPlus\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_ablationcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART AblationCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_ablationcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART AblationCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_xgradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART XGradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_xgradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART XGradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_eigencam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART EigenCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_eigencam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART EigenCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_fullgrad.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART FullGrad\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_fullgrad.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART FullGrad\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_layercam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART LayerCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_layercam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART LayerCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n2번째 시도\n\nimg = PILImage.create(get_image_files(path)[3031])\n\n\nx, = first(dls.test_dl([img]))  #이미지 텐서화\nx=x.to('cpu')\n\n\ncam_gradcam = gradcam(input_tensor=x,targets=None)\n\n\ncam_hirescam = hirescam(input_tensor=x,targets=None)\n\n\ncam_scorecam = scorecam(input_tensor=x,targets=None)\n\n100%|██████████| 32/32 [00:03&lt;00:00,  9.06it/s]\n\n\n\ncam_gradcamplusplus = gradcamplusplus(input_tensor=x,targets=None)\n\n\ncam_ablationcam = ablationcam(input_tensor=x,targets=None)\n\n100%|██████████| 16/16 [00:03&lt;00:00,  4.18it/s]\n\n\n\ncam_xgradcam = xgradcam(input_tensor=x,targets=None)\n\n\ncam_eigencam = eigencam(input_tensor=x,targets=None)\n\n\ncam_fullgrad = fullgrad(input_tensor=x,targets=None)\n\n\ncam_eigengradcam = eigengradcam(input_tensor=x,targets=None)\n\n\ncam_cat_layercam = layercam(input_tensor=x,targets=None)\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_hirescam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART HiResCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_hirescam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART HiResCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_scorecam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART ScoreCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_scorecam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART ScoreCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAMPlusPlus\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAMPlusPlus\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_ablationcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART AblationCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_ablationcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART AblationCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_xgradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART XGradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_xgradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART XGradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_eigencam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART EigenCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_eigencam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART EigenCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_fullgrad.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART FullGrad\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_fullgrad.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART FullGrad\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_layercam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART LayerCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_layercam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART LayerCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n3번째 시도\n\nimg = PILImage.create(get_image_files(path)[3107])\n\n\nx, = first(dls.test_dl([img]))  #이미지 텐서화\nx=x.to('cpu')\n\n\ncam_gradcam = gradcam(input_tensor=x,targets=None)\n\n\ncam_hirescam = hirescam(input_tensor=x,targets=None)\n\n\ncam_scorecam = scorecam(input_tensor=x,targets=None)\n\n100%|██████████| 32/32 [00:03&lt;00:00,  9.22it/s]\n\n\n\ncam_gradcamplusplus = gradcamplusplus(input_tensor=x,targets=None)\n\n\ncam_ablationcam = ablationcam(input_tensor=x,targets=None)\n\n100%|██████████| 16/16 [00:03&lt;00:00,  4.23it/s]\n\n\n\ncam_xgradcam = xgradcam(input_tensor=x,targets=None)\n\n\ncam_eigencam = eigencam(input_tensor=x,targets=None)\n\n\ncam_fullgrad = fullgrad(input_tensor=x,targets=None)\n\n\ncam_eigengradcam = eigengradcam(input_tensor=x,targets=None)\n\n\ncam_cat_layercam = layercam(input_tensor=x,targets=None)\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_hirescam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART HiResCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_hirescam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART HiResCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_scorecam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART ScoreCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_scorecam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART ScoreCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAMPlusPlus\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAMPlusPlus\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_ablationcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART AblationCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_ablationcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART AblationCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_xgradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART XGradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_xgradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART XGradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_eigencam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART EigenCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_eigencam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART EigenCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_fullgrad.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART FullGrad\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_fullgrad.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART FullGrad\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_layercam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART LayerCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_layercam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART LayerCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-12-26-HCAM_edit_dog.html#mode-1",
    "href": "posts/2_research/2023-12-26-HCAM_edit_dog.html#mode-1",
    "title": "[CAM]수정본 HCAM_dog",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed2))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x_dog.squeeze().to('cpu')*Y1-torch.min(x_dog.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x_dog.squeeze().to('cpu')*Y12-torch.min(x_dog.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.3).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x1).squeeze())\n\n\npower_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\nybar_threshed3 = np.where(power_threshed3&gt;10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\nybar_threshed3 = torch.tensor(ybar_threshed3.reshape(16,16))\n\npower_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\nybar_threshed4 = np.where(power_threshed4&gt;10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\nybar_threshed4 = torch.tensor(ybar_threshed4.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\n&lt;ipython-input-32-292f842a7fbc&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed3 = np.where(power_threshed3&gt;10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\n&lt;ipython-input-32-292f842a7fbc&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\n&lt;ipython-input-32-292f842a7fbc&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed4 = np.where(power_threshed4&gt;10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\n\n\n\na1,b1 = net(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.014474672732127929, 0.985525327267872)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed2,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 2nd CAM 분리\n\n# test1=camimg1[1]-torch.min(camimg1[1])\nA3 = torch.exp(-0.05*(ybar_threshed4))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n# res \nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1*0.2)*Y2-torch.min((x1*0.2)*Y2)\n#\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1*0.2)*Y22-torch.min((x1*0.2)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*3).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x2).squeeze())\n\n\npower_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\nybar_threshed5 = np.where(power_threshed5&gt;4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\nybar_threshed5 = torch.tensor(ybar_threshed5.reshape(16,16))\n\npower_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\nybar_threshed6 = np.where(power_threshed6&gt;4,torch.tensor(camimg1[1].detach().reshape(-1)),0)\nybar_threshed6 = torch.tensor(ybar_threshed6.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\n&lt;ipython-input-44-25e0375ebe18&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed5 = np.where(power_threshed5&gt;4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\n&lt;ipython-input-44-25e0375ebe18&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\n&lt;ipython-input-44-25e0375ebe18&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed6 = np.where(power_threshed6&gt;4,torch.tensor(camimg1[1].detach().reshape(-1)),0)\n\n\n\na2,b2 = net(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.1807078585239272, 0.8192921414760728)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed2,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax3)\nax3.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-12-26-HCAM_edit_dog.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "href": "posts/2_research/2023-12-26-HCAM_edit_dog.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "title": "[CAM]수정본 HCAM_dog",
    "section": "mode 3 만들기 더이상 분리되지 않는 듯",
    "text": "mode 3 만들기 더이상 분리되지 않는 듯\n\n# test2=camimg2[1]-torch.min(camimg2[1])\n\n\nA5 = torch.exp(-0.05*(ybar_threshed6))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n\nwith open('hcam_dog_plt1.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_dog_plt2.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*4).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_dog_plt3.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*8).squeeze().show(ax=ax1)  #MODE3\n(x3).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_dog_plt4.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_dog_plt_mode1.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('hcam_dog_plt_mode1.pkl', 'rb') as file:\n    hcam_dog_plt_mode1 = pickle.load(file)\nplt.show(hcam_dog_plt_mode1)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_dog_plt_mode2.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('hcam_dog_plt_mode2.pkl', 'rb') as file:\n    hcam_dog_plt_mode2 = pickle.load(file)\nplt.show(hcam_dog_plt_mode2)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4 + x32*2).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_dog_plt_mode3.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('hcam_dog_plt_mode3.pkl', 'rb') as file:\n    hcam_dog_plt_mode3 = pickle.load(file)\nplt.show(hcam_dog_plt_mode3)"
  },
  {
    "objectID": "posts/2_research/test.html#mode-1",
    "href": "posts/2_research/test.html#mode-1",
    "title": "test",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.35).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x1).squeeze())\n\n\npower_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\nybar_threshed3 = np.where(power_threshed3&gt;10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\nybar_threshed3 = torch.tensor(ybar_threshed3.reshape(16,16))\n\npower_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\nybar_threshed4 = np.where(power_threshed4&gt;10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\nybar_threshed4 = torch.tensor(ybar_threshed4.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\n&lt;ipython-input-32-292f842a7fbc&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed3 = np.where(power_threshed3&gt;10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\n&lt;ipython-input-32-292f842a7fbc&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\n&lt;ipython-input-32-292f842a7fbc&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed4 = np.where(power_threshed4&gt;10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\n\n\n\na1,b1 = net(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.9992811248320637, 0.0007188751679363709)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 2nd CAM 분리\n\n# test1=camimg1[0]-torch.min(camimg1[0])\nA3 = torch.exp(-0.05*(ybar_threshed3))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1)*Y2-torch.min((x1)*Y2)\n\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1)*Y22-torch.min((x1)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n(x2*0.2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x2).squeeze())\n\n\npower_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\nybar_threshed5 = np.where(power_threshed5&gt;4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\nybar_threshed5 = torch.tensor(ybar_threshed5.reshape(16,16))\n\npower_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\nybar_threshed6 = np.where(power_threshed6&gt;4,torch.tensor(camimg2[1].detach().reshape(-1)),0)\nybar_threshed6 = torch.tensor(ybar_threshed6.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\n&lt;ipython-input-44-4701a2d33601&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed5 = np.where(power_threshed5&gt;4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\n&lt;ipython-input-44-4701a2d33601&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\n&lt;ipython-input-44-4701a2d33601&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed6 = np.where(power_threshed6&gt;4,torch.tensor(camimg2[1].detach().reshape(-1)),0)\n\n\n\na2,b2 = net(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.9965164483511132, 0.003483551648886877)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/test.html#mode-3-만들기",
    "href": "posts/2_research/test.html#mode-3-만들기",
    "title": "test",
    "section": "mode 3 만들기",
    "text": "mode 3 만들기\n\n# test2=camimg2[0]-torch.min(camimg2[0])\n\n\nA5 = torch.exp(-0.05*(ybar_threshed5))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n\nwith open('hcam_cat_plt1.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\nwith open('hcam_cat_plt2.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n    \n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n(x2*0.2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\nwith open('hcam_cat_plt3.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n    \n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*0.8).squeeze().show(ax=ax1)  #MODE3\n(x3*0.2).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_cat_plt4.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt1.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt2.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt3.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt4.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_cat_plt_mode1.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt_mode1.pkl', 'rb') as file:\n    hcam_cat_plt_mode1 = pickle.load(file)\nplt.show(hcam_cat_plt_mode1)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*0.5).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_cat_plt_mode2.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt_mode2.pkl', 'rb') as file:\n    hcam_cat_plt_mode2 = pickle.load(file)\nplt.show(hcam_cat_plt_mode2)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*0.5 + x32*0.5).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('hcam_cat_plt_mode3.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('hcam_cat_plt_mode3.pkl', 'rb') as file:\n    hcam_cat_plt_mode3 = pickle.load(file)\nplt.show(hcam_cat_plt_mode3)"
  },
  {
    "objectID": "posts/2_research/2023-09-16-Grad_CAM_rst.html",
    "href": "posts/2_research/2023-09-16-Grad_CAM_rst.html",
    "title": "[CAM]Grad CAM(Original, Randombox)",
    "section": "",
    "text": "https://github.com/jacobgil/pytorch-grad-cam\nhttps://hygradcam.blogspot.com/2020/11/blog-post.html\nhttps://haystar.tistory.com/72"
  },
  {
    "objectID": "posts/2_research/2023-09-16-Grad_CAM_rst.html#cat",
    "href": "posts/2_research/2023-09-16-Grad_CAM_rst.html#cat",
    "title": "[CAM]Grad CAM(Original, Randombox)",
    "section": "CAT",
    "text": "CAT\n\nx, = first(dls.test_dl([PILImage.create(get_image_files(path)[2])]))\n\n\ngrad_cam = compute_gradcam(lrnr2,x)\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow((grad_cam).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"CAT PART\")\n#\n# dls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\n# ax3.imshow((ybar_threshed2).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n# ax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -&gt; 보라색\n\n\na,b = net(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(0.9999999910101288, 8.989871077326127e-09)"
  },
  {
    "objectID": "posts/2_research/2023-09-16-Grad_CAM_rst.html#dog",
    "href": "posts/2_research/2023-09-16-Grad_CAM_rst.html#dog",
    "title": "[CAM]Grad CAM(Original, Randombox)",
    "section": "DOG",
    "text": "DOG\n\nx, = first(dls.test_dl([PILImage.create(get_image_files(path)[12])]))\n\n\ngrad_cam = compute_gradcam(lrnr2,x)\n\n\nfig, (ax1,ax3) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \n# dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n# ax2.imshow((ybar_threshed).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n# ax2.set_title(\"CAT PART\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow((grad_cam).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -&gt; 보라색\n\n\na,b = net(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(6.72737421709701e-06, 0.9999932726257829)"
  },
  {
    "objectID": "posts/2_research/2023-09-16-Grad_CAM_rst.html#cat-1",
    "href": "posts/2_research/2023-09-16-Grad_CAM_rst.html#cat-1",
    "title": "[CAM]Grad CAM(Original, Randombox)",
    "section": "CAT",
    "text": "CAT\n\nx, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[2])]))\n\n\ngrad_cam = compute_gradcam(lrnr2_r,x)\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow((grad_cam).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"CAT PART\")\n#\n# dls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\n# ax3.imshow((ybar_threshed2).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n# ax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -&gt; 보라색\n\n\na,b = net_r(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(0.9999999956844526, 4.315547465228285e-09)"
  },
  {
    "objectID": "posts/2_research/2023-09-16-Grad_CAM_rst.html#dog-1",
    "href": "posts/2_research/2023-09-16-Grad_CAM_rst.html#dog-1",
    "title": "[CAM]Grad CAM(Original, Randombox)",
    "section": "DOG",
    "text": "DOG\n\nx, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[12])]))\n\n\ngrad_cam = compute_gradcam(lrnr2_r,x)\n\n\nfig, (ax1,ax3) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \n# dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n# ax2.imshow((ybar_threshed).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n# ax2.set_title(\"CAT PART\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow((grad_cam).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -&gt; 보라색\n\n\na,b = net_r(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(1.3188068250511113e-08, 0.9999999868119317)"
  },
  {
    "objectID": "posts/2_research/2023-11-09-CAM_Scorecam_rst.html",
    "href": "posts/2_research/2023-11-09-CAM_Scorecam_rst.html",
    "title": "[CAM]Score CAM(Original, Randombox)",
    "section": "",
    "text": "import torch \nfrom fastai.vision.all import *\nimport cv2\nimport numpy as np\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageFile\nfrom PIL import Image\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom torchvision.utils import save_image\nimport os\nimport torchvision.transforms as transforms\n\n\ndef label_func(f):\n    if f[0].isupper():\n        return 'cat' \n    else: \n        return 'dog' \n\n\npath=Path('original_pet') \nfiles=get_image_files(path)\ndls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) \n\n\npath_r=Path('random_pet_one')   #랜덤박스넣은사진\nfiles_r=get_image_files(path_r)\ndls_r=ImageDataLoaders.from_name_func(path_r,files_r,label_func,item_tfms=Resize(512)) \n\n\n학습\n\nlrnr=cnn_learner(dls,resnet34,metrics=error_rate)\nlrnr.fine_tune(1)\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/fastai/vision/learner.py:288: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.135569\n0.021936\n0.006089\n00:37\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.033069\n0.016387\n0.003383\n00:47\n\n\n\n\n\n\nnet1=lrnr.model[0]\nnet2=lrnr.model[1]\n\n\nnet2 = torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), \n    torch.nn.Flatten(),\n    torch.nn.Linear(512,out_features=2,bias=False))\n\n\nnet=torch.nn.Sequential(net1,net2)\n\n\nlrnr2=Learner(dls,net,metrics=accuracy) \n\n\nlrnr2.fine_tune(5) \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.223036\n1.529223\n0.627199\n00:46\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.122068\n0.748446\n0.734100\n00:46\n\n\n1\n0.115533\n0.599636\n0.785521\n00:47\n\n\n2\n0.066296\n0.100066\n0.966847\n00:46\n\n\n3\n0.029701\n0.049993\n0.981055\n00:46\n\n\n4\n0.009684\n0.052729\n0.978349\n00:46\n\n\n\n\n\n\ninterp = ClassificationInterpretation.from_learner(lrnr2)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlrnr_r=cnn_learner(dls_r,resnet34,metrics=error_rate)\nlrnr_r.fine_tune(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.140315\n0.002963\n0.000677\n00:36\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.000983\n0.000002\n0.000000\n00:47\n\n\n\n\n\n\nnet1_r=lrnr_r.model[0]\nnet2_r=lrnr_r.model[1]\n\n\nnet2_r = torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), \n    torch.nn.Flatten(),\n    torch.nn.Linear(512,out_features=2,bias=False))\n\n\nnet_r=torch.nn.Sequential(net1_r,net2_r)\n\n\nlrnr2_r=Learner(dls_r,net_r,metrics=accuracy) \n\n\nlrnr2_r.fine_tune(5) \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.009831\n0.000473\n1.000000\n00:47\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.000008\n0.000001\n1.000000\n00:47\n\n\n1\n0.000002\n0.000000\n1.000000\n00:47\n\n\n2\n0.000001\n0.000000\n1.000000\n00:46\n\n\n3\n0.000000\n0.000000\n1.000000\n00:46\n\n\n4\n0.000000\n0.000000\n1.000000\n00:46\n\n\n\n\n\n\ninterp_r = ClassificationInterpretation.from_learner(lrnr2_r)\ninterp_r.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass\n\ndef score_cam(model, img, class_index):\n    def forward_hook(module, input, output):\n        module.forward_output = output\n\n    def backward_hook(module, grad_in, grad_out):\n        grad_in_tensor = grad_in[0]\n        module.backward_output = grad_in_tensor\n\n    # target_layer_output = model.layer4  \n    target_layer_output = model[0][-1]\n    target_layer_output.register_forward_hook(forward_hook)\n    target_layer_output.register_backward_hook(backward_hook)\n\n    output = model(img)\n\n    # 클래스 스코어 계산\n    class_score = output[0][class_index]\n\n    # 클래스 스코어를 기반으로 활성화 맵 생성\n    grad_cam = torch.zeros(target_layer_output.forward_output.size()[2:])\n    # grad_cam = grad_cam.to(device)\n\n    class_score.backward()\n    \n    for i in range(target_layer_output.forward_output.size()[2]):\n        for j in range(target_layer_output.forward_output.size()[3]):\n            grad_cam[i, j] = target_layer_output.forward_output[0, class_index, i, j]\n\n    grad_cam = grad_cam.clamp(min=0)\n\n    return grad_cam\n\n\n\n이미지\n\nx_cat, = first(dls.test_dl([PILImage.create(get_image_files(path)[2])]))\nx_cat = x_cat.to('cpu')\nx_cat_r, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[2])]))\nx_cat_r = x_cat_r.to('cpu')\nx_dog, = first(dls.test_dl([PILImage.create(get_image_files(path)[12])]))\nx_dog = x_dog.to('cpu')\nx_dog_r, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[12])]))\nx_dog_r = x_dog_r.to('cpu')\n\n\ntransform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((224, 224)), transforms.ToTensor()])\n\n\nimg_cat = cv2.imread('original_pet/Ragdoll_8.jpg')\nimg_cat = cv2.cvtColor(img_cat, cv2.COLOR_BGR2RGB)\n\nimg_cat = transform(img_cat)\nimg_cat = img_cat.unsqueeze(0)\n\n\nimg_cat_r = cv2.imread('random_pet_one/Ragdoll_8.jpg')\nimg_cat_r = cv2.cvtColor(img_cat_r, cv2.COLOR_BGR2RGB)\n\nimg_cat_r = transform(img_cat_r)\nimg_cat_r = img_cat_r.unsqueeze(0)\n\n\nimg_dog = cv2.imread('original_pet/pomeranian_112.jpg')\nimg_dog = cv2.cvtColor(img_dog, cv2.COLOR_BGR2RGB)\n\nimg_dog = transform(img_dog)\nimg_dog = img_dog.unsqueeze(0)\n\n\nimg_dog_r = cv2.imread('random_pet_one/pomeranian_112.jpg')\nimg_dog_r = cv2.cvtColor(img_dog_r, cv2.COLOR_BGR2RGB)\n\nimg_dog_r = transform(img_dog_r)\nimg_dog_r = img_dog_r.unsqueeze(0)\n\n\n\n결과\n\ngrad_cam_cat = score_cam(lrnr2.model.to('cpu'), img_cat, class_index=0)  # ResNet-34에서는 layer4를 사용\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax1)\nax1.imshow((grad_cam_cat).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='spline36',cmap='magma')\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\ngrad_cam_cat_r = score_cam(lrnr2_r.model.to('cpu'), img_cat_r, class_index=1)  # ResNet-34에서는 layer4를 사용\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax1)\nax1.imshow((grad_cam_cat_r).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='spline36',cmap='magma')\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\ngrad_cam_dog = score_cam(lrnr2.model.to('cpu'), img_dog, class_index=1)  # ResNet-34에서는 layer4를 사용\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax1)\nax1.imshow((grad_cam_dog).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='spline36',cmap='magma')\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\ngrad_cam_dog_r = score_cam(lrnr2_r.model.to('cpu'), img_dog_r, class_index=1)\n\n\ngrad_cam_dog_r\n\ntensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.1389, 0.4988, 0.6678, 0.3931, 0.0012, 0.0000],\n        [0.0000, 0.2094, 0.6792, 0.9307, 0.6193, 0.1842, 0.0000],\n        [0.0000, 0.2330, 0.6546, 0.8194, 0.4580, 0.0776, 0.0000],\n        [0.0000, 0.0000, 0.1763, 0.3683, 0.2077, 0.0029, 0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n       grad_fn=&lt;ClampBackward1&gt;)\n\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax1)\nax1.imshow((grad_cam_dog_r).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='spline36',cmap='magma')\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2024-01-05-CAM_Dataset1.html",
    "href": "posts/2_research/2024-01-05-CAM_Dataset1.html",
    "title": "[CAM]Dataset1",
    "section": "",
    "text": "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad, EigenGradCAM, LayerCAM\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n\n\nimport torch \nfrom fastai.vision.all import *\nfrom fastai.vision import *\nimport cv2\n\n\nimport numpy as np\n\n\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageFile\nfrom PIL import Image\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n\nfrom torchvision import *\nimport os\n\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr"
  },
  {
    "objectID": "posts/2_research/2024-01-05-CAM_Dataset1.html#mode-1",
    "href": "posts/2_research/2024-01-05-CAM_Dataset1.html#mode-1",
    "title": "[CAM]Dataset1",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*10).squeeze().show(ax=ax1)  #MODE1\n(x1*0.1).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=102, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x1).squeeze())\n\n\npower_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\nybar_threshed3 = np.where(power_threshed3&gt;10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\nybar_threshed3 = torch.tensor(ybar_threshed3.reshape(16,16))\n\npower_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\nybar_threshed4 = np.where(power_threshed4&gt;10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\nybar_threshed4 = torch.tensor(ybar_threshed4.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\n&lt;ipython-input-81-292f842a7fbc&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed3 = np.where(power_threshed3&gt;10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\n&lt;ipython-input-81-292f842a7fbc&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\n&lt;ipython-input-81-292f842a7fbc&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed4 = np.where(power_threshed4&gt;10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 2nd CAM 분리\n\n# test1=camimg1[0]-torch.min(camimg1[0])\nA3 = torch.exp(-0.05*(ybar_threshed3))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1)*Y2-torch.min((x1)*Y2)\n\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1)*Y22-torch.min((x1)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12).squeeze().show(ax=ax1)  #MODE1\n(x1*0.1).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.55).squeeze().show(ax=ax1)  #MODE2\n(x2*0.1).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=102, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -&gt; ikl', net2[2].weight, net1(x2).squeeze())\n\n\npower_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\nybar_threshed5 = np.where(power_threshed5&gt;40,torch.tensor(camimg2[0].detach().reshape(-1)),0)\nybar_threshed5 = torch.tensor(ybar_threshed5.reshape(16,16))\n\npower_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\nybar_threshed6 = np.where(power_threshed6&gt;40,torch.tensor(camimg2[1].detach().reshape(-1)),0)\nybar_threshed6 = torch.tensor(ybar_threshed6.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\n&lt;ipython-input-102-ba6e482cf5c4&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed5 = np.where(power_threshed5&gt;40,torch.tensor(camimg2[0].detach().reshape(-1)),0)\n&lt;ipython-input-102-ba6e482cf5c4&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\n&lt;ipython-input-102-ba6e482cf5c4&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed6 = np.where(power_threshed6&gt;40,torch.tensor(camimg2[1].detach().reshape(-1)),0)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2024-01-05-CAM_Dataset1.html#mode-3-만들기",
    "href": "posts/2_research/2024-01-05-CAM_Dataset1.html#mode-3-만들기",
    "title": "[CAM]Dataset1",
    "section": "mode 3 만들기",
    "text": "mode 3 만들기\n\n# test2=camimg2[0]-torch.min(camimg2[0])\n\n\nA5 = torch.exp(-0.05*(ybar_threshed5))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nimport pickle\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n\nwith open('CALTECH_101_hcam_cat_plt1.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*-0.5).squeeze().show(ax=ax1)  #MODE1\n(x1*0.1).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\nwith open('CALTECH_101_hcam_cat_plt2.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n    \n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.33).squeeze().show(ax=ax1)  #MODE2\n(x2*0.1).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\nwith open('CALTECH_101_hcam_cat_plt3.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n    \n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*0.22).squeeze().show(ax=ax1)  #MODE3\n(x3*0.1).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('CALTECH_101_hcam_cat_plt4.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_hcam_cat_plt1.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_hcam_cat_plt2.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_hcam_cat_plt3.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_hcam_cat_plt4.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*-0.5).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('CALTECH_101_hcam_cat_plt_mode1.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_hcam_cat_plt_mode1.pkl', 'rb') as file:\n    hcam_cat_plt_mode1 = pickle.load(file)\nplt.show(hcam_cat_plt_mode1)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*-0.5 + x22*0.33).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('CALTECH_101_hcam_cat_plt_mode2.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_hcam_cat_plt_mode2.pkl', 'rb') as file:\n    hcam_cat_plt_mode2 = pickle.load(file)\nplt.show(hcam_cat_plt_mode2)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*-0.5 + x22*0.33 + x32*0.22).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE1+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('CALTECH_101_hcam_cat_plt_mode3.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_hcam_cat_plt_mode3.pkl', 'rb') as file:\n    hcam_cat_plt_mode3 = pickle.load(file)\nplt.show(hcam_cat_plt_mode3)"
  },
  {
    "objectID": "posts/2_research/2024-01-05-CAM_Dataset1.html#시도",
    "href": "posts/2_research/2024-01-05-CAM_Dataset1.html#시도",
    "title": "[CAM]Dataset1",
    "section": "시도",
    "text": "시도\n\nx, = first(dls.test_dl([PILImage.create(get_image_files(path)[20])]))\nx = x.to('cpu')\ndls.train.decode((x,))[0].squeeze().show()\n\n\n\n\n\n\n\n\n\ncam_gradcam = gradcam(input_tensor=x,targets=None)\n\n\ncam_hirescam = hirescam(input_tensor=x,targets=None)\n\n\ncam_scorecam = scorecam(input_tensor=x,targets=None)\n\n100%|██████████| 32/32 [00:23&lt;00:00,  1.38it/s]\n\n\n\ncam_gradcamplusplus = gradcamplusplus(input_tensor=x,targets=None)\n\n\ncam_ablationcam = ablationcam(input_tensor=x,targets=None)\n\n100%|██████████| 16/16 [00:26&lt;00:00,  1.63s/it]\n\n\n\ncam_xgradcam = xgradcam(input_tensor=x,targets=None)\n\n\ncam_eigencam = eigencam(input_tensor=x,targets=None)\n\n\ncam_fullgrad = fullgrad(input_tensor=x,targets=None)\n\n\ncam_eigengradcam = eigengradcam(input_tensor=x,targets=None)\n\n\ncam_layercam = layercam(input_tensor=x,targets=None)\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_hirescam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART HiResCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_hirescam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART HiResCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_scorecam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART ScoreCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_scorecam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART ScoreCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAMPlusPlus\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAMPlusPlus\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_ablationcam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART AblationCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_ablationcam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART AblationCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_xgradcam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART XGradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_xgradcam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART XGradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_eigencam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART EigenCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_eigencam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART EigenCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_fullgrad.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART FullGrad\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_fullgrad.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART FullGrad\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_layercam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART LayerCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_layercam.squeeze(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART LayerCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, ((ax1,ax2,ax3,ax4),\n      (ax5,ax6,ax7,ax8),\n      (ax9,ax10,ax11,ax12)) = plt.subplots(3,4) \nplt.title('CALTECH 101 Dataset')\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(cam_gradcam.squeeze(), alpha=0.7)\nax1.set_title(\"GradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_hirescam.squeeze(), alpha=0.7)\nax2.set_title(\"HiResCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(cam_scorecam.squeeze(), alpha=0.7)\nax3.set_title(\"ScoreCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax4)\nax4.imshow(cam_gradcamplusplus.squeeze(), alpha=0.7)\nax4.set_title(\"GradCAMPlusPlus\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax5)\nax5.imshow(cam_ablationcam.squeeze(), alpha=0.7)\nax5.set_title(\"AblationCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax6)\nax6.imshow(cam_xgradcam.squeeze(), alpha=0.7)\nax6.set_title(\"XGradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax7)\nax7.imshow(cam_eigencam.squeeze(), alpha=0.7)\nax7.set_title(\"EigenCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax8)\nax8.imshow(cam_fullgrad.squeeze(), alpha=0.7)\nax8.set_title(\"FullGrad\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax9)\nax9.imshow(cam_eigengradcam.squeeze(), alpha=0.7)\nax9.set_title(\"EigenGradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax10)\nax10.imshow(cam_layercam.squeeze(), alpha=0.7)\nax10.set_title(\"LayerCAM\")\n\n(dls.train.decode((x,))[0].squeeze()*0).show(ax=ax11)\n(dls.train.decode((x,))[0].squeeze()*0).show(ax=ax12)\n#\nfig.set_figwidth(20)            \nfig.set_figheight(20)\nfig.tight_layout()\n\nwith open('CALTECH_101_fig_randombox_plt.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_fig_randombox_plt.pkl', 'rb') as file:\n    fig_randombox_plt = pickle.load(file)\nfig_randombox_plt.show()"
  },
  {
    "objectID": "posts/2_research/2024-01-05-CAM_Dataset1.html#mode-1-1",
    "href": "posts/2_research/2024-01-05-CAM_Dataset1.html#mode-1-1",
    "title": "[CAM]Dataset1",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x_r,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x_r.squeeze().to('cpu')*Y1-torch.min(x_r.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x_r.squeeze().to('cpu')*Y12-torch.min(x_r.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_r,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*-1.5).squeeze().show(ax=ax1)  #MODE1\n(x1*0.7).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1_r.to('cpu')\nnet2_r.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=23, bias=False)\n)\n\n\n\ncamimg1_r = torch.einsum('ij,jkl -&gt; ikl', net2_r[2].weight, net1_r(x1).squeeze())\n\n\npower_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1_r[0].detach().reshape(-1))**2)))\nybar_threshed3 = np.where(power_threshed3&gt;20,torch.tensor(camimg1_r[0].detach().reshape(-1)),0)\nybar_threshed3 = torch.tensor(ybar_threshed3.reshape(16,16))\n\npower_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1_r[1].detach().reshape(-1))**2)))\nybar_threshed4 = np.where(power_threshed4&gt;20,torch.tensor(camimg1_r[1].detach().reshape(-1)),0)\nybar_threshed4 = torch.tensor(ybar_threshed4.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1_r[0].detach().reshape(-1))**2)))\n&lt;ipython-input-724-c83bfb4d70dd&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed3 = np.where(power_threshed3&gt;20,torch.tensor(camimg1_r[0].detach().reshape(-1)),0)\n&lt;ipython-input-724-c83bfb4d70dd&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1_r[1].detach().reshape(-1))**2)))\n&lt;ipython-input-724-c83bfb4d70dd&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed4 = np.where(power_threshed4&gt;20,torch.tensor(camimg1_r[1].detach().reshape(-1)),0)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x_r,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 2nd CAM 분리\n\n# test1=camimg1[0]-torch.min(camimg1[0])\nA3 = torch.exp(-0.05*(ybar_threshed3))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1)*Y2-torch.min((x1)*Y2)\n\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1)*Y22-torch.min((x1)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_r,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*-1.5).squeeze().show(ax=ax1)  #MODE1\n(x1*0.7).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.7).squeeze().show(ax=ax1)  #MODE2\n(x2*0.5).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1_r.to('cpu')\nnet2_r.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=23, bias=False)\n)\n\n\n\ncamimg2_r = torch.einsum('ij,jkl -&gt; ikl', net2_r[2].weight, net1_r(x2).squeeze())\n\n\npower_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2_r[0].detach().reshape(-1))**2)))\nybar_threshed5 = np.where(power_threshed5&gt;10,torch.tensor(camimg2_r[0].detach().reshape(-1)),0)\nybar_threshed5 = torch.tensor(ybar_threshed5.reshape(16,16))\n\npower_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2_r[1].detach().reshape(-1))**2)))\nybar_threshed6 = np.where(power_threshed6&gt;10,torch.tensor(camimg2_r[1].detach().reshape(-1)),0)\nybar_threshed6 = torch.tensor(ybar_threshed6.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2_r[0].detach().reshape(-1))**2)))\n&lt;ipython-input-746-f3a70d6c47ba&gt;:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed5 = np.where(power_threshed5&gt;10,torch.tensor(camimg2_r[0].detach().reshape(-1)),0)\n&lt;ipython-input-746-f3a70d6c47ba&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2_r[1].detach().reshape(-1))**2)))\n&lt;ipython-input-746-f3a70d6c47ba&gt;:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed6 = np.where(power_threshed6&gt;10,torch.tensor(camimg2_r[1].detach().reshape(-1)),0)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x_r,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax3)\nax3.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2024-01-05-CAM_Dataset1.html#mode-3-만들기-1",
    "href": "posts/2_research/2024-01-05-CAM_Dataset1.html#mode-3-만들기-1",
    "title": "[CAM]Dataset1",
    "section": "mode 3 만들기",
    "text": "mode 3 만들기\n\n# test2=camimg2[0]-torch.min(camimg2[0])\n\n\nA5 = torch.exp(-0.05*(ybar_threshed5))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_r,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n\nwith open('CALTECH_101_random_hcam_cat_plt1.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*-1.5).squeeze().show(ax=ax1)  #MODE1\n(x1*0.7).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\nwith open('CALTECH_101_random_hcam_cat_plt2.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n    \n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.7).squeeze().show(ax=ax1)  #MODE2\n(x2*0.5).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\nwith open('CALTECH_101_random_hcam_cat_plt3.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n    \n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*0.7).squeeze().show(ax=ax1)  #MODE3\n(x3*0.4).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('CALTECH_101_random_hcam_cat_plt4.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_random_hcam_cat_plt1.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_random_hcam_cat_plt2.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_random_hcam_cat_plt3.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_random_hcam_cat_plt4.pkl', 'rb') as file:\n    hcam_cat_plt = pickle.load(file)\nplt.show(hcam_cat_plt)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*-1.5).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('CALTECH_101_random_hcam_cat_plt_mode1.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_random_hcam_cat_plt_mode1.pkl', 'rb') as file:\n    hcam_cat_plt_mode1 = pickle.load(file)\nplt.show(hcam_cat_plt_mode1)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*-1.5 + x22*0.7).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('CALTECH_101_random_hcam_cat_plt_mode2.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_random_hcam_cat_plt_mode2.pkl', 'rb') as file:\n    hcam_cat_plt_mode2 = pickle.load(file)\nplt.show(hcam_cat_plt_mode2)\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*-1.5 + x22*0.7 + x32*0.4).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE1+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nwith open('CALTECH_101_random_hcam_cat_plt_mode3.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_random_hcam_cat_plt_mode3.pkl', 'rb') as file:\n    hcam_cat_plt_mode3 = pickle.load(file)\nplt.show(hcam_cat_plt_mode3)"
  },
  {
    "objectID": "posts/2_research/2024-01-05-CAM_Dataset1.html#figure_randombox",
    "href": "posts/2_research/2024-01-05-CAM_Dataset1.html#figure_randombox",
    "title": "[CAM]Dataset1",
    "section": "Figure_Randombox",
    "text": "Figure_Randombox\n\nfig, ((ax1,ax2,ax3,ax4),\n      (ax5,ax6,ax7,ax8),\n      (ax9,ax10,ax11,ax12)) = plt.subplots(3,4) \nplt.title('Randombox')\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax1)\nax1.imshow(cam_gradcam_randombox.squeeze(), alpha=0.7)\nax1.set_title(\"GradCAM\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_hirescam_randombox.squeeze(), alpha=0.7)\nax2.set_title(\"HiResCAM\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax3)\nax3.imshow(cam_scorecam_randombox.squeeze(), alpha=0.7)\nax3.set_title(\"ScoreCAM\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax4)\nax4.imshow(cam_gradcamplusplus_randombox.squeeze(), alpha=0.7)\nax4.set_title(\"GradCAMPlusPlus\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax5)\nax5.imshow(cam_ablationcam_randombox.squeeze(), alpha=0.7)\nax5.set_title(\"AblationCAM\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax6)\nax6.imshow(cam_xgradcam_randombox.squeeze(), alpha=0.7)\nax6.set_title(\"XGradCAM\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax7)\nax7.imshow(cam_eigencam_randombox.squeeze(), alpha=0.7)\nax7.set_title(\"EigenCAM\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax8)\nax8.imshow(cam_fullgrad_randombox.squeeze(), alpha=0.7)\nax8.set_title(\"FullGrad\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax9)\nax9.imshow(cam_eigengradcam_randombox.squeeze(), alpha=0.7)\nax9.set_title(\"EigenGradCAM\")\n#\ndls.train.decode((x_r,))[0].squeeze().show(ax=ax10)\nax10.imshow(cam_layercam_randombox.squeeze(), alpha=0.7)\nax10.set_title(\"LayerCAM\")\n#\n(dls.train.decode((x_r,))[0].squeeze()*0).show(ax=ax11)\n(dls.train.decode((x_r,))[0].squeeze()*0).show(ax=ax12)\n#\nfig.set_figwidth(20)            \nfig.set_figheight(20)\nfig.tight_layout()\n\nwith open('CALTECH_101_random_fig_randombox_plt.pkl', 'wb') as file:\n    pickle.dump(fig, file)\n\n\n\n\n\n\n\n\n\nwith open('CALTECH_101_random_fig_randombox_plt.pkl', 'rb') as file:\n    fig_randombox_plt = pickle.load(file)\nfig_randombox_plt.show()"
  },
  {
    "objectID": "posts/2_research/2023-09-02-CAM_original.html",
    "href": "posts/2_research/2023-09-02-CAM_original.html",
    "title": "[CAM]Original CAM",
    "section": "",
    "text": "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html\nhttps://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html\n\nimport\n\nimport torch \nfrom fastai.vision.all import *\nimport cv2\nimport numpy as np\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageFile\nfrom PIL import Image\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom torchvision.utils import save_image\nimport os\n\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\n\ndef label_func(f):\n    if f[0].isupper():\n        return 'cat' \n    else: \n        return 'dog' \n\n\n\n원본 CAM\n\n# os.mkdir(\"original_pet\")\n\n\nfor i in range(len(path.ls())) :\n    img = PILImage.create(get_image_files(path)[i])\n    img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n    (w, h) = (img.shape[0], img.shape[1])\n    # a = random.uniform(0, w*0.7)\n    # b = random.uniform(0, h*0.9)\n    shape = [(a, b), (a+100, b+50)]\n    # font = ImageFont.truetype(\"DejaVuSans.ttf\", round(h*0.08))\n    name = str(list(path.ls())[i]).split('/')[-1]\n    fname = name.split('.')[-1]\n    if name[0].isupper() == True :\n        img1 = ImageDraw.Draw(img)  \n        # img1.rectangle(shape, fill =\"white\", outline =\"black\")\n        # ImageDraw.Draw(img).text((a, b), 'CAT', (0,0,0), font=font)\n        img.save(\"original_pet/\"+name)\n    else: \n        img1 = ImageDraw.Draw(img)  \n        # img1.rectangle(shape, fill =\"black\", outline =\"black\")\n        # ImageDraw.Draw(img).text((a, b), 'DOG', (255,255,255), font=font)\n        img.save(\"original_pet/\"+name)\n\n\npath_o=Path('original_pet')   #랜덤박스넣은사진\n\n\nfiles_o=get_image_files(path_o)\n\n\ndls_o=ImageDataLoaders.from_name_func(path_o,files_o,label_func,item_tfms=Resize(512)) \n\n\nlrnr_o1=cnn_learner(dls_o,resnet34,metrics=error_rate)\nlrnr_o1.fine_tune(1)\n\n\nnet_o1=lrnr_o1.model[0]\nnet_o2=lrnr_o1.model[1] \n\n\nnet_o2 = torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), \n    torch.nn.Flatten(),\n    torch.nn.Linear(512,out_features=2,bias=False))\n\n\nnet_o=torch.nn.Sequential(net_o1,net_o2)\n\n\nlrnr_o2=Learner(dls_o,net_o,metrics=accuracy) \n\n\nlrnr_o2.fine_tune(10) \n\n\ninterp_o = ClassificationInterpretation.from_learner(lrnr_o2)\ninterp_o.plot_confusion_matrix()\n\n\nx_o, = first(dls_o.test_dl([PILImage.create(get_image_files(path_o)[7389])]))\n\n\ncamimg_o = torch.einsum('ij,jkl -&gt; ikl', net_o2[2].weight, net_o1(x).squeeze())\n\n\n# 서연 수정 code\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_o.train.decode((x_o,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg_o[0].to(\"cpu\").detach(),alpha=0.7,extent=(0,511,511,0),interpolation='bilinear',cmap='bone')\n#\ndls_r.train.decode((x_o,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg_o[1].to(\"cpu\").detach(),alpha=0.7,extent=(0,511,511,0),interpolation='bilinear',cmap='bone')\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x_o, = first(dls_o.test_dl([PILImage.create(get_image_files(path_o)[k])]))\n        camimg_o = torch.einsum('ij,jkl -&gt; ikl', net_o2[2].weight, net_o1(x_o).squeeze())\n        a_o,b_o = net_r(x_o).tolist()[0]\n        catprob, dogprob = np.exp(a_o)/ (np.exp(a_o)+np.exp(b_o)) ,  np.exp(b_o)/ (np.exp(a_o)+np.exp(b_o)) \n        if catprob&gt;dogprob: \n            dls_o.train.decode((x_o,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(camimg_o[0].to(\"cpu\").detach(),alpha=0.7,extent=(0,512,512,0),interpolation='bilinear',cmap='bone')\n            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n        else: \n            dls_o.train.decode((x_o,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(camimg_o[1].to(\"cpu\").detach(),alpha=0.7,extent=(0,512,512,0),interpolation='bilinear',cmap='bone')\n            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x_o, = first(dls_o.test_dl([PILImage.create(get_image_files(path_o)[k])]))\n        camimg_o = torch.einsum('ij,jkl -&gt; ikl', net_o2[2].weight, net_o1(x).squeeze())\n        a_o,b_o = net_o(x_o).tolist()[0]\n        catprob, dogprob = np.exp(a_o)/ (np.exp(a_o)+np.exp(b_o)) ,  np.exp(b_o)/ (np.exp(a_o)+np.exp(b_o))\n        if catprob&gt;dogprob: \n            test=camimg_o[0]-torch.min(camimg_o[0])\n            A1=torch.exp(-0.1*test)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x_o.squeeze().to('cpu')*Y1-torch.min(x_o.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n        else: \n            test=camimg_o[1]-torch.min(camimg_o[1])\n            A1=torch.exp(-0.1*test)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x_o.squeeze().to('cpu')*Y1-torch.min(x_o.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n.mat파일 있나 확인\n\n\nfor i in range(len(path_o.ls())) :\n    img = PILImage.create(get_image_files(path_o)[i])\n    img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n    name = str(list(path_o.ls())[i]).split('/')[-1]\n    fname = name.split('.')[-1]\n    if fname!=\"jpg\" : \n        print(name)\n    else : pass\n\n\nx_o, = first(dls_o.test_dl([PILImage.create(get_image_files(path_o)[1])]))\ncamimg_o = torch.einsum('ij,jkl -&gt; ikl', net_o2[2].weight, net_o1(x).squeeze())\na_o,b_o = net_o(x_o).tolist()[0]\ncatprob_o, dogprob_o = np.exp(a_o)/ (np.exp(a_o)+np.exp(b_o)) ,  np.exp(b_o)/ (np.exp(a_o)+np.exp(b_o))\nif catprob_o&gt;dogprob_o: \n    test_o=camimg_o[0]-torch.min(camimg_o[0])\n    A1_o=torch.exp(-0.01*test_o)\n    X1_o=np.array(A1_o.to(\"cpu\").detach(),dtype=np.float32)\n    Y1_o=torch.Tensor(cv2.resize(X1_o,(512,512),interpolation=cv2.INTER_LINEAR))\n    x1_o=x_o.squeeze().to('cpu')*Y1_o-torch.min(x_o.squeeze().to('cpu'))*Y1_o\n    (x1_o*0.25).squeeze().show()\nelse: \n        test_o=camimg_o[1]-torch.min(camimg_o[1])\n        A1_o=torch.exp(-0.01*test_o)\n        X1_o=np.array(A1_o.to(\"cpu\").detach(),dtype=np.float32)\n        Y1_o=torch.Tensor(cv2.resize(X1_o,(512,512),interpolation=cv2.INTER_LINEAR))\n        x1_o=x_o.squeeze().to('cpu')*Y1-torch.min(x_o.squeeze().to('cpu'))*Y1_o\n        (x1_o*0.25).squeeze().show()\n\n\n# #저장 참고\n# np_arr = np.array(tensor, dtype=np.uint8)\n# img = PIL.Image.fromarray(np_arr)\n# img.save('path')\n\n\n# name = str(list(path.ls())[1]).split('/')[-1]\n# res1=(x1*0.35).squeeze()\n# res1.show()\n# save_image(res1, \"pet3_mode1_res/\"+name)\n#res1.save(\"pet3_mode1_res/\"+name)"
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html",
    "title": "[CAM]HCAM random",
    "section": "",
    "text": "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html\nhttps://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html\nCNN으로 이미지 분류를 할 때 마지막 단의 출력값이 클수록 softmax를 거친 뒤 1에 가까워 진다면, 입력 이미지의 label에 해당하는 채널의 마지막 conv layer의 출력이 크게 하는 클래스에 크게 반응했다는 것이 됌..!"
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html#thresholding-point",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html#thresholding-point",
    "title": "[CAM]HCAM random",
    "section": "thresholding point",
    "text": "thresholding point\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[k])]))\n        camimg = torch.einsum('ij,jkl -&gt; ikl', net_2[2].weight, net_1(x).squeeze())\n        a,b = net_r(x).tolist()[0]\n        catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        power_threshed=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[0].detach().reshape(-1))**2)))\n        ybar_threshed = np.where(power_threshed&gt;2000,torch.tensor(camimg[0].detach().reshape(-1)),0)\n        power_threshed2=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[1].detach().reshape(-1))**2)))\n        ybar_threshed2 = np.where(power_threshed&gt;2000,torch.tensor(camimg[1].detach().reshape(-1)),0)\n        ybar_threshed = torch.tensor(ybar_threshed.reshape(16,16))\n        ybar_threshed2 = torch.tensor(ybar_threshed2.reshape(16,16))\n        if catprob&gt;dogprob: \n            # test=camimg[0]-torch.min(camimg[0])\n            A1=torch.exp(-0.1*ybar_threshed)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n        else: \n            # test=camimg[1]-torch.min(camimg[1])\n            A1=torch.exp(-0.1*ybar_threshed2)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[0].detach().reshape(-1))**2)))\n&lt;ipython-input-16-98bb7127f6af&gt;:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed = np.where(power_threshed&gt;2000,torch.tensor(camimg[0].detach().reshape(-1)),0)\n&lt;ipython-input-16-98bb7127f6af&gt;:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed2=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[1].detach().reshape(-1))**2)))\n&lt;ipython-input-16-98bb7127f6af&gt;:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed2 = np.where(power_threshed&gt;2000,torch.tensor(camimg[1].detach().reshape(-1)),0)\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html#ebayes-x",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html#ebayes-x",
    "title": "[CAM]HCAM random",
    "section": "ebayes X",
    "text": "ebayes X\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[k])]))\n        camimg = torch.einsum('ij,jkl -&gt; ikl', net_2[2].weight, net_1(x).squeeze())\n        a,b = net_r(x).tolist()[0]\n        catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n        if catprob&gt;dogprob: \n            test=camimg[0]-torch.min(camimg[0])\n            A1=torch.exp(-0.1*test)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n        else: \n            test=camimg[1]-torch.min(camimg[1])\n            A1=torch.exp(-0.1*test)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-1",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-1",
    "title": "[CAM]HCAM random",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.35).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet_1.to('cpu')\nnet_2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -&gt; ikl', net_2[2].weight, net_1(x1).squeeze())\n\n\na1,b1 = net_r(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.9505286776057943, 0.04947132239420577)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 2nd CAM 분리\n\ntest1=camimg1[0]-torch.min(camimg1[0])\nA3 = torch.exp(-0.03*(test1))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls_r.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls_r.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\n\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\n\nx2=(x1*0.2)*Y2-torch.min((x1*0.2)*Y2)\n\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\n\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\n\nx22=(x1*0.2)*Y22-torch.min((x1*0.2)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*4).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet_1.to('cpu')\nnet_2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -&gt; ikl', net_2[2].weight, net_1(x2).squeeze())\n\n\na2,b2 = net_r(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.538050281567858, 0.461949718432142)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-3-만들기",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-3-만들기",
    "title": "[CAM]HCAM random",
    "section": "mode 3 만들기",
    "text": "mode 3 만들기\n\ntest2=camimg2[0]-torch.min(camimg2[0])\n\n\nA5 = torch.exp(-0.05*(test2))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*4).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*8).squeeze().show(ax=ax1)  #MODE3\n(x3).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4 + x32*2).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-1-1",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-1-1",
    "title": "[CAM]HCAM random",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed2))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.3).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet_1.to('cpu')\nnet_2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -&gt; ikl', net_2[2].weight, net_1(x1).squeeze())\n\n\na1,b1 = net_r(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.001180554413474461, 0.9988194455865255)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 2nd CAM 분리\n\ntest1=camimg1[1]-torch.min(camimg1[1])\nA3 = torch.exp(-0.05*(test1))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls_r.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls_r.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n# res \nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1*0.2)*Y2-torch.min((x1*0.2)*Y2)\n#\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1*0.2)*Y22-torch.min((x1*0.2)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*3).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet_1.to('cpu')\nnet_2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -&gt; ikl', net_2[2].weight, net_1(x2).squeeze())\n\n\na2,b2 = net_r(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.48014948791345896, 0.5198505120865412)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "title": "[CAM]HCAM random",
    "section": "mode 3 만들기 더이상 분리되지 않는 듯",
    "text": "mode 3 만들기 더이상 분리되지 않는 듯\n\ntest2=camimg2[1]-torch.min(camimg2[1])\n\n\nA5 = torch.exp(-0.05*(test2))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*4).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*8).squeeze().show(ax=ax1)  #MODE3\n(x3).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4 + x32*2).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "2_research.html",
    "href": "2_research.html",
    "title": "Research",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 5, 2024\n\n\n[CAM]Dataset1\n\n\nSEOYEON CHOI\n\n\n\n\nDec 26, 2023\n\n\n[CAM]수정본 HCAM_dog\n\n\nSEOYEON CHOI\n\n\n\n\nDec 26, 2023\n\n\ntest\n\n\nSEOYEON CHOI\n\n\n\n\nDec 26, 2023\n\n\n[CAM]수정본 HCAM_cat\n\n\nSEOYEON CHOI\n\n\n\n\nNov 29, 2023\n\n\n[CAM]HCAM Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nNov 9, 2023\n\n\n[CAM]Score CAM(Original, Randombox)\n\n\nSEOYEON CHOI\n\n\n\n\nOct 18, 2023\n\n\n[CAM]Other Methods\n\n\nSEOYEON CHOI\n\n\n\n\nSep 21, 2023\n\n\n[CAM]chest xray\n\n\nSEOYEON CHOI\n\n\n\n\nSep 19, 2023\n\n\n[CAM]HCAM original\n\n\nSEOYEON CHOI\n\n\n\n\nSep 16, 2023\n\n\n[CAM]Grad CAM(Original, Randombox)\n\n\nSEOYEON CHOI\n\n\n\n\nSep 15, 2023\n\n\n[CAM]Original CAM\n\n\nSEOYEON CHOI\n\n\n\n\nSep 14, 2023\n\n\n[CAM]Image Download\n\n\nSEOYEON CHOI\n\n\n\n\nAug 28, 2023\n\n\n[CAM]Original CAM\n\n\nSEOYEON CHOI\n\n\n\n\nAug 28, 2023\n\n\n[CAM]HCAM random\n\n\nSEOYEON CHOI\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Main_Blog",
      "**Research**",
      "**Research**"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog provides information on HCAM."
  }
]