[
  {
    "objectID": "4_figure.html",
    "href": "4_figure.html",
    "title": "Figure",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "2_research.html",
    "href": "2_research.html",
    "title": "Research",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nNov 29, 2023\n\n\n[CAM]HCAM Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nNov 9, 2023\n\n\n[CAM]Score CAM(Original, Randombox)\n\n\nSEOYEON CHOI\n\n\n\n\nOct 31, 2023\n\n\n[CAM]other methods chest xray\n\n\nSEOYEON CHOI\n\n\n\n\nOct 18, 2023\n\n\n[CAM]Other Methods\n\n\nSEOYEON CHOI\n\n\n\n\nSep 23, 2023\n\n\n[CAM]HCAM_ebayes\n\n\nSEOYEON CHOI\n\n\n\n\nSep 21, 2023\n\n\n[CAM]chest xray\n\n\nSEOYEON CHOI\n\n\n\n\nSep 19, 2023\n\n\n[CAM]HCAM original\n\n\nSEOYEON CHOI\n\n\n\n\nSep 16, 2023\n\n\n[CAM]Grad CAM(Original, Randombox)\n\n\nSEOYEON CHOI\n\n\n\n\nSep 15, 2023\n\n\n[CAM]Original CAM\n\n\nSEOYEON CHOI\n\n\n\n\nAug 28, 2023\n\n\n[CAM]HCAM random\n\n\nSEOYEON CHOI\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html",
    "title": "[CAM]Other Methods",
    "section": "",
    "text": "https://pythonrepo.com/repo/jacobgil-pytorch-grad-cam\nhttps://github.com/jacobgil/pytorch-grad-cam"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_gradcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_gradcam",
    "title": "[CAM]Other Methods",
    "section": "Cat_GradCAM",
    "text": "Cat_GradCAM\n\nCat_GradCAM_Original\n\ngradcam_original = GradCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_gradcam_original = gradcam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_gradcam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9dbc3c4340>\n\n\n\n\n\n\n\nCat_GradCAM_Randombox\n\ngradcam_randombox = GradCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_gradcam_randombox = gradcam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_gradcam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9f209a88e0>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_gradcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_gradcam",
    "title": "[CAM]Other Methods",
    "section": "Dog_GradCAM",
    "text": "Dog_GradCAM\n\nDog_GradCAM_Original\n\ncam_dog_gradcam_original = gradcam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_gradcam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9f206d0e80>\n\n\n\n\n\n\n\nDog_GradCAM_Randombox\n\ncam_dog_gradcam_randombox = gradcam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_gradcam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9f0ccfa550>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_hirescam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_hirescam",
    "title": "[CAM]Other Methods",
    "section": "Cat_HiResCAM",
    "text": "Cat_HiResCAM\n\nCat_HiResCAM_Original\n\nhirescam_original = HiResCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_hirescam_original = hirescam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_hirescam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9f0cc68a60>\n\n\n\n\n\n\n\nCat_HiResCAM_Randombox\n\nhirescam_randombox = HiResCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_hirescam_randombox = hirescam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_hirescam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9f0cc48e20>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_hirescam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_hirescam",
    "title": "[CAM]Other Methods",
    "section": "Dog_HiResCAM",
    "text": "Dog_HiResCAM\n\nDog_HiResCAM_Original\n\ncam_dog_hirescam_original = hirescam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_hirescam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9f0cbe6f70>\n\n\n\n\n\n\n\nDog_HiResCAM_Random\n\ncam_dog_hirescam_randombox = hirescam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_hirescam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9f0cb30d30>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_scorecam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_scorecam",
    "title": "[CAM]Other Methods",
    "section": "Cat_ScoreCAM",
    "text": "Cat_ScoreCAM\n\nCat_ScoreCAM_Original\n\nscorecam_original = ScoreCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_scorecam_original = scorecam_original(input_tensor=x_cat,targets=None)\n\n100%|██████████| 32/32 [00:26<00:00,  1.23it/s]\n100%|██████████| 32/32 [00:25<00:00,  1.27it/s]\n100%|██████████| 32/32 [00:25<00:00,  1.26it/s]\n\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_scorecam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9f0cb143a0>\n\n\n\n\n\n\n\nCat_ScoreCAM_Randombox\n\nscorecam_randombox = ScoreCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_scorecam_randombox = scorecam_randombox(input_tensor=x_cat_r,targets=None)\n\n100%|██████████| 32/32 [00:25<00:00,  1.25it/s]\n100%|██████████| 32/32 [00:25<00:00,  1.26it/s]\n100%|██████████| 32/32 [00:25<00:00,  1.26it/s]\n\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_scorecam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d9025d040>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_scorecam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_scorecam",
    "title": "[CAM]Other Methods",
    "section": "Dog_ScoreCAM",
    "text": "Dog_ScoreCAM\n\nDog_ScoreCAM_Original\n\ncam_dog_scorecam_original = scorecam_original(input_tensor=x_dog,targets=None)\n\n100%|██████████| 32/32 [00:25<00:00,  1.25it/s]\n100%|██████████| 32/32 [00:25<00:00,  1.27it/s]\n100%|██████████| 32/32 [00:24<00:00,  1.30it/s]\n\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_scorecam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9dbc0a6040>\n\n\n\n\n\n\n\nDog_ScoreCAM_Randombox\n\ncam_dog_scorecam_randombox = scorecam_randombox(input_tensor=x_dog_r,targets=None)\n\n100%|██████████| 32/32 [00:24<00:00,  1.30it/s]\n100%|██████████| 32/32 [00:24<00:00,  1.30it/s]\n100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_scorecam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d90101130>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_gradcamplusplus",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_gradcamplusplus",
    "title": "[CAM]Other Methods",
    "section": "Cat_GradCAMPlusPlus",
    "text": "Cat_GradCAMPlusPlus\n\nCat_GradCAMPlusPlus_Original\n\ngradcamplusplus_original = GradCAMPlusPlus(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_gradcamplusplus_original = gradcamplusplus_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_gradcamplusplus_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d6cf9e6d0>\n\n\n\n\n\n\n\nCat_GradCAMPlusPlus_Randombox\n\ngradcamplusplus_randombox = GradCAMPlusPlus(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_gradcamplusplus_randombox = gradcamplusplus_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_gradcamplusplus_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d6cf0fbb0>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_gradcamplusplus",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_gradcamplusplus",
    "title": "[CAM]Other Methods",
    "section": "Dog_GradCAMPlusPlus",
    "text": "Dog_GradCAMPlusPlus\n\nDog_GradCAMPlusPlus_Original\n\ncam_dog_gradcamplusplus_original = gradcamplusplus_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_gradcamplusplus_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d6ce8b100>\n\n\n\n\n\n\n\nDog_GradCAMPlusPlus_Randombox\n\ncam_dog_gradcamplusplus_randombox = gradcamplusplus_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_gradcamplusplus_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9f280609d0>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_ablationcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_ablationcam",
    "title": "[CAM]Other Methods",
    "section": "Cat_AblationCAM",
    "text": "Cat_AblationCAM\n\nCat_AblationCAM_Original\n\nablationcam_original = AblationCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_ablationcam_original = ablationcam_original(input_tensor=x_cat,targets=None)\n\n100%|██████████| 16/16 [00:28<00:00,  1.75s/it]\n100%|██████████| 16/16 [00:28<00:00,  1.78s/it]\n100%|██████████| 16/16 [00:27<00:00,  1.72s/it]\n\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_ablationcam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9dbc52cb80>\n\n\n\n\n\n\n\nCat_AblationCAM_Randombox\n\nablationcam_randombox = AblationCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_ablationcam_randombox = ablationcam_randombox(input_tensor=x_cat_r,targets=None)\n\n100%|██████████| 16/16 [00:26<00:00,  1.63s/it]\n100%|██████████| 16/16 [00:25<00:00,  1.60s/it]\n100%|██████████| 16/16 [00:25<00:00,  1.60s/it]\n\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_ablationcam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9f0cca57c0>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_ablationcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_ablationcam",
    "title": "[CAM]Other Methods",
    "section": "Dog_AblationCAM",
    "text": "Dog_AblationCAM\n\nDog_AblationCAM_Original\n\ncam_dog_ablationcam_original = ablationcam_original(input_tensor=x_dog,targets=None)\n\n100%|██████████| 16/16 [00:25<00:00,  1.61s/it]\n100%|██████████| 16/16 [00:25<00:00,  1.58s/it]\n100%|██████████| 16/16 [00:25<00:00,  1.58s/it]\n\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_ablationcam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d5405caf0>\n\n\n\n\n\n\n\nDog_AblationCAM_Randombox\n\ncam_dog_ablationcam_randombox = ablationcam_randombox(input_tensor=x_dog_r,targets=None)\n\n100%|██████████| 16/16 [00:25<00:00,  1.60s/it]\n100%|██████████| 16/16 [00:25<00:00,  1.60s/it]\n100%|██████████| 16/16 [00:25<00:00,  1.59s/it]\n\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_ablationcam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a7631c0>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_xgradcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_xgradcam",
    "title": "[CAM]Other Methods",
    "section": "Cat_XGradCAM",
    "text": "Cat_XGradCAM\n\nCat_XGradCAM_Original\n\nxgradcam_original = XGradCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_xgradcam_original = xgradcam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_xgradcam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a730fd0>\n\n\n\n\n\n\n\nCat_XGradCAM_Randombox\n\nxgradcam_randombox = XGradCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_xgradcam_randombox = xgradcam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_xgradcam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a67f220>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_xgradcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_xgradcam",
    "title": "[CAM]Other Methods",
    "section": "Dog_XGradCAM",
    "text": "Dog_XGradCAM\n\nDog_XGradCAM_Original\n\ncam_dog_xgradcam_original = xgradcam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_xgradcam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a606730>\n\n\n\n\n\n\n\nDog_XGradCAM_Randombox\n\ncam_dog_xgradcam_randombox = xgradcam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_xgradcam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a6657f0>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_eigencam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_eigencam",
    "title": "[CAM]Other Methods",
    "section": "Cat_EigenCAM",
    "text": "Cat_EigenCAM\n\nCat_EigenCAM_Original\n\neigencam_original = EigenCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_eigencam_original = eigencam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_eigencam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a55af70>\n\n\n\n\n\n\n\nCat_EigenCAM_Randombox\n\neigencam_randombox = EigenCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_eigencam_randombox = eigencam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_eigencam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a4c8d30>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_eigencam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_eigencam",
    "title": "[CAM]Other Methods",
    "section": "Dog_EigenCAM",
    "text": "Dog_EigenCAM\n\nDog_EigenCAM_Original\n\ncam_dog_eigencam_original = eigencam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_eigencam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a51fa90>\n\n\n\n\n\n\n\nDog_EigenCAM_Randombox\n\ncam_dog_eigencam_randombox = eigencam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_eigencam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a418d90>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_fullgrad",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_fullgrad",
    "title": "[CAM]Other Methods",
    "section": "Cat_FullGrad",
    "text": "Cat_FullGrad\n\nCat_FullGrad_Original\n\nfullgrad_original = FullGrad(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\nWarning: target_layers is ignored in FullGrad. All bias layers will be used instead\n\n\n\ncam_cat_fullgrad_original = fullgrad_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_fullgrad_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a38de80>\n\n\n\n\n\n\n\nCat_FullGrad_Randombox\n\nfullgrad_randombox = FullGrad(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\nWarning: target_layers is ignored in FullGrad. All bias layers will be used instead\n\n\n\ncam_cat_fullgrad_randombox = fullgrad_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_fullgrad_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a243d90>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_fullgrad",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_fullgrad",
    "title": "[CAM]Other Methods",
    "section": "Dog_FullGrad",
    "text": "Dog_FullGrad\n\nDog_FullGrad_Original\n\ncam_dog_fullgrad_original = fullgrad_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_fullgrad_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a269670>\n\n\n\n\n\n\n\nDog_FullGrad_Randombox\n\ncam_dog_fullgrad_randombox = fullgrad_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_fullgrad_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9f0caf5af0>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_eigengradcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_eigengradcam",
    "title": "[CAM]Other Methods",
    "section": "Cat_EigenGradCAM",
    "text": "Cat_EigenGradCAM\n\nCat_EigenGradCAM_Original\n\neigengradcam_original = EigenGradCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_eigengradcam_original = eigengradcam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_eigengradcam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a15f400>\n\n\n\n\n\n\n\nCat_EigenGradCAM_Randombox\n\neigengradcam_randombox = EigenGradCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_eigengradcam_randombox = eigengradcam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_eigengradcam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a0d16a0>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_eigengradcam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_eigengradcam",
    "title": "[CAM]Other Methods",
    "section": "Dog_EigenGradCAM",
    "text": "Dog_EigenGradCAM\n\nDog_EigenGradCAM_Original\n\ncam_dog_eigengradcam_original = eigengradcam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_eigengradcam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a03db80>\n\n\n\n\n\n\n\nDog_EigenGradCAM_Randombox\n\ncam_dog_eigengradcam_randombox = eigengradcam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_eigengradcam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d0a02e850>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_layercam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#cat_layercam",
    "title": "[CAM]Other Methods",
    "section": "Cat_LayerCAM",
    "text": "Cat_LayerCAM\n\nCat_LayerCAM_Original\n\nlayercam_original = LayerCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_layercam_original = layercam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_layercam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d09fa14c0>\n\n\n\n\n\n\n\nCat_LayerCAM_Randombox\n\nlayercam_randombox = LayerCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_layercam_randombox = layercam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_layercam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d09f78f40>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_layercam",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_layercam",
    "title": "[CAM]Other Methods",
    "section": "Dog_LayerCAM",
    "text": "Dog_LayerCAM"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_layercam_original",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_layercam_original",
    "title": "[CAM]Other Methods",
    "section": "Dog_LayerCAM_Original",
    "text": "Dog_LayerCAM_Original\n\ncam_dog_layercam_original = layercam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_layercam_original.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d09ee0940>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_layercam_randombox",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#dog_layercam_randombox",
    "title": "[CAM]Other Methods",
    "section": "Dog_LayerCAM_Randombox",
    "text": "Dog_LayerCAM_Randombox\n\ncam_dog_layercam_randombox = layercam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_layercam_randombox.squeeze(), alpha=0.7)\n\n<matplotlib.image.AxesImage at 0x7f9d09ed7700>"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#figure_original",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#figure_original",
    "title": "[CAM]Other Methods",
    "section": "Figure_Original",
    "text": "Figure_Original\n\nfig, ((ax1,ax2,ax3,ax4),\n      (ax5,ax6,ax7,ax8),\n      (ax9,ax10,ax11,ax12),\n      (ax13,ax14,ax15,ax16),\n     (ax17,ax18,ax19,ax20)) = plt.subplots(5,4) \nplt.title('Original')\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax1)\nax1.imshow(cam_cat_gradcam_original.squeeze(), alpha=0.7)\nax1.set_title(\"GradCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_dog_gradcam_original.squeeze(), alpha=0.7)\nax2.set_title(\"GradCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax3)\nax3.imshow(cam_cat_hirescam_original.squeeze(), alpha=0.7)\nax3.set_title(\"HiResCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax4)\nax4.imshow(cam_dog_hirescam_original.squeeze(), alpha=0.7)\nax4.set_title(\"HiResCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax5)\nax5.imshow(cam_cat_scorecam_original.squeeze(), alpha=0.7)\nax5.set_title(\"ScoreCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax6)\nax6.imshow(cam_dog_scorecam_original.squeeze(), alpha=0.7)\nax6.set_title(\"ScoreCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax7)\nax7.imshow(cam_cat_gradcamplusplus_original.squeeze(), alpha=0.7)\nax7.set_title(\"GradCAMPlusPlus CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax8)\nax8.imshow(cam_dog_gradcamplusplus_original.squeeze(), alpha=0.7)\nax8.set_title(\"GradCAMPlusPlus DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax9)\nax9.imshow(cam_cat_ablationcam_original.squeeze(), alpha=0.7)\nax9.set_title(\"AblationCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax10)\nax10.imshow(cam_dog_ablationcam_original.squeeze(), alpha=0.7)\nax10.set_title(\"AblationCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax11)\nax11.imshow(cam_cat_xgradcam_original.squeeze(), alpha=0.7)\nax11.set_title(\"XGradCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax12)\nax12.imshow(cam_dog_xgradcam_original.squeeze(), alpha=0.7)\nax12.set_title(\"XGradCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax13)\nax13.imshow(cam_cat_eigencam_original.squeeze(), alpha=0.7)\nax13.set_title(\"EigenCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax14)\nax14.imshow(cam_dog_eigencam_original.squeeze(), alpha=0.7)\nax14.set_title(\"EigenCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax15)\nax15.imshow(cam_cat_fullgrad_original.squeeze(), alpha=0.7)\nax15.set_title(\"FullGrad CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax16)\nax16.imshow(cam_dog_fullgrad_original.squeeze(), alpha=0.7)\nax16.set_title(\"FullGrad DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax17)\nax17.imshow(cam_cat_eigengradcam_original.squeeze(), alpha=0.7)\nax17.set_title(\"EigenGradCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax18)\nax18.imshow(cam_dog_eigengradcam_original.squeeze(), alpha=0.7)\nax18.set_title(\"EigenGradCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax19)\nax19.imshow(cam_cat_layercam_original.squeeze(), alpha=0.7)\nax19.set_title(\"LayerCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax20)\nax20.imshow(cam_dog_layercam_original.squeeze(), alpha=0.7)\nax20.set_title(\"LayerCAM DOG PART\")\n#\nfig.set_figwidth(20)            \nfig.set_figheight(20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-10-18-CAM_Other_Methods.html#figure_randombox",
    "href": "posts/2_research/2023-10-18-CAM_Other_Methods.html#figure_randombox",
    "title": "[CAM]Other Methods",
    "section": "Figure_Randombox",
    "text": "Figure_Randombox\n\nfig, ((ax1,ax2,ax3,ax4),\n      (ax5,ax6,ax7,ax8),\n      (ax9,ax10,ax11,ax12),\n      (ax13,ax14,ax15,ax16),\n     (ax17,ax18,ax19,ax20)) = plt.subplots(5,4) \nplt.title('Randombox')\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax1)\nax1.imshow(cam_cat_gradcam_randombox.squeeze(), alpha=0.7)\nax1.set_title(\"GradCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_dog_gradcam_randombox.squeeze(), alpha=0.7)\nax2.set_title(\"GradCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax3)\nax3.imshow(cam_cat_hirescam_randombox.squeeze(), alpha=0.7)\nax3.set_title(\"HiResCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax4)\nax4.imshow(cam_dog_hirescam_randombox.squeeze(), alpha=0.7)\nax4.set_title(\"HiResCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax5)\nax5.imshow(cam_cat_scorecam_randombox.squeeze(), alpha=0.7)\nax5.set_title(\"ScoreCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax6)\nax6.imshow(cam_dog_scorecam_randombox.squeeze(), alpha=0.7)\nax6.set_title(\"ScoreCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax7)\nax7.imshow(cam_cat_gradcamplusplus_randombox.squeeze(), alpha=0.7)\nax7.set_title(\"GradCAMPlusPlus CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax8)\nax8.imshow(cam_dog_gradcamplusplus_randombox.squeeze(), alpha=0.7)\nax8.set_title(\"GradCAMPlusPlus DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax9)\nax9.imshow(cam_cat_ablationcam_randombox.squeeze(), alpha=0.7)\nax9.set_title(\"AblationCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax10)\nax10.imshow(cam_dog_ablationcam_randombox.squeeze(), alpha=0.7)\nax10.set_title(\"AblationCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax11)\nax11.imshow(cam_cat_xgradcam_randombox.squeeze(), alpha=0.7)\nax11.set_title(\"XGradCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax12)\nax12.imshow(cam_dog_xgradcam_randombox.squeeze(), alpha=0.7)\nax12.set_title(\"XGradCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax13)\nax13.imshow(cam_cat_eigencam_randombox.squeeze(), alpha=0.7)\nax13.set_title(\"EigenCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax14)\nax14.imshow(cam_dog_eigencam_randombox.squeeze(), alpha=0.7)\nax14.set_title(\"EigenCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax15)\nax15.imshow(cam_cat_fullgrad_randombox.squeeze(), alpha=0.7)\nax15.set_title(\"FullGrad CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax16)\nax16.imshow(cam_dog_fullgrad_randombox.squeeze(), alpha=0.7)\nax16.set_title(\"FullGrad DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax17)\nax17.imshow(cam_cat_eigengradcam_randombox.squeeze(), alpha=0.7)\nax17.set_title(\"EigenGradCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax18)\nax18.imshow(cam_dog_eigengradcam_randombox.squeeze(), alpha=0.7)\nax18.set_title(\"EigenGradCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax19)\nax19.imshow(cam_cat_layercam_randombox.squeeze(), alpha=0.7)\nax19.set_title(\"LayerCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax20)\nax20.imshow(cam_dog_layercam_randombox.squeeze(), alpha=0.7)\nax20.set_title(\"LayerCAM DOG PART\")\n#\nfig.set_figwidth(20)            \nfig.set_figheight(20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-09-19-HCAM_original.html",
    "href": "posts/2_research/2023-09-19-HCAM_original.html",
    "title": "[CAM]HCAM original",
    "section": "",
    "text": "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html\nhttps://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html\nCNN으로 이미지 분류를 할 때 마지막 단의 출력값이 클수록 softmax를 거친 뒤 1에 가까워 진다면, 입력 이미지의 label에 해당하는 채널의 마지막 conv layer의 출력이 크게 하는 클래스에 크게 반응했다는 것이 됌..!"
  },
  {
    "objectID": "posts/2_research/2023-09-19-HCAM_original.html#ebayes-x",
    "href": "posts/2_research/2023-09-19-HCAM_original.html#ebayes-x",
    "title": "[CAM]HCAM original",
    "section": "ebayes X",
    "text": "ebayes X\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        camimg = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x).squeeze())\n        a,b = net(x).tolist()[0]\n        catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n        if catprob>dogprob: \n            test=camimg[0]-torch.min(camimg[0])\n            A1=torch.exp(-0.1*test)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n        else: \n            test=camimg[1]-torch.min(camimg[1])\n            A1=torch.exp(-0.1*test)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-09-19-HCAM_original.html#mode-1",
    "href": "posts/2_research/2023-09-19-HCAM_original.html#mode-1",
    "title": "[CAM]HCAM original",
    "section": "mode 1",
    "text": "mode 1\n\ntest=camimg[0]-torch.min(camimg[0])\nA1=torch.exp(-0.01*(test))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.3).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x1).squeeze())\n\n\na1,b1 = net(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.9986349047084874, 0.0013650952915126677)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.3).squeeze().show(ax=ax1)\nax1.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.3).squeeze().show(ax=ax2)\nax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n- 2nd CAM 분리\n\ntest1=camimg1[0]-torch.min(camimg1[0])\nA3 = torch.exp(-0.015*(test1))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1)*Y2-torch.min((x1)*Y2)\n\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1)*Y22-torch.min((x1)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n(x2*0.3).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x2).squeeze())\n\n\na2,b2 = net(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.19813533943993217, 0.8018646605600679)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-09-19-HCAM_original.html#mode-3-만들기",
    "href": "posts/2_research/2023-09-19-HCAM_original.html#mode-3-만들기",
    "title": "[CAM]HCAM original",
    "section": "mode 3 만들기",
    "text": "mode 3 만들기\n\ntest2=camimg2[0]-torch.min(camimg2[0])\n\n\nA5 = torch.exp(-0.05*(test2))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n(x2*0.3).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*0.3).squeeze().show(ax=ax1)  #MODE3\n(x3*0.2).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*0.3).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*0.3 + x32*0.2).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-09-19-HCAM_original.html#mode-1-1",
    "href": "posts/2_research/2023-09-19-HCAM_original.html#mode-1-1",
    "title": "[CAM]HCAM original",
    "section": "mode 1",
    "text": "mode 1\n\ntest=camimg[1]-torch.min(camimg[1])\nA1=torch.exp(-0.015*(test))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x1).squeeze())\n\n\na1,b1 = net(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.003175590188180829, 0.9968244098118192)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.3).squeeze().show(ax=ax1)\nax1.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.3).squeeze().show(ax=ax2)\nax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n- 2nd CAM 분리\n\ntest1=camimg1[1]-torch.min(camimg1[1])\nA3 = torch.exp(-0.05*(test1))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n# res \nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1*0.2)*Y2-torch.min((x1*0.2)*Y2)\n#\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1*0.2)*Y22-torch.min((x1*0.2)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*3).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x2).squeeze())\n\n\na2,b2 = net(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.6993123345460756, 0.3006876654539244)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-09-19-HCAM_original.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "href": "posts/2_research/2023-09-19-HCAM_original.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "title": "[CAM]HCAM original",
    "section": "mode 3 만들기 더이상 분리되지 않는 듯",
    "text": "mode 3 만들기 더이상 분리되지 않는 듯\n\ntest2=camimg2[1]-torch.min(camimg2[1])\n\n\nA5 = torch.exp(-0.05*(test2))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*2).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*8).squeeze().show(ax=ax1)  #MODE3\n(x3).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*1).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*1 + x32*1).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\npath_r=Path('random_pet_one')   #랜덤박스넣은사진\n\n\nfiles_r=get_image_files(path_r)\n\n\ndls_r=ImageDataLoaders.from_name_func(path_r,files_r,label_func,item_tfms=Resize(512))"
  },
  {
    "objectID": "posts/2_research/2023-09-16-Grad_CAM_rst.html",
    "href": "posts/2_research/2023-09-16-Grad_CAM_rst.html",
    "title": "[CAM]Grad CAM(Original, Randombox)",
    "section": "",
    "text": "https://github.com/jacobgil/pytorch-grad-cam\nhttps://hygradcam.blogspot.com/2020/11/blog-post.html\nhttps://haystar.tistory.com/72"
  },
  {
    "objectID": "posts/2_research/2023-09-16-Grad_CAM_rst.html#cat",
    "href": "posts/2_research/2023-09-16-Grad_CAM_rst.html#cat",
    "title": "[CAM]Grad CAM(Original, Randombox)",
    "section": "CAT",
    "text": "CAT\n\nx, = first(dls.test_dl([PILImage.create(get_image_files(path)[2])]))\n\n\ngrad_cam = compute_gradcam(lrnr2,x)\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow((grad_cam).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"CAT PART\")\n#\n# dls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\n# ax3.imshow((ybar_threshed2).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n# ax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -> 보라색\n\n\na,b = net(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(0.9999999910101288, 8.989871077326127e-09)"
  },
  {
    "objectID": "posts/2_research/2023-09-16-Grad_CAM_rst.html#dog",
    "href": "posts/2_research/2023-09-16-Grad_CAM_rst.html#dog",
    "title": "[CAM]Grad CAM(Original, Randombox)",
    "section": "DOG",
    "text": "DOG\n\nx, = first(dls.test_dl([PILImage.create(get_image_files(path)[12])]))\n\n\ngrad_cam = compute_gradcam(lrnr2,x)\n\n\nfig, (ax1,ax3) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \n# dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n# ax2.imshow((ybar_threshed).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n# ax2.set_title(\"CAT PART\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow((grad_cam).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -> 보라색\n\n\na,b = net(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(6.72737421709701e-06, 0.9999932726257829)"
  },
  {
    "objectID": "posts/2_research/2023-09-16-Grad_CAM_rst.html#cat-1",
    "href": "posts/2_research/2023-09-16-Grad_CAM_rst.html#cat-1",
    "title": "[CAM]Grad CAM(Original, Randombox)",
    "section": "CAT",
    "text": "CAT\n\nx, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[2])]))\n\n\ngrad_cam = compute_gradcam(lrnr2_r,x)\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow((grad_cam).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"CAT PART\")\n#\n# dls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\n# ax3.imshow((ybar_threshed2).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n# ax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -> 보라색\n\n\na,b = net_r(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(0.9999999956844526, 4.315547465228285e-09)"
  },
  {
    "objectID": "posts/2_research/2023-09-16-Grad_CAM_rst.html#dog-1",
    "href": "posts/2_research/2023-09-16-Grad_CAM_rst.html#dog-1",
    "title": "[CAM]Grad CAM(Original, Randombox)",
    "section": "DOG",
    "text": "DOG\n\nx, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[12])]))\n\n\ngrad_cam = compute_gradcam(lrnr2_r,x)\n\n\nfig, (ax1,ax3) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \n# dls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\n# ax2.imshow((ybar_threshed).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n# ax2.set_title(\"CAT PART\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow((grad_cam).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -> 보라색\n\n\na,b = net_r(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(1.3188068250511113e-08, 0.9999999868119317)"
  },
  {
    "objectID": "posts/2_research/2023-11-29-HCAM_Tutorial.html",
    "href": "posts/2_research/2023-11-29-HCAM_Tutorial.html",
    "title": "[CAM]HCAM Tutorial",
    "section": "",
    "text": "import HCAM\nfrom torchvision.models import *\nfrom fastai.vision.all import *"
  },
  {
    "objectID": "posts/2_research/2023-11-29-HCAM_Tutorial.html#mode-1",
    "href": "posts/2_research/2023-11-29-HCAM_Tutorial.html#mode-1",
    "title": "[CAM]HCAM Tutorial",
    "section": "Mode 1",
    "text": "Mode 1\n\none = HCAM.HCAM(lrnr = lrnr2)\n\n\none.learner_thresh(Thresh=1600,input_img=x_cat)\n\n/home/csy/Dropbox/blog/posts/CAM/HCAM/learners.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[0].detach().reshape(-1))**2)))\n/home/csy/Dropbox/blog/posts/CAM/HCAM/learners.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  self.ybar_threshed = np.where(power_threshed>Thresh,torch.tensor(camimg[0].detach().reshape(-1)),0)\n\n\n\none.learner_step(Rate=-0.05)\n\n\none.prob(input_img=x_cat)\n\n\none.mode_decomp(input_img=x_cat)\n\n\n# one(input_img=x_cat)\n\n\nHCAM.plot(dls,input_img=x_cat,\n         input_img1=one(input_img=x_cat)['x'],input_img1_res=one(input_img=x_cat)['x_res'],\n         one=0.3, one_res=0.2)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-11-29-HCAM_Tutorial.html#mode-2",
    "href": "posts/2_research/2023-11-29-HCAM_Tutorial.html#mode-2",
    "title": "[CAM]HCAM Tutorial",
    "section": "Mode 2",
    "text": "Mode 2\n\none.learner_thresh(Thresh=1600,input_img=one(input_img=x_cat)['x_res'])\n\n\none.learner_step(Rate=-0.05)\n\n\none.prob(input_img=one(input_img=x_cat)['x_res'])\n\n\none.mode_decomp(input_img=one(input_img=x_cat)['x_res'])\n\n\n# one(input_img=one(input_img=x_cat)['x_res'])\n\n\nHCAM.plot(dls,input_img=x_cat,\n         input_img1=one(input_img=x_cat)['x'],input_img1_res=one(input_img=x_cat)['x_res'],\n         input_img2=one(input_img=one(input_img=x_cat)['x'])['x'],input_img2_res=one(input_img=one(input_img=x_cat)['x_res'])['x_res'],\n         one=0.35, one_res=0.2, two=0.5, two_res=0.2)"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html",
    "title": "[CAM]chest xray",
    "section": "",
    "text": "import torch \nfrom fastai.vision.all import * \nimport cv2 as cv\nimport fastbook\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nimport os"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#st-cam-결과-분리",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#st-cam-결과-분리",
    "title": "[CAM]chest xray",
    "section": "1st cam 결과 분리",
    "text": "1st cam 결과 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx12.squeeze().show(ax=ax1)  #MODE1\nx1.squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"X1\")\nax2.set_title(\"X1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nx1=x1.reshape(1,3,224,224)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\nver2 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x1).squeeze())\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax1)\nax1.imshow(ver2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART\")\n#\nx1.squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\na1=net(x1).tolist()[0][0]\nb1=net(x1).tolist()[0][1]\nnp.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1))\n\n(6.664552246309979e-19, 1.0)\n\n\n\\(\\theta\\) 생각, hyperparameter로서..\n\ntest1=ver2[0]-torch.min(ver2[0])\n\n\nA3=torch.exp(-0.04*test1)  \n\n\nA4=1-A3\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 WEIGHT WITH THETA=0.04\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 RES WEIGHT WITH THETA=0.04\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n#mode2_res\nX3=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv.resize(X3,(224,224),interpolation=cv.INTER_LINEAR))\nx3=x.squeeze().to('cpu')*Y1*Y3-torch.min(x.squeeze().to('cpu')*Y1*Y3)\n\n\n#mode1*x\nX4=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY4=torch.Tensor(cv.resize(X4,(224,224),interpolation=cv.INTER_LINEAR))\nx4=x.squeeze().to('cpu')*Y1*Y4"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-분리-결과",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-분리-결과",
    "title": "[CAM]chest xray",
    "section": "2nd 분리 결과",
    "text": "2nd 분리 결과\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx12.squeeze().show(ax=ax1)  \nx1.squeeze().show(ax=ax2)  \nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx4.squeeze().show(ax=ax1)  \nx3.squeeze().show(ax=ax2)  \nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\nx3=x3.reshape(1,3,224,224)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\nver22 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x3).squeeze())"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam",
    "title": "[CAM]chest xray",
    "section": "CAM",
    "text": "CAM\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx3.squeeze().show(ax=ax1)\nax1.imshow(ver22[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART\")\n#\nx3.squeeze().show(ax=ax2)\nax2.imshow(ver22[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1,ax2, ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ver22[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\n#\n\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\na2=net(x3).tolist()[0][0]\nb2=net(x3).tolist()[0][1]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(3.322455317236289e-16, 0.9999999999999998)"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#차",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#차",
    "title": "[CAM]chest xray",
    "section": "2차",
    "text": "2차\n\nver2 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x1).squeeze())"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam-1",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam-1",
    "title": "[CAM]chest xray",
    "section": "CAM",
    "text": "CAM\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax1)\nax1.imshow(ver2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART\")\n#\nx1.squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\na1=net(x1).tolist()[0][0]\nb1=net(x1).tolist()[0][1]\nnp.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1))\n\n(3.013152213595138e-16, 0.9999999999999997)\n\n\n\ntest=ver2[0]-torch.min(ver2[0])\n\n\ntest1=ver2[1]-torch.min(ver2[1])\n\n\nA3=torch.exp(-0.08*test)  \n\n\nA4=1-A3\n\n\nA33 = torch.exp(-0.08*test1)\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"X2 WEIGHT WITH THETA=0.08\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A33.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"X2 RES WEIGHT WITH THETA=0.08\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n#mode2_res\nX3=np.array(A33.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv.resize(X3,(224,224),interpolation=cv.INTER_LINEAR))\nx3=(x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1))*0.2*Y3\n\n#x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1)*0.03\n\n\n#mode1그림을 위한 mode2_res*x\nX_3=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY_3=torch.Tensor(cv.resize(X_3,(224,224),interpolation=cv.INTER_LINEAR))\nx_3=(x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1))*Y3\n\n\n#mode2*x\nX4=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY4=torch.Tensor(cv.resize(X_3,(224,224),interpolation=cv.INTER_LINEAR))\nx4=(x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1))*Y4*0.2"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-cam-결과-분리",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-cam-결과-분리",
    "title": "[CAM]chest xray",
    "section": "2nd cam 결과 분리",
    "text": "2nd cam 결과 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx12.squeeze().show(ax=ax1)  \nx1.squeeze().show(ax=ax2)  \nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx4.squeeze().show(ax=ax1)  \nx3.squeeze().show(ax=ax2)  \nax1.set_title(\"X2\")\nax2.set_title(\"X2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\nx3=x3.reshape(1,3,224,224)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\nver22 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x3).squeeze())"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam-2",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam-2",
    "title": "[CAM]chest xray",
    "section": "CAM",
    "text": "CAM\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx3.squeeze().show(ax=ax1)\nax1.imshow(ver22[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART\")\n#\nx3.squeeze().show(ax=ax2)\nax2.imshow(ver22[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2, ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ver22[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\n#\n\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\na2=net(x3).tolist()[0][0]\nb2=net(x3).tolist()[0][1]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(1.1537635027871649e-15, 0.9999999999999989)"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#st-cam-결과-분리-1",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#st-cam-결과-분리-1",
    "title": "[CAM]chest xray",
    "section": "1st cam 결과 분리",
    "text": "1st cam 결과 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx12.squeeze().show(ax=ax1)  #MODE1\nx1.squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"X1\")\nax2.set_title(\"X1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nx1=x1.reshape(1,3,224,224)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-cam-분리",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-cam-분리",
    "title": "[CAM]chest xray",
    "section": "2nd cam 분리",
    "text": "2nd cam 분리\n\nver2 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x1).squeeze())"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam-3",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#cam-3",
    "title": "[CAM]chest xray",
    "section": "cam",
    "text": "cam\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax1)\nax1.imshow(ver2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART\")\n#\nx1.squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\na1=net(x1).tolist()[0][0]\nb1=net(x1).tolist()[0][1]\nnp.exp(a1)/(np.exp(a1)+np.exp(b1)), np.exp(b1)/(np.exp(a1)+np.exp(b1))\n\n(1.4950733419675e-20, 1.0)\n\n\n\ntest=ver2[0]-torch.min(ver2[0])\n\n\ntest1=ver2[1]-torch.min(ver2[1])\n\n\nA3=torch.exp(-0.1*test)  \n\n\nA4=1-A3\n\n\nA33 = torch.exp(-0.1*test1)\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"X2 WEIGHT WITH THETA=0.1\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A33.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"X2 RES WEIGHT WITH THETA=0.1\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n#mode2_res\nX3=np.array(A33.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv.resize(X3,(224,224),interpolation=cv.INTER_LINEAR))\nx3=(x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1))*0.3*Y3\n\n#x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1)*0.03\n\n\n#mode1그림을 위한 mode2_res*x\nX_3=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY_3=torch.Tensor(cv.resize(X_3,(224,224),interpolation=cv.INTER_LINEAR))\nx_3=(x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1))*Y3\n\n\n#mode2*x\nX4=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY4=torch.Tensor(cv.resize(X_3,(224,224),interpolation=cv.INTER_LINEAR))\nx4=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu')*Y1)*Y4*0.05"
  },
  {
    "objectID": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-cam-결과-분리-1",
    "href": "posts/2_research/2023-09-21-CAM_chest_xray.html#nd-cam-결과-분리-1",
    "title": "[CAM]chest xray",
    "section": "2nd cam 결과 분리",
    "text": "2nd cam 결과 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx12.squeeze().show(ax=ax1)  \nx1.squeeze().show(ax=ax2)  \nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \nx4.squeeze().show(ax=ax1)  \nx3.squeeze().show(ax=ax2)  \nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\nx3=x3.reshape(1,3,224,224)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\nver22 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x3).squeeze())\n\ncam\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx3.squeeze().show(ax=ax1)\nax1.imshow(ver22[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART\")\n#\nx3.squeeze().show(ax=ax2)\nax2.imshow(ver22[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2, ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ver2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ver22[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,223,223,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\n#\n\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\na2=net(x3).tolist()[0][0]\nb2=net(x3).tolist()[0][1]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(4.3886825515670436e-18, 1.0)"
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html",
    "title": "[CAM]HCAM random",
    "section": "",
    "text": "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html\nhttps://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html\nCNN으로 이미지 분류를 할 때 마지막 단의 출력값이 클수록 softmax를 거친 뒤 1에 가까워 진다면, 입력 이미지의 label에 해당하는 채널의 마지막 conv layer의 출력이 크게 하는 클래스에 크게 반응했다는 것이 됌..!"
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html#thresholding-point",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html#thresholding-point",
    "title": "[CAM]HCAM random",
    "section": "thresholding point",
    "text": "thresholding point\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[k])]))\n        camimg = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x).squeeze())\n        a,b = net_r(x).tolist()[0]\n        catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n        ebayesthresh = importr('EbayesThresh').ebayesthresh\n        power_threshed=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[0].detach().reshape(-1))**2)))\n        ybar_threshed = np.where(power_threshed>2000,torch.tensor(camimg[0].detach().reshape(-1)),0)\n        power_threshed2=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[1].detach().reshape(-1))**2)))\n        ybar_threshed2 = np.where(power_threshed>2000,torch.tensor(camimg[1].detach().reshape(-1)),0)\n        ybar_threshed = torch.tensor(ybar_threshed.reshape(16,16))\n        ybar_threshed2 = torch.tensor(ybar_threshed2.reshape(16,16))\n        if catprob>dogprob: \n            # test=camimg[0]-torch.min(camimg[0])\n            A1=torch.exp(-0.1*ybar_threshed)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n        else: \n            # test=camimg[1]-torch.min(camimg[1])\n            A1=torch.exp(-0.1*ybar_threshed2)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[0].detach().reshape(-1))**2)))\n<ipython-input-16-98bb7127f6af>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed = np.where(power_threshed>2000,torch.tensor(camimg[0].detach().reshape(-1)),0)\n<ipython-input-16-98bb7127f6af>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed2=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[1].detach().reshape(-1))**2)))\n<ipython-input-16-98bb7127f6af>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed2 = np.where(power_threshed>2000,torch.tensor(camimg[1].detach().reshape(-1)),0)\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html#ebayes-x",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html#ebayes-x",
    "title": "[CAM]HCAM random",
    "section": "ebayes X",
    "text": "ebayes X\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[k])]))\n        camimg = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x).squeeze())\n        a,b = net_r(x).tolist()[0]\n        catprob, dogprob = np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n        if catprob>dogprob: \n            test=camimg[0]-torch.min(camimg[0])\n            A1=torch.exp(-0.1*test)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n        else: \n            test=camimg[1]-torch.min(camimg[1])\n            A1=torch.exp(-0.1*test)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-1",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-1",
    "title": "[CAM]HCAM random",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.35).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet_1.to('cpu')\nnet_2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x1).squeeze())\n\n\na1,b1 = net_r(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.9505286776057943, 0.04947132239420577)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n- 2nd CAM 분리\n\ntest1=camimg1[0]-torch.min(camimg1[0])\nA3 = torch.exp(-0.03*(test1))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls_r.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls_r.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\n\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\n\nx2=(x1*0.2)*Y2-torch.min((x1*0.2)*Y2)\n\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\n\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\n\nx22=(x1*0.2)*Y22-torch.min((x1*0.2)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*4).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet_1.to('cpu')\nnet_2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x2).squeeze())\n\n\na2,b2 = net_r(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.538050281567858, 0.461949718432142)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-3-만들기",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-3-만들기",
    "title": "[CAM]HCAM random",
    "section": "mode 3 만들기",
    "text": "mode 3 만들기\n\ntest2=camimg2[0]-torch.min(camimg2[0])\n\n\nA5 = torch.exp(-0.05*(test2))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*4).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*8).squeeze().show(ax=ax1)  #MODE3\n(x3).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4 + x32*2).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-1-1",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-1-1",
    "title": "[CAM]HCAM random",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed2))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.3).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet_1.to('cpu')\nnet_2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x1).squeeze())\n\n\na1,b1 = net_r(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.001180554413474461, 0.9988194455865255)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(camimg1[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n- 2nd CAM 분리\n\ntest1=camimg1[1]-torch.min(camimg1[1])\nA3 = torch.exp(-0.05*(test1))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls_r.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls_r.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n# res \nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1*0.2)*Y2-torch.min((x1*0.2)*Y2)\n#\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1*0.2)*Y22-torch.min((x1*0.2)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*3).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet_1.to('cpu')\nnet_2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -> ikl', net_2[2].weight, net_1(x2).squeeze())\n\n\na2,b2 = net_r(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.48014948791345896, 0.5198505120865412)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg1[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "href": "posts/2_research/2023-08-28-HCAM_random_old.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "title": "[CAM]HCAM random",
    "section": "mode 3 만들기 더이상 분리되지 않는 듯",
    "text": "mode 3 만들기 더이상 분리되지 않는 듯\n\ntest2=camimg2[1]-torch.min(camimg2[1])\n\n\nA5 = torch.exp(-0.05*(test2))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(camimg2[0].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(camimg2[1].to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*4).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*8).squeeze().show(ax=ax1)  #MODE3\n(x3).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4 + x32*2).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-10-31-HCAM_Other_Methods_chest_xray.html",
    "href": "posts/2_research/2023-10-31-HCAM_Other_Methods_chest_xray.html",
    "title": "[CAM]other methods chest xray",
    "section": "",
    "text": "scorecam nan 값 산출 문제찾는 중..\n\nImport\n\nimport torch \nfrom fastai.vision.all import * \nimport cv2 as cv\nimport fastbook\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nimport os\n\nfrom pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad, EigenGradCAM, LayerCAM\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nimport torchvision\nfrom torchvision.models import resnet18\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torchvision.models import resnet50\n\n\n\nData\nrefer : https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n\n# path=Path('./home/Dropbox/chest_xray/chest_xray') \npath = Path(os.path.expanduser(os.path.join('~', 'Dropbox/chest_xray/chest_xray')))\n\n\npath.ls()\n\n(#3) [Path('/home/csy/Dropbox/chest_xray/chest_xray/train'),Path('/home/csy/Dropbox/chest_xray/chest_xray/test'),Path('/home/csy/Dropbox/chest_xray/chest_xray/val')]\n\n\n\nfiles=get_image_files(path)\n\n\ndls = ImageDataLoaders.from_folder(path, train='train', valid_pct=0.2, item_tfms=Resize(224))      \n\n\ndls.vocab\n\n['NORMAL', 'PNEUMONIA']\n\n\n\ndls.show_batch(max_n=16)\n\n\n\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\ngradcam = GradCAM(model=model, target_layers=target_layer)\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\nhirescam = HiResCAM(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\nscorecam = ScoreCAM(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\ngradcamplusplus = GradCAMPlusPlus(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\nablationcam = AblationCAM(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\nxgradcam = XGradCAM(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\neigencam = EigenCAM(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\nfullgrad = FullGrad(model=model, target_layers=target_layer)\n\nWarning: target_layers is ignored in FullGrad. All bias layers will be used instead\n\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\neigengradcam = EigenGradCAM(model=model, target_layers=target_layer)\n\n\nmodel = resnet34(pretrained=True)\n\ntarget_layer = [model.layer4[-1]]\nlayercam = LayerCAM(model=model, target_layers=target_layer)\n\n\n\n1번째 시도\n\nimg = PILImage.create(get_image_files(path)[304])\n\n\nx, = first(dls.test_dl([img]))  #이미지 텐서화\nx = x.to('cpu')\n\n\ncam_gradcam = gradcam(input_tensor=x,targets=None)\n\n\ncam_hirescam = hirescam(input_tensor=x,targets=None)\n\n\ncam_scorecam = scorecam(input_tensor=x,targets=None)\n\n100%|██████████| 32/32 [00:03<00:00,  9.20it/s]\n\n\n\ncam_gradcamplusplus = gradcamplusplus(input_tensor=x,targets=None)\n\n\ncam_ablationcam = ablationcam(input_tensor=x,targets=None)\n\n100%|██████████| 16/16 [00:03<00:00,  4.14it/s]\n\n\n\ncam_xgradcam = xgradcam(input_tensor=x,targets=None)\n\n\ncam_eigencam = eigencam(input_tensor=x,targets=None)\n\n\ncam_fullgrad = fullgrad(input_tensor=x,targets=None)\n\n\ncam_eigengradcam = eigengradcam(input_tensor=x,targets=None)\n\n\ncam_layercam = layercam(input_tensor=x,targets=None)\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_hirescam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART HiResCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_hirescam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART HiResCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_scorecam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART ScoreCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_scorecam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART ScoreCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAMPlusPlus\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAMPlusPlus\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_ablationcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART AblationCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_ablationcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART AblationCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_xgradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART XGradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_xgradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART XGradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_eigencam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART EigenCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_eigencam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART EigenCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_fullgrad.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART FullGrad\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_fullgrad.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART FullGrad\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_layercam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART LayerCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_layercam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART LayerCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n2번째 시도\n\nimg = PILImage.create(get_image_files(path)[3031])\n\n\nx, = first(dls.test_dl([img]))  #이미지 텐서화\nx=x.to('cpu')\n\n\ncam_gradcam = gradcam(input_tensor=x,targets=None)\n\n\ncam_hirescam = hirescam(input_tensor=x,targets=None)\n\n\ncam_scorecam = scorecam(input_tensor=x,targets=None)\n\n100%|██████████| 32/32 [00:03<00:00,  9.06it/s]\n\n\n\ncam_gradcamplusplus = gradcamplusplus(input_tensor=x,targets=None)\n\n\ncam_ablationcam = ablationcam(input_tensor=x,targets=None)\n\n100%|██████████| 16/16 [00:03<00:00,  4.18it/s]\n\n\n\ncam_xgradcam = xgradcam(input_tensor=x,targets=None)\n\n\ncam_eigencam = eigencam(input_tensor=x,targets=None)\n\n\ncam_fullgrad = fullgrad(input_tensor=x,targets=None)\n\n\ncam_eigengradcam = eigengradcam(input_tensor=x,targets=None)\n\n\ncam_cat_layercam = layercam(input_tensor=x,targets=None)\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_hirescam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART HiResCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_hirescam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART HiResCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_scorecam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART ScoreCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_scorecam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART ScoreCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAMPlusPlus\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAMPlusPlus\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_ablationcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART AblationCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_ablationcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART AblationCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_xgradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART XGradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_xgradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART XGradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_eigencam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART EigenCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_eigencam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART EigenCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_fullgrad.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART FullGrad\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_fullgrad.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART FullGrad\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_layercam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART LayerCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_layercam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART LayerCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n\n3번째 시도\n\nimg = PILImage.create(get_image_files(path)[3107])\n\n\nx, = first(dls.test_dl([img]))  #이미지 텐서화\nx=x.to('cpu')\n\n\ncam_gradcam = gradcam(input_tensor=x,targets=None)\n\n\ncam_hirescam = hirescam(input_tensor=x,targets=None)\n\n\ncam_scorecam = scorecam(input_tensor=x,targets=None)\n\n100%|██████████| 32/32 [00:03<00:00,  9.22it/s]\n\n\n\ncam_gradcamplusplus = gradcamplusplus(input_tensor=x,targets=None)\n\n\ncam_ablationcam = ablationcam(input_tensor=x,targets=None)\n\n100%|██████████| 16/16 [00:03<00:00,  4.23it/s]\n\n\n\ncam_xgradcam = xgradcam(input_tensor=x,targets=None)\n\n\ncam_eigencam = eigencam(input_tensor=x,targets=None)\n\n\ncam_fullgrad = fullgrad(input_tensor=x,targets=None)\n\n\ncam_eigengradcam = eigengradcam(input_tensor=x,targets=None)\n\n\ncam_cat_layercam = layercam(input_tensor=x,targets=None)\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_hirescam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART HiResCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_hirescam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART HiResCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_scorecam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART ScoreCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_scorecam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART ScoreCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART GradCAMPlusPlus\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_gradcamplusplus.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART GradCAMPlusPlus\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_ablationcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART AblationCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_ablationcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART AblationCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_xgradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART XGradCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_xgradcam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART XGradCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_eigencam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART EigenCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_eigencam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART EigenCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_fullgrad.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART FullGrad\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_fullgrad.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART FullGrad\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(-cam_layercam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"NORMAL PART LayerCAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_layercam.squeeze(),alpha=0.5,extent=(0,224,224,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DISEASE PART LayerCAM\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-09-23-HCAM_hy.html#mode-1",
    "href": "posts/2_research/2023-09-23-HCAM_hy.html#mode-1",
    "title": "[CAM]HCAM_ebayes",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.35).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x1).squeeze())\n\n\npower_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\nybar_threshed3 = np.where(power_threshed3>10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\nybar_threshed3 = torch.tensor(ybar_threshed3.reshape(16,16))\n\npower_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\nybar_threshed4 = np.where(power_threshed4>10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\nybar_threshed4 = torch.tensor(ybar_threshed4.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\n<ipython-input-333-292f842a7fbc>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed3 = np.where(power_threshed3>10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\n<ipython-input-333-292f842a7fbc>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\n<ipython-input-333-292f842a7fbc>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed4 = np.where(power_threshed4>10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\n\n\n\na1,b1 = net(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.9993523558198389, 0.0006476441801611291)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n- 2nd CAM 분리\n\n# test1=camimg1[0]-torch.min(camimg1[0])\nA3 = torch.exp(-0.05*(ybar_threshed3))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1)*Y2-torch.min((x1)*Y2)\n\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1)*Y22-torch.min((x1)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n(x2*0.2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x2).squeeze())\n\n\npower_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\nybar_threshed5 = np.where(power_threshed5>4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\nybar_threshed5 = torch.tensor(ybar_threshed5.reshape(16,16))\n\npower_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\nybar_threshed6 = np.where(power_threshed6>4,torch.tensor(camimg2[1].detach().reshape(-1)),0)\nybar_threshed6 = torch.tensor(ybar_threshed6.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\n<ipython-input-364-4701a2d33601>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed5 = np.where(power_threshed5>4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\n<ipython-input-364-4701a2d33601>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\n<ipython-input-364-4701a2d33601>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed6 = np.where(power_threshed6>4,torch.tensor(camimg2[1].detach().reshape(-1)),0)\n\n\n\na2,b2 = net(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.9923479929133789, 0.007652007086621125)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-09-23-HCAM_hy.html#mode-3-만들기",
    "href": "posts/2_research/2023-09-23-HCAM_hy.html#mode-3-만들기",
    "title": "[CAM]HCAM_ebayes",
    "section": "mode 3 만들기",
    "text": "mode 3 만들기\n\n# test2=camimg2[0]-torch.min(camimg2[0])\n\n\nA5 = torch.exp(-0.05*(ybar_threshed5))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n(x2*0.2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*0.8).squeeze().show(ax=ax1)  #MODE3\n(x3*0.2).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*0.5).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*0.5 + x32*0.5).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-09-23-HCAM_hy.html#mode-1-1",
    "href": "posts/2_research/2023-09-23-HCAM_hy.html#mode-1-1",
    "title": "[CAM]HCAM_ebayes",
    "section": "mode 1",
    "text": "mode 1\n\n# test=camimg_o[0]-torch.min(camimg_o[0])\nA1=torch.exp(-0.05*(ybar_threshed2))\nA2 = 1 - A1\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE1 WEIGHTT\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE1 RES WEIGHT\")\n#\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n# mode 1 res\nX1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\nY1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\nx1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n\n# mode 1\nX12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\nY12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\nx12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12\n\n- 1st CAM 분리\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.3).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nx1 = x1.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg1 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x1).squeeze())\n\n\npower_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\nybar_threshed3 = np.where(power_threshed3>10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\nybar_threshed3 = torch.tensor(ybar_threshed3.reshape(16,16))\n\npower_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\nybar_threshed4 = np.where(power_threshed4>10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\nybar_threshed4 = torch.tensor(ybar_threshed4.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\n<ipython-input-292-292f842a7fbc>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed3 = np.where(power_threshed3>10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\n<ipython-input-292-292f842a7fbc>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\n<ipython-input-292-292f842a7fbc>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed4 = np.where(power_threshed4>10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\n\n\n\na1,b1 = net(x1).tolist()[0]\n\n\nnp.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))\n\n(0.005690363539499261, 0.9943096364605006)\n\n\n- mode1 res\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \n(x1*0.25).squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\n(x1*0.25).squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n- 첫번째 CAM 결과와 비교\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed2,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n- 2nd CAM 분리\n\n# test1=camimg1[1]-torch.min(camimg1[1])\nA3 = torch.exp(-0.05*(ybar_threshed4))\nA4 = 1 - A3\n\n\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax1)\nax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"MODE2 RES WEIGHT\")\n#\nx1.squeeze().show(ax=ax2)\ndls.train.decode((x1,))[0].squeeze().show(ax=ax2)\nax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"MODE2 WEIGHT\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n# res \nX2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\nY2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\nx2=(x1*0.2)*Y2-torch.min((x1*0.2)*Y2)\n#\nX22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\nY22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\nx22=(x1*0.2)*Y22-torch.min((x1*0.2)*Y22)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*3).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\nx2 = x2.reshape(1,3,512,512)\n\n\nnet1.to('cpu')\nnet2.to('cpu')\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\ncamimg2 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x2).squeeze())\n\n\npower_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\nybar_threshed5 = np.where(power_threshed5>4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\nybar_threshed5 = torch.tensor(ybar_threshed5.reshape(16,16))\n\npower_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\nybar_threshed6 = np.where(power_threshed6>4,torch.tensor(camimg1[1].detach().reshape(-1)),0)\nybar_threshed6 = torch.tensor(ybar_threshed6.reshape(16,16))\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\n<ipython-input-307-25e0375ebe18>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed5 = np.where(power_threshed5>4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\n<ipython-input-307-25e0375ebe18>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  power_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\n<ipython-input-307-25e0375ebe18>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  ybar_threshed6 = np.where(power_threshed6>4,torch.tensor(camimg1[1].detach().reshape(-1)),0)\n\n\n\na2,b2 = net(x2).tolist()[0]\nnp.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))\n\n(0.7995345644391025, 0.2004654355608974)\n\n\n- mode2 res 에 CAM 결과 올리기\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed2,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"1ST CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"2ND CAM\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"3RD CAM\")\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2_research/2023-09-23-HCAM_hy.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "href": "posts/2_research/2023-09-23-HCAM_hy.html#mode-3-만들기-더이상-분리되지-않는-듯",
    "title": "[CAM]HCAM_ebayes",
    "section": "mode 3 만들기 더이상 분리되지 않는 듯",
    "text": "mode 3 만들기 더이상 분리되지 않는 듯\n\n# test2=camimg2[1]-torch.min(camimg2[1])\n\n\nA5 = torch.exp(-0.05*(ybar_threshed6))\n\n\nA6 = 1 - A5\n\n\nfig, (ax1, ax2) = plt.subplots(1,2) \n#\nx2.squeeze().show(ax=ax1)\nax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax1.set_title(\"CAT PART\")\n#\nx2.squeeze().show(ax=ax2)\nax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"DOG PART\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\n#mode 3 res\nX3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\nY3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\nx3=x2*Y3-torch.min(x2*Y3)\n# mode 3\nX32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\nY32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\nx32=x2*Y32-torch.min(x2*Y32)\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"ORIGINAL\")\nfig.set_figwidth(4)            \nfig.set_figheight(4)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\nax1.set_title(\"MODE1\")\nax2.set_title(\"MODE1 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x22*4).squeeze().show(ax=ax1)  #MODE2\n(x2).squeeze().show(ax=ax2)  #MODE2_res\nax1.set_title(\"MODE2\")\nax2.set_title(\"MODE2 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n#\nfig, (ax1, ax2) = plt.subplots(1,2) \n(x32*8).squeeze().show(ax=ax1)  #MODE3\n(x3).squeeze().show(ax=ax2)  #MODE3_res\nax1.set_title(\"MODE3\")\nax2.set_title(\"MODE3 RES\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3).squeeze().show(ax=ax1)  #MODE1\nax1.set_title(\"MODE1\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4).squeeze().show(ax=ax1)  #MODE1+MODE2\nax1.set_title(\"MODE1+MODE2\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\nfig, (ax1) = plt.subplots(1,1) \n(x12*0.3 + x22*4 + x32*2).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\nax1.set_title(\"MODE3+MODE2+MODE3\")\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  },
  {
    "objectID": "posts/2_research/2023-09-15-CAM-Original_rst.html",
    "href": "posts/2_research/2023-09-15-CAM-Original_rst.html",
    "title": "[CAM]Original CAM",
    "section": "",
    "text": "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html\nhttps://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html"
  },
  {
    "objectID": "posts/2_research/2023-09-15-CAM-Original_rst.html#cat",
    "href": "posts/2_research/2023-09-15-CAM-Original_rst.html#cat",
    "title": "[CAM]Original CAM",
    "section": "CAT",
    "text": "CAT\n\nx, = first(dls.test_dl([PILImage.create(get_image_files(path)[2])]))\n\n\ncamimg = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x).squeeze())\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow((camimg[0]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"CAT PART\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow((camimg[1]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -> 보라색\n\n\na,b = net(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(0.9999981602003378, 1.8397996622021463e-06)"
  },
  {
    "objectID": "posts/2_research/2023-09-15-CAM-Original_rst.html#dog",
    "href": "posts/2_research/2023-09-15-CAM-Original_rst.html#dog",
    "title": "[CAM]Original CAM",
    "section": "DOG",
    "text": "DOG\n\nx, = first(dls.test_dl([PILImage.create(get_image_files(path)[12])]))\n\n\ncamimg = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x).squeeze())\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \ndls.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow((camimg[0]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"CAT PART\")\n#\ndls.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow((camimg[1]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -> 보라색\n\n\na,b = net(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(0.00010162988443540359, 0.9998983701155646)"
  },
  {
    "objectID": "posts/2_research/2023-09-15-CAM-Original_rst.html#cat-1",
    "href": "posts/2_research/2023-09-15-CAM-Original_rst.html#cat-1",
    "title": "[CAM]Original CAM",
    "section": "CAT",
    "text": "CAT\n\nx, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[2])]))\n\n\ncamimg = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x).squeeze())\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow((camimg[0]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"CAT PART\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow((camimg[1]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -> 보라색\n\n\na,b = net(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(0.999967767699998, 3.22323000020705e-05)"
  },
  {
    "objectID": "posts/2_research/2023-09-15-CAM-Original_rst.html#dog-1",
    "href": "posts/2_research/2023-09-15-CAM-Original_rst.html#dog-1",
    "title": "[CAM]Original CAM",
    "section": "DOG",
    "text": "DOG\n\nx, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[12])]))\n\n\ncamimg = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x).squeeze())\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3) \n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax1)\nax1.set_title(\"Input image\")\n# \ndls_r.train.decode((x,))[0].squeeze().show(ax=ax2)\nax2.imshow((camimg[0]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax2.set_title(\"CAT PART\")\n#\ndls_r.train.decode((x,))[0].squeeze().show(ax=ax3)\nax3.imshow((camimg[1]).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\nax3.set_title(\"DOG PART\")\n#\nfig.set_figwidth(12)            \nfig.set_figheight(12)\nfig.tight_layout()\n\n\n\n\n\n판단 근거가 강할 수록 파란색 -> 보라색\n\n\na,b = net(x).tolist()[0]\n\n\nnp.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))\n\n(0.0002528585790783918, 0.9997471414209217)"
  },
  {
    "objectID": "posts/2_research/2023-11-09-CAM_Scorecam_rst.html",
    "href": "posts/2_research/2023-11-09-CAM_Scorecam_rst.html",
    "title": "[CAM]Score CAM(Original, Randombox)",
    "section": "",
    "text": "import torch \nfrom fastai.vision.all import *\nimport cv2\nimport numpy as np\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageFile\nfrom PIL import Image\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom torchvision.utils import save_image\nimport os\nimport torchvision.transforms as transforms\n\n\ndef label_func(f):\n    if f[0].isupper():\n        return 'cat' \n    else: \n        return 'dog' \n\n\npath=Path('original_pet') \nfiles=get_image_files(path)\ndls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) \n\n\npath_r=Path('random_pet_one')   #랜덤박스넣은사진\nfiles_r=get_image_files(path_r)\ndls_r=ImageDataLoaders.from_name_func(path_r,files_r,label_func,item_tfms=Resize(512)) \n\n\n학습\n\nlrnr=cnn_learner(dls,resnet34,metrics=error_rate)\nlrnr.fine_tune(1)\n\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/fastai/vision/learner.py:288: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.135569\n      0.021936\n      0.006089\n      00:37\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.033069\n      0.016387\n      0.003383\n      00:47\n    \n  \n\n\n\n\nnet1=lrnr.model[0]\nnet2=lrnr.model[1]\n\n\nnet2 = torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), \n    torch.nn.Flatten(),\n    torch.nn.Linear(512,out_features=2,bias=False))\n\n\nnet=torch.nn.Sequential(net1,net2)\n\n\nlrnr2=Learner(dls,net,metrics=accuracy) \n\n\nlrnr2.fine_tune(5) \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.223036\n      1.529223\n      0.627199\n      00:46\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.122068\n      0.748446\n      0.734100\n      00:46\n    \n    \n      1\n      0.115533\n      0.599636\n      0.785521\n      00:47\n    \n    \n      2\n      0.066296\n      0.100066\n      0.966847\n      00:46\n    \n    \n      3\n      0.029701\n      0.049993\n      0.981055\n      00:46\n    \n    \n      4\n      0.009684\n      0.052729\n      0.978349\n      00:46\n    \n  \n\n\n\n\ninterp = ClassificationInterpretation.from_learner(lrnr2)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlrnr_r=cnn_learner(dls_r,resnet34,metrics=error_rate)\nlrnr_r.fine_tune(1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.140315\n      0.002963\n      0.000677\n      00:36\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.000983\n      0.000002\n      0.000000\n      00:47\n    \n  \n\n\n\n\nnet1_r=lrnr_r.model[0]\nnet2_r=lrnr_r.model[1]\n\n\nnet2_r = torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), \n    torch.nn.Flatten(),\n    torch.nn.Linear(512,out_features=2,bias=False))\n\n\nnet_r=torch.nn.Sequential(net1_r,net2_r)\n\n\nlrnr2_r=Learner(dls_r,net_r,metrics=accuracy) \n\n\nlrnr2_r.fine_tune(5) \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.009831\n      0.000473\n      1.000000\n      00:47\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.000008\n      0.000001\n      1.000000\n      00:47\n    \n    \n      1\n      0.000002\n      0.000000\n      1.000000\n      00:47\n    \n    \n      2\n      0.000001\n      0.000000\n      1.000000\n      00:46\n    \n    \n      3\n      0.000000\n      0.000000\n      1.000000\n      00:46\n    \n    \n      4\n      0.000000\n      0.000000\n      1.000000\n      00:46\n    \n  \n\n\n\n\ninterp_r = ClassificationInterpretation.from_learner(lrnr2_r)\ninterp_r.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass\n\ndef score_cam(model, img, class_index):\n    def forward_hook(module, input, output):\n        module.forward_output = output\n\n    def backward_hook(module, grad_in, grad_out):\n        grad_in_tensor = grad_in[0]\n        module.backward_output = grad_in_tensor\n\n    # target_layer_output = model.layer4  \n    target_layer_output = model[0][-1]\n    target_layer_output.register_forward_hook(forward_hook)\n    target_layer_output.register_backward_hook(backward_hook)\n\n    output = model(img)\n\n    # 클래스 스코어 계산\n    class_score = output[0][class_index]\n\n    # 클래스 스코어를 기반으로 활성화 맵 생성\n    grad_cam = torch.zeros(target_layer_output.forward_output.size()[2:])\n    # grad_cam = grad_cam.to(device)\n\n    class_score.backward()\n    \n    for i in range(target_layer_output.forward_output.size()[2]):\n        for j in range(target_layer_output.forward_output.size()[3]):\n            grad_cam[i, j] = target_layer_output.forward_output[0, class_index, i, j]\n\n    grad_cam = grad_cam.clamp(min=0)\n\n    return grad_cam\n\n\n\n이미지\n\nx_cat, = first(dls.test_dl([PILImage.create(get_image_files(path)[2])]))\nx_cat = x_cat.to('cpu')\nx_cat_r, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[2])]))\nx_cat_r = x_cat_r.to('cpu')\nx_dog, = first(dls.test_dl([PILImage.create(get_image_files(path)[12])]))\nx_dog = x_dog.to('cpu')\nx_dog_r, = first(dls_r.test_dl([PILImage.create(get_image_files(path_r)[12])]))\nx_dog_r = x_dog_r.to('cpu')\n\n\ntransform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((224, 224)), transforms.ToTensor()])\n\n\nimg_cat = cv2.imread('original_pet/Ragdoll_8.jpg')\nimg_cat = cv2.cvtColor(img_cat, cv2.COLOR_BGR2RGB)\n\nimg_cat = transform(img_cat)\nimg_cat = img_cat.unsqueeze(0)\n\n\nimg_cat_r = cv2.imread('random_pet_one/Ragdoll_8.jpg')\nimg_cat_r = cv2.cvtColor(img_cat_r, cv2.COLOR_BGR2RGB)\n\nimg_cat_r = transform(img_cat_r)\nimg_cat_r = img_cat_r.unsqueeze(0)\n\n\nimg_dog = cv2.imread('original_pet/pomeranian_112.jpg')\nimg_dog = cv2.cvtColor(img_dog, cv2.COLOR_BGR2RGB)\n\nimg_dog = transform(img_dog)\nimg_dog = img_dog.unsqueeze(0)\n\n\nimg_dog_r = cv2.imread('random_pet_one/pomeranian_112.jpg')\nimg_dog_r = cv2.cvtColor(img_dog_r, cv2.COLOR_BGR2RGB)\n\nimg_dog_r = transform(img_dog_r)\nimg_dog_r = img_dog_r.unsqueeze(0)\n\n\n\n결과\n\ngrad_cam_cat = score_cam(lrnr2.model.to('cpu'), img_cat, class_index=0)  # ResNet-34에서는 layer4를 사용\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax1)\nax1.imshow((grad_cam_cat).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='spline36',cmap='magma')\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\ngrad_cam_cat_r = score_cam(lrnr2_r.model.to('cpu'), img_cat_r, class_index=1)  # ResNet-34에서는 layer4를 사용\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax1)\nax1.imshow((grad_cam_cat_r).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='spline36',cmap='magma')\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\ngrad_cam_dog = score_cam(lrnr2.model.to('cpu'), img_dog, class_index=1)  # ResNet-34에서는 layer4를 사용\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax1)\nax1.imshow((grad_cam_dog).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='spline36',cmap='magma')\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\n\n\n\ngrad_cam_dog_r = score_cam(lrnr2_r.model.to('cpu'), img_dog_r, class_index=1)\n\n\ngrad_cam_dog_r\n\ntensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.1389, 0.4988, 0.6678, 0.3931, 0.0012, 0.0000],\n        [0.0000, 0.2094, 0.6792, 0.9307, 0.6193, 0.1842, 0.0000],\n        [0.0000, 0.2330, 0.6546, 0.8194, 0.4580, 0.0776, 0.0000],\n        [0.0000, 0.0000, 0.1763, 0.3683, 0.2077, 0.0029, 0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n       grad_fn=<ClampBackward1>)\n\n\n\nfig, (ax1) = plt.subplots(1,1) \ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax1)\nax1.imshow((grad_cam_dog_r).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='spline36',cmap='magma')\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()"
  },
  {
    "objectID": "3_table.html",
    "href": "3_table.html",
    "title": "Table",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HCAM blog",
    "section": "",
    "text": "This blog indicates information of HCAM.\n\nSome links related HCAM\n\nCAMExisted Thesis related CAM\n\n\n\nClass Activation Map: https://openaccess.thecvf.com/content_cvpr_2016/papers/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf\n\n\n\n\ngrad-cam: https://arxiv.org/pdf/1610.02391.pdf\n\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nNov 29, 2023\n\n\nCAMHCAM Tutorial\n\n\nSEOYEON CHOI\n\n\n\n\nNov 9, 2023\n\n\nCAMScore CAM(Original, Randombox)\n\n\nSEOYEON CHOI\n\n\n\n\nOct 31, 2023\n\n\nCAMother methods chest xray\n\n\nSEOYEON CHOI\n\n\n\n\nOct 18, 2023\n\n\nCAMOther Methods\n\n\nSEOYEON CHOI\n\n\n\n\nSep 23, 2023\n\n\nCAMHCAM_ebayes\n\n\nSEOYEON CHOI\n\n\n\n\nSep 21, 2023\n\n\nCAMchest xray\n\n\nSEOYEON CHOI\n\n\n\n\nSep 19, 2023\n\n\nCAMHCAM original\n\n\nSEOYEON CHOI\n\n\n\n\nSep 16, 2023\n\n\nCAMGrad CAM(Original, Randombox)\n\n\nSEOYEON CHOI\n\n\n\n\nSep 15, 2023\n\n\nCAMOriginal CAM\n\n\nSEOYEON CHOI\n\n\n\n\nAug 28, 2023\n\n\nCAMHCAM random\n\n\nSEOYEON CHOI\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog indicates HCAM information."
  },
  {
    "objectID": "1_studies.html",
    "href": "1_studies.html",
    "title": "Studies",
    "section": "",
    "text": "No matching items"
  }
]