{
 "cells": [
  {
   "cell_type": "raw",
   "id": "25394d6c-d719-4db1-8369-cea8c28f15b5",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"**[CAM]**수정본 HCAM_cat\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-12-26\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be66784-5447-467e-b04c-31514018f149",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b168b622-f45d-4e48-a3b6-12c182f5914e",
   "metadata": {
    "id": "e6420e49-d6db-4593-931e-18d5d88df0e4",
    "tags": []
   },
   "source": [
    "### import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fc5a2de-b4c8-4ee1-88e4-604defa42d23",
   "metadata": {
    "id": "989676d6-d597-4c4e-a89a-11e4aa915efd"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from fastai.vision.all import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea7359d-5d88-43d5-9aac-49bb2acec4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6b2a9cc-7ed9-4fcd-8822-e4fee68f0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b4a516-5556-454e-8e86-232b6a09bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2f574e-9cd4-4514-ba46-2b03bc841677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "602e9cc0-699d-4cd4-83e6-30bf593cf619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as ro \n",
    "from rpy2.robjects.vectors import FloatVector \n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855c8b91-cfa4-457b-b4f6-06959fbfe200",
   "metadata": {
    "id": "e8148f33-c5ca-4f5f-9500-91c9569e6f62"
   },
   "outputs": [],
   "source": [
    "def label_func(f):\n",
    "    if f[0].isupper():\n",
    "        return 'cat' \n",
    "    else: \n",
    "        return 'dog' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fed40320-f547-4214-b0ae-5f70c1e5f382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53199c7d-27f3-4f3d-83ac-89ea0a755bf2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566a861-133a-45b0-8f86-61e9918f42cb",
   "metadata": {
    "id": "7c4d95af-c434-4e4f-8c86-c44e1f2ce2f9"
   },
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076be514-9088-4eb7-b6bd-45400a90a3c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### - 여기서는 `랜덤박스가 추가된 개/고양이 그림`에 대해 CAM을 진행한 결과를 확인함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f15c23-e8db-46ac-b787-5fe6fb190687",
   "metadata": {},
   "source": [
    "#### (1) 랜덤박스가 들어간 개 고양이 그림 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb8e4d62-12ab-4123-a053-c4d3e38573ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path('random_pet_one')   #랜덤박스넣은사진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0224ae67-438a-429c-883e-bfc623123b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7391) [Path('random_pet_one/Bombay_13.jpg'),Path('random_pet_one/beagle_193.jpg'),Path('random_pet_one/Ragdoll_8.jpg'),Path('random_pet_one/boxer_106.jpg'),Path('random_pet_one/keeshond_56.jpg'),Path('random_pet_one/american_pit_bull_terrier_162.jpg'),Path('random_pet_one/saint_bernard_136.jpg'),Path('random_pet_one/staffordshire_bull_terrier_76.jpg'),Path('random_pet_one/pug_173.jpg'),Path('random_pet_one/american_pit_bull_terrier_117.jpg')...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbbff5ed-058c-4f48-bc5f-8568c3a2615a",
   "metadata": {
    "id": "fca1bf6a-c7aa-416b-8ac1-9922e05a20da"
   },
   "outputs": [],
   "source": [
    "files=get_image_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a61eb85-3850-45b3-8b03-e924b0d46976",
   "metadata": {
    "id": "33ffcc28-46b8-4dbe-b331-86372312177d"
   },
   "outputs": [],
   "source": [
    "dls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8408df-9b12-4146-b936-2175ba864791",
   "metadata": {},
   "source": [
    "#### (2) 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370c57a0-a8ac-4737-947a-25e8249fa20f",
   "metadata": {
    "id": "8c83bf24-f52c-4467-a042-e6467d102a3a",
    "outputId": "3c87c3dd-6d54-492e-c9b9-5cd814d5b23b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/fastai/vision/learner.py:288: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n",
      "  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n",
      "/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/csy/anaconda3/envs/temp_csy/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.125641</td>\n",
       "      <td>0.007128</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrnr=cnn_learner(dls,resnet34,metrics=error_rate)\n",
    "lrnr.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d21b3d4-aa24-4de3-b476-80695ea66ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1=lrnr.model[0]\n",
    "net2=lrnr.model[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28c0a3ec-b0a7-4cc9-807f-8a14d3a9f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.AdaptiveAvgPool2d(output_size=1), \n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(512,out_features=2,bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb7bbf18-ffc1-4c7b-a344-0d86a0b8f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=torch.nn.Sequential(net1,net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d69bffeb-a78a-4af3-84b3-cb4808285d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr2=Learner(dls,net,metrics=accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472fe0f-74a9-4083-9411-4183abcf721b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.307659</td>\n",
       "      <td>171.091370</td>\n",
       "      <td>0.414750</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='2' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.00% [2/10 01:32&lt;06:10]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.099324</td>\n",
       "      <td>0.018034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.014832</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='23' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      25.00% [23/92 00:11&lt;00:35 0.0096]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrnr2.fine_tune(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b9cc13-27ba-4498-8a89-258459491364",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ea2185-e0de-4460-88a3-be5516dcd9ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c6dc44-4249-456f-9aba-5c6a633a3270",
   "metadata": {},
   "source": [
    "# CAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d06a91-7f21-4489-8e16-b35681f26abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = first(dls.test_dl([PILImage.create(get_image_files(path)[2])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb3f62-aec3-4c82-bfda-ce24de5e38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f05494e-1602-43c2-b2f2-86401151558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebayesthresh = importr('EbayesThresh').ebayesthresh\n",
    "\n",
    "power_threshed=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[0].detach().reshape(-1))**2)))\n",
    "ybar_threshed = np.where(power_threshed>1600,torch.tensor(camimg[0].detach().reshape(-1)).cpu(),0)\n",
    "ybar_threshed = torch.tensor(ybar_threshed.reshape(16,16))\n",
    "\n",
    "power_threshed2=np.array(ebayesthresh(FloatVector(torch.tensor(camimg[1].detach().reshape(-1))**2)))\n",
    "ybar_threshed2 = np.where(power_threshed2>2100,torch.tensor(camimg[1].detach().reshape(-1)).cpu(),0)\n",
    "ybar_threshed2 = torch.tensor(ybar_threshed2.reshape(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7d46f-a72c-47b4-af4e-81f4e431a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3) \n",
    "# \n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"Input image\")\n",
    "# \n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow((ybar_threshed).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"CAT PART\")\n",
    "#\n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax3)\n",
    "ax3.imshow((ybar_threshed2).to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax3.set_title(\"DOG PART\")\n",
    "#\n",
    "fig.set_figwidth(12)            \n",
    "fig.set_figheight(12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b263097-16d0-4bd8-9bfe-f0dba07f3471",
   "metadata": {},
   "source": [
    "- 판단 근거가 강할 수록 파란색 -> 보라색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b18cb-a0d9-4397-9c0b-706b86267c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = net(x).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d6ab8-a7af-4c51-87a4-442f4c7e23a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(a)/ (np.exp(a)+np.exp(b)) ,  np.exp(b)/ (np.exp(a)+np.exp(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49610eaa-24a9-4903-b3eb-a78e3e299df8",
   "metadata": {},
   "source": [
    "## mode 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b89a9-1517-41e5-8af9-7f2d365b6f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=camimg_o[0]-torch.min(camimg_o[0])\n",
    "A1=torch.exp(-0.05*(ybar_threshed))\n",
    "A2 = 1 - A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd7c9d-17a0-4c1b-a5ff-95472d52e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(A2.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"MODE1 WEIGHTT\")\n",
    "#\n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(A1.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"MODE1 RES WEIGHT\")\n",
    "#\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e52c1-c142-41e0-b293-eac1ea89a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode 1 res\n",
    "X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x1=x.squeeze().to('cpu')*Y1-torch.min(x.squeeze().to('cpu'))*Y1\n",
    "\n",
    "# mode 1\n",
    "X12=np.array(A2.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y12=torch.Tensor(cv2.resize(X12,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x12=x.squeeze().to('cpu')*Y12-torch.min(x.squeeze().to('cpu'))*Y12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedbcf52-c0e4-4d94-bba7-6a2e6d8236d5",
   "metadata": {},
   "source": [
    "`-` 1st CAM 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132361f0-acb2-496a-8369-398777520d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"ORIGINAL\")\n",
    "fig.set_figwidth(4)            \n",
    "fig.set_figheight(4)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x12*0.35).squeeze().show(ax=ax1)  #MODE1\n",
    "(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\n",
    "ax1.set_title(\"MODE1\")\n",
    "ax2.set_title(\"MODE1 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef80604-3c90-4fcd-92cc-802f23fc645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.reshape(1,3,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac4475a-1f9e-40de-a9f9-3fd189608903",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1.to('cpu')\n",
    "net2.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab50141-f12f-4729-8afe-a3e19acbdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg1 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x1).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b593a-a718-427c-aee7-bb858c024e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_threshed3=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[0].detach().reshape(-1))**2)))\n",
    "ybar_threshed3 = np.where(power_threshed3>10,torch.tensor(camimg1[0].detach().reshape(-1)),0)\n",
    "ybar_threshed3 = torch.tensor(ybar_threshed3.reshape(16,16))\n",
    "\n",
    "power_threshed4=np.array(ebayesthresh(FloatVector(torch.tensor(camimg1[1].detach().reshape(-1))**2)))\n",
    "ybar_threshed4 = np.where(power_threshed4>10,torch.tensor(camimg1[1].detach().reshape(-1)),0)\n",
    "ybar_threshed4 = torch.tensor(ybar_threshed4.reshape(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b1a953-d4a1-4e16-8774-c882a1d22831",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1,b1 = net(x1).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea588c-ef2d-45aa-b539-b6a3eb01d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(a1)/ (np.exp(a1)+np.exp(b1)) ,  np.exp(b1)/ (np.exp(a1)+np.exp(b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbca66-450d-4cd2-81fa-61d7fcb943f4",
   "metadata": {},
   "source": [
    "`-` mode1 res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0126e2-0a97-4d73-9d5f-75aa86521d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "(x1*0.25).squeeze().show(ax=ax1)\n",
    "ax1.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"CAT PART\")\n",
    "#\n",
    "(x1*0.25).squeeze().show(ax=ax2)\n",
    "ax2.imshow(ybar_threshed4,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"DOG PART\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343967c4-3bcb-4e1a-b480-7682080d40f3",
   "metadata": {},
   "source": [
    "`-` 첫번째 CAM 결과와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605bfd7-c0c7-4653-bff0-e17e61889f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"1ST CAM\")\n",
    "#\n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"2ND CAM\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a41656-027a-48e3-abf9-1a613e52dd11",
   "metadata": {},
   "source": [
    "`-` 2nd CAM 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fde689-d2c8-44b2-b83c-eef319dc0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1=camimg1[0]-torch.min(camimg1[0])\n",
    "A3 = torch.exp(-0.05*(ybar_threshed3))\n",
    "A4 = 1 - A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ba764-b025-4770-8bb8-b9730ebc56e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "x1.squeeze().show(ax=ax2)\n",
    "dls.train.decode((x1,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(A3.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"MODE2 RES WEIGHT\")\n",
    "#\n",
    "x1.squeeze().show(ax=ax2)\n",
    "dls.train.decode((x1,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(A4.data.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"MODE2 WEIGHT\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb947e8-afa3-4b6d-839f-062f7ef648c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=np.array(A3.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y2=torch.Tensor(cv2.resize(X2,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x2=(x1)*Y2-torch.min((x1)*Y2)\n",
    "\n",
    "X22=np.array(A4.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y22=torch.Tensor(cv2.resize(X22,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x22=(x1)*Y22-torch.min((x1)*Y22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4146a478-9890-40bf-a151-6b065cbab0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"ORIGINAL\")\n",
    "fig.set_figwidth(4)            \n",
    "fig.set_figheight(4)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n",
    "(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\n",
    "ax1.set_title(\"MODE1\")\n",
    "ax2.set_title(\"MODE1 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n",
    "(x2*0.2).squeeze().show(ax=ax2)  #MODE2_res\n",
    "ax1.set_title(\"MODE2\")\n",
    "ax2.set_title(\"MODE2 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a6c43-0d66-4769-9bf5-c7b00c5b6f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x2.reshape(1,3,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6f37a-fce1-4661-bce6-27a1964346d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1.to('cpu')\n",
    "net2.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4122d-5d20-43f6-91e5-604aecf744a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg2 = torch.einsum('ij,jkl -> ikl', net2[2].weight, net1(x2).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611ef42-62fa-4eeb-9865-523029a720b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_threshed5=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[0].detach().reshape(-1))**2)))\n",
    "ybar_threshed5 = np.where(power_threshed5>4,torch.tensor(camimg2[0].detach().reshape(-1)),0)\n",
    "ybar_threshed5 = torch.tensor(ybar_threshed5.reshape(16,16))\n",
    "\n",
    "power_threshed6=np.array(ebayesthresh(FloatVector(torch.tensor(camimg2[1].detach().reshape(-1))**2)))\n",
    "ybar_threshed6 = np.where(power_threshed6>4,torch.tensor(camimg2[1].detach().reshape(-1)),0)\n",
    "ybar_threshed6 = torch.tensor(ybar_threshed6.reshape(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f544fd-7047-43ed-8471-56db419fb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2,b2 = net(x2).tolist()[0]\n",
    "np.exp(a2)/(np.exp(a2)+np.exp(b2)), np.exp(b2)/(np.exp(a2)+np.exp(b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c47b8a-07e9-410f-bcd2-706ef8875b38",
   "metadata": {},
   "source": [
    "`-` mode2 res 에 CAM 결과 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2d4b9-8383-4583-93c1-cc2f04635834",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "#\n",
    "x2.squeeze().show(ax=ax1)\n",
    "ax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"CAT PART\")\n",
    "#\n",
    "x2.squeeze().show(ax=ax2)\n",
    "ax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"DOG PART\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0a356-b393-4e74-9755-1ddecfd11da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3) \n",
    "# \n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(ybar_threshed,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"1ST CAM\")\n",
    "#\n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(ybar_threshed3,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"2ND CAM\")\n",
    "#\n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax3)\n",
    "ax3.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax3.set_title(\"3RD CAM\")\n",
    "fig.set_figwidth(12)            \n",
    "fig.set_figheight(12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473cb77e-b5b2-48a8-b43e-e0c67bad6d7e",
   "metadata": {},
   "source": [
    "## mode 3 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b8788-2b30-432a-9941-705b37fe4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test2=camimg2[0]-torch.min(camimg2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f6574-5562-43d2-ba72-f33b622c7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "A5 = torch.exp(-0.05*(ybar_threshed5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc6c179-45bd-4806-a941-108c6e71b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A6 = 1 - A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af093e5-7a54-4a2c-8e7e-525c9c123fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "#\n",
    "x2.squeeze().show(ax=ax1)\n",
    "ax1.imshow(ybar_threshed5,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax1.set_title(\"CAT PART\")\n",
    "#\n",
    "x2.squeeze().show(ax=ax2)\n",
    "ax2.imshow(ybar_threshed6,alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='cool')\n",
    "ax2.set_title(\"DOG PART\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f040b4-f8cc-4818-99e4-1c7a9f84beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode 3 res\n",
    "X3=np.array(A5.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y3=torch.Tensor(cv2.resize(X3,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x3=x2*Y3-torch.min(x2*Y3)\n",
    "# mode 3\n",
    "X32=np.array(A6.to(\"cpu\").detach(),dtype=np.float32)\n",
    "Y32=torch.Tensor(cv2.resize(X32,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "x32=x2*Y32-torch.min(x2*Y32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35dc4a7-30a8-4a5a-ad34-587e93352824",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "dls.train.decode((x,))[0].squeeze().show(ax=ax1)\n",
    "ax1.set_title(\"ORIGINAL\")\n",
    "fig.set_figwidth(4)            \n",
    "fig.set_figheight(4)\n",
    "fig.tight_layout()\n",
    "\n",
    "with open('hcam_cat_plt1.pkl', 'wb') as file:\n",
    "    pickle.dump(fig, file)\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n",
    "(x1*0.2).squeeze().show(ax=ax2)  #MODE1_res\n",
    "ax1.set_title(\"MODE1\")\n",
    "ax2.set_title(\"MODE1 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "with open('hcam_cat_plt2.pkl', 'wb') as file:\n",
    "    pickle.dump(fig, file)\n",
    "    \n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x22*0.5).squeeze().show(ax=ax1)  #MODE2\n",
    "(x2*0.2).squeeze().show(ax=ax2)  #MODE2_res\n",
    "ax1.set_title(\"MODE2\")\n",
    "ax2.set_title(\"MODE2 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "with open('hcam_cat_plt3.pkl', 'wb') as file:\n",
    "    pickle.dump(fig, file)\n",
    "    \n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1,2) \n",
    "(x32*0.8).squeeze().show(ax=ax1)  #MODE3\n",
    "(x3*0.2).squeeze().show(ax=ax2)  #MODE3_res\n",
    "ax1.set_title(\"MODE3\")\n",
    "ax2.set_title(\"MODE3 RES\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "\n",
    "with open('hcam_cat_plt4.pkl', 'wb') as file:\n",
    "    pickle.dump(fig, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b24d5c-3a88-488d-a357-2d2fc696a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hcam_cat_plt1.pkl', 'rb') as file:\n",
    "    hcam_cat_plt = pickle.load(file)\n",
    "plt.show(hcam_cat_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c519be-7fda-4429-960f-b4ffb1d8f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hcam_cat_plt2.pkl', 'rb') as file:\n",
    "    hcam_cat_plt = pickle.load(file)\n",
    "plt.show(hcam_cat_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0a25a-f720-4186-9142-5e4502066076",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hcam_cat_plt3.pkl', 'rb') as file:\n",
    "    hcam_cat_plt = pickle.load(file)\n",
    "plt.show(hcam_cat_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4772bc38-ca5f-4cf4-8e30-6ed7a8ed2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hcam_cat_plt4.pkl', 'rb') as file:\n",
    "    hcam_cat_plt = pickle.load(file)\n",
    "plt.show(hcam_cat_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e8497b-951c-4303-9df0-5b907cadb778",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "(x12*0.3).squeeze().show(ax=ax1)  #MODE1\n",
    "ax1.set_title(\"MODE1\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "\n",
    "with open('hcam_cat_plt_mode1.pkl', 'wb') as file:\n",
    "    pickle.dump(fig, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905be2f-14c1-46d7-84ad-00dae9ef8ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hcam_cat_plt_mode1.pkl', 'rb') as file:\n",
    "    hcam_cat_plt_mode1 = pickle.load(file)\n",
    "plt.show(hcam_cat_plt_mode1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60603a85-2843-4089-ac93-0f42f53f9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "(x12*0.3 + x22*0.5).squeeze().show(ax=ax1)  #MODE1+MODE2\n",
    "ax1.set_title(\"MODE1+MODE2\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "\n",
    "with open('hcam_cat_plt_mode2.pkl', 'wb') as file:\n",
    "    pickle.dump(fig, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd809c-6e7a-4ad9-8cf1-d7ca733939b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hcam_cat_plt_mode2.pkl', 'rb') as file:\n",
    "    hcam_cat_plt_mode2 = pickle.load(file)\n",
    "plt.show(hcam_cat_plt_mode2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dfdb51-038a-442e-9305-a685b12af7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1) \n",
    "(x12*0.3 + x22*0.5 + x32*0.5).squeeze().show(ax=ax1)  #MODE1+MODE2+MODE3\n",
    "ax1.set_title(\"MODE3+MODE2+MODE3\")\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()\n",
    "\n",
    "with open('hcam_cat_plt_mode3.pkl', 'wb') as file:\n",
    "    pickle.dump(fig, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b316547c-476d-49ce-bf1d-e60ffd541177",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hcam_cat_plt_mode3.pkl', 'rb') as file:\n",
    "    hcam_cat_plt_mode3 = pickle.load(file)\n",
    "plt.show(hcam_cat_plt_mode3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc64e76-93d3-45d1-a801-cd3a6447abea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48274c97-4a06-4f71-b3ed-8c0682e198ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
